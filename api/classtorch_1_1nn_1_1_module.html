

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Class Module &#8212; PyTorch main documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/theme.css" />
    <link rel="stylesheet" type="text/css" href="../_static/collapsible-lists/css/tree_view.css" />
    <link rel="stylesheet" type="text/css" href="../_static/cpp_theme.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/collapsible-lists/js/CollapsibleLists.compressed.js"></script>
    <script src="../_static/collapsible-lists/js/apply-collapsible-lists.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'api/classtorch_1_1nn_1_1_module';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Class ModuleDict" href="classtorch_1_1nn_1_1_module_dict.html" />
    <link rel="prev" title="Class MishImpl" href="classtorch_1_1nn_1_1_mish_impl.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->

<link rel="stylesheet" type="text/css" href="../_static/css/theme.css" crossorigin="anonymous">
<script type="text/javascript" src="../_static/js/theme.js"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400&display=swap" rel="stylesheet">
<meta property="og:image" content="../_static/img/pytorch_seo.png" />
<link rel="stylesheet" href="../_static/webfonts/all.min.css" crossorigin="anonymous">
<meta http-equiv="Content-Security-Policy"
  content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;">
<meta name="pytorch_project" content="">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" height="0" width="0"
    style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'GTM-T8XT4PS');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', 'main');
</script>
<noscript>
  <img height="1" width="1" src="https://www.facebook.com/tr?id=243028289693773&ev=PageView&noscript=1" />
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>

<script async src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>

<!--
   Search engines should not index the main version of documentation.
   Stable documentation are built without release == 'main'.
   -->
<meta name="robots" content="noindex">


  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>

  </head>

<body data-feedback-url="https://github.com/pytorch/pytorch" class="pytorch-body">
  
    <div class="container-fluid header-holder tutorials-header" id="header-holder">
   <div class="header-container-wrapper">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                <span>Learn</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started/locally">
                  <span class=dropdown-title>Get Started</span>
                </a>
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/webinars/">
                  <span class="dropdown-title">Webinars</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Community</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Landscape</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/join-ecosystem">
                  <span class="dropdown-title">Join the Ecosystem</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-hub/">
                  <span class="dropdown-title">Community Hub</span>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/">
                  <span class="dropdown-title">Forums</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contributor-awards/">
                  <span class="dropdown-title">Contributor Awards</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-events/">
                  <span class="dropdown-title">Community Events</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/programs/ambassadors/">
                  <span class="dropdown-title">PyTorch Ambassadors</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Projects</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/pytorch/">
                  <span class="dropdown-title">PyTorch</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/vllm/">
                  <span class="dropdown-title">vLLM</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/deepspeed/">
                  <span class="dropdown-title">DeepSpeed</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/host-your-project/">
                  <span class="dropdown-title">Host Your Project</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span> Docs</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/domains">
                  <span class="dropdown-title">Domains</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Blogs & News</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">Blog</span>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/announcements">
                  <span class="dropdown-title">Announcements</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/case-studies/">
                  <span class="dropdown-title">Case Studies</span>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">Newsletter</span>
                </a>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>About</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/members">
                  <span class="dropdown-title">Members</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact">
                  <span class="dropdown-title">Contact</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown main-menu-button">
              <a href="https://pytorch.org/join" data-cta="join">
                JOIN
              </a>
            </div>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu">
        <i class="fa-solid fa-ellipsis"></i>
      </a>
    </div>
  </div>
 </div>

 <!-- Begin Mobile Menu -->

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="header-container-wrapper">
      <div class="mobile-main-menu-header-container">
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu">
        </a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">
    <div class="main-menu">
      <ul>
         <li class="resources-mobile-menu-title">
           <a>Learn</a>
         </li>
         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.org/get-started/locally">Get Started</a>
           </li>
           <li>
             <a href="https://docs.pytorch.org/tutorials">Tutorials</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
           </li>
           <li>
            <a href="https://pytorch.org/webinars/">Webinars</a>
          </li>
        </ul>
         <li class="resources-mobile-menu-title">
           <a>Community</a>
         </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://landscape.pytorch.org/">Landscape</a>
          </li>
          <li>
             <a href="https://pytorch.org/join-ecosystem">Join the Ecosystem</a>
           </li>
           <li>
             <a href="https://pytorch.org/community-hub/">Community Hub</a>
           </li>
           <li>
             <a href="https://discuss.pytorch.org/">Forums</a>
           </li>
           <li>
             <a href="https://pytorch.org/resources">Developer Resources</a>
           </li>
           <li>
             <a href="https://pytorch.org/contributor-awards/">Contributor Awards</a>
           </li>
           <li>
            <a href="https://pytorch.org/community-events/">Community Events</a>
          </li>
          <li>
            <a href="https://pytorch.org/programs/ambassadors/">PyTorch Ambassadors</a>
          </li>
       </ul>

         <li class="resources-mobile-menu-title">
           <a>Projects</a>
         </li>

         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.org/projects/pytorch/">PyTorch</a>
           </li>

           <li>
             <a href="https://pytorch.org/projects/vllm/">vLLM</a>
           </li>
           <li>
            <a href="https://pytorch.org/projects/deepspeed/">DeepSpeed</a>
          </li>
          <li>
             <a href="https://pytorch.org/projects/host-your-project/">Host Your Project</a>
           </li>
         </ul>

         <li class="resources-mobile-menu-title">
           <a>Docs</a>
         </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://docs.pytorch.org/docs/stable/index.html">PyTorch</a>
          </li>

          <li>
            <a href="https://pytorch.org/domains">Domains</a>
          </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>Blog & News</a>
        </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>
          <li>
            <a href="https://pytorch.org/announcements">Announcements</a>
          </li>

          <li>
            <a href="https://pytorch.org/case-studies/">Case Studies</a>
          </li>
          <li>
            <a href="https://pytorch.org/events">Events</a>
          </li>
          <li>
             <a href="https://pytorch.org/newsletter">Newsletter</a>
           </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>About</a>
        </li>

        <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
          </li>
          <li>
            <a href="https://pytorch.org/members">Members</a>
          </li>
          <li>
            <a href="https://pytorch.org/governing-board">Governing Board</a>
          </li>
          <li>
            <a href="https://pytorch.org/tac">Technical Advisory Council</a>
         </li>
         <li>
             <a href="https://pytorch.org/credits">Cloud Credit Program</a>
          </li>
          <li>
             <a href="https://pytorch.org/staff">Staff</a>
          </li>
          <li>
             <a href="https://pytorch.org/contact">Contact</a>
          </li>
        </ul>
      </ul>
    </div>
  </div>
</div>

<!-- End Mobile Menu -->
  
  
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">
  <a href="../index.html" class="version">main</a>
</div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../installing.html">
    Installing C++ Distributions of PyTorch
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../frontend.html">
    The C++ Frontend
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="library_root.html">
    Library API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes/faq.html">
    FAQ
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes/inference_mode.html">
    Inference Mode
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../notes/maybe_owned.html">
    MaybeOwned<Tensor>
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../notes/tensor_basics.html">
    Tensor Basics
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../notes/tensor_creation.html">
    Tensor Creation API
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../notes/tensor_cuda_stream.html">
    Tensor CUDA Stream API
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../notes/tensor_indexing.html">
    Tensor Indexing API
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../notes/versioning.html">
    Library Versioning
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
        <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/pytorch" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.org/" title="PyTorch Forum" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyTorch Forum</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../installing.html">
    Installing C++ Distributions of PyTorch
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../frontend.html">
    The C++ Frontend
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="library_root.html">
    Library API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes/faq.html">
    FAQ
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes/inference_mode.html">
    Inference Mode
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes/maybe_owned.html">
    MaybeOwned<Tensor>
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes/tensor_basics.html">
    Tensor Basics
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes/tensor_creation.html">
    Tensor Creation API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes/tensor_cuda_stream.html">
    Tensor CUDA Stream API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes/tensor_indexing.html">
    Tensor Indexing API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes/versioning.html">
    Library Versioning
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/pytorch" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.org/" title="PyTorch Forum" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyTorch Forum</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"></div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="library_root.html" class="nav-link">Library API</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Class Module</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              
  
<div id="searchbox"></div>
  <article class="bd-article" id="pytorch-article">
    <!-- Hidden breadcrumb schema for SEO only -->
    <div style="display:none;" itemscope itemtype="https://schema.org/BreadcrumbList">
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <link itemprop="item" href="library_root.html">
        <meta itemprop="name" content="Library API">
        <meta itemprop="position" content="1">
      </div>
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <meta itemprop="name" content="Class Module">
        <meta itemprop="position" content="2">
      </div>
    </div>

    

    
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="section" id="class-module">
<span id="exhale-class-classtorch-1-1nn-1-1-module"></span><h1>Class Module<a class="headerlink" href="#class-module" title="Permalink to this heading">#</a></h1>
<ul class="simple">
<li><p>Defined in <a class="reference internal" href="file_torch_csrc_api_include_torch_nn_module.h.html#file-torch-csrc-api-include-torch-nn-module-h"><span class="std std-ref">File module.h</span></a></p></li>
</ul>
<div class="contents local topic" id="page-contents">
<p class="topic-title">Page Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#inheritance-relationships" id="id1">Inheritance Relationships</a></p>
<ul>
<li><p><a class="reference internal" href="#base-type" id="id2">Base Type</a></p></li>
<li><p><a class="reference internal" href="#derived-types" id="id3">Derived Types</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#class-documentation" id="id4">Class Documentation</a></p></li>
</ul>
</div>
<div class="section" id="inheritance-relationships">
<h2>Inheritance Relationships<a class="headerlink" href="#inheritance-relationships" title="Permalink to this heading">#</a></h2>
<div class="section" id="base-type">
<h3>Base Type<a class="headerlink" href="#base-type" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">std::enable_shared_from_this&lt;</span> <span class="pre">Module</span> <span class="pre">&gt;</span></code></p></li>
</ul>
</div>
<div class="section" id="derived-types">
<h3>Derived Types<a class="headerlink" href="#derived-types" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">SoftshrinkImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">PReLUImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">LogSoftmaxImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">L1LossImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">SequentialImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">HardshrinkImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">GLUImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">RReLUImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">ParameterDictImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">IdentityImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">FoldImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">EmbeddingBagImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">BilinearImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">TripletMarginWithDistanceLossImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">SoftminImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">SmoothL1LossImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">MultiLabelMarginLossImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">LeakyReLUImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">FunctionalImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">ELUImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">TanhshrinkImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">PairwiseDistanceImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">LogSigmoidImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">HardtanhImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">FractionalMaxPool2dImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">FlattenImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">CrossMapLRN2dImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">TransformerEncoderLayerImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">ThresholdImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">SoftsignImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">MultiMarginLossImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">FractionalMaxPool3dImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">CTCLossImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">UnfoldImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">SiLUImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">ParameterListImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">MultiheadAttentionImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">CELUImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">UpsampleImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">TransformerImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">SELUImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">PixelUnshuffleImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">LinearImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">HingeEmbeddingLossImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">EmbeddingImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">MultiLabelSoftMarginLossImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">CrossEntropyLossImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">TripletMarginLossImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">TransformerDecoderLayerImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">SoftMarginLossImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">LocalResponseNormImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">BCELossImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">LayerNormImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">AdaptiveLogSoftmaxWithLossImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">ReLUImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">ModuleListImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">HuberLossImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">GELUImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">SoftmaxImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">Softmax2dImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">SoftplusImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">SigmoidImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">PoissonNLLLossImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">ModuleDictImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">MishImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">UnflattenImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">ReLU6Impl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">MSELossImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">CosineSimilarityImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">CosineEmbeddingLossImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">TransformerDecoderImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">TanhImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">NLLLossImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">MarginRankingLossImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">BCEWithLogitsLossImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">TransformerEncoderImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">PixelShuffleImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">KLDivLossImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">GroupNormImpl</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">public</span> <span class="pre">torch::nn::Cloneable&lt;</span> <span class="pre">Derived</span> <span class="pre">&gt;</span></code> (<a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#exhale-class-classtorch-1-1nn-1-1-cloneable"><span class="std std-ref">Template Class Cloneable</span></a>)</p></li>
</ul>
</div>
</div>
<div class="section" id="class-documentation">
<h2>Class Documentation<a class="headerlink" href="#class-documentation" title="Permalink to this heading">#</a></h2>
<dl class="cpp class">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6ModuleE">
<span id="_CPPv3N5torch2nn6ModuleE"></span><span id="_CPPv2N5torch2nn6ModuleE"></span><span id="torch::nn::Module"></span><span class="target" id="classtorch_1_1nn_1_1_module"></span><span class="k"><span class="pre">class</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">Module</span></span></span><span class="w"> </span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="k"><span class="pre">public</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">enable_shared_from_this</span></span><span class="p"><span class="pre">&lt;</span></span><a class="reference internal" href="#_CPPv4N5torch2nn6ModuleE" title="torch::nn::Module"><span class="n"><span class="pre">Module</span></span></a><span class="p"><span class="pre">&gt;</span></span><a class="headerlink" href="#_CPPv4N5torch2nn6ModuleE" title="Permalink to this definition">#</a><br /></dt>
<dd><p>The base class for all modules in PyTorch. </p>
<p>A <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> is an abstraction over the implementation of some function or algorithm, possibly associated with some persistent data. A <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> may contain further <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code>s (“submodules”), each with their own implementation, persistent data and further submodules. <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code>s can thus be said to form a recursive tree structure. A <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> is registered as a submodule to another <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> by calling <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module_1a505feb18878e17ed60038c4ed87406f5"><span class="std std-ref"><span class="pre">register_module()</span></span></a></code>, typically from within a parent module’s constructor.</p>
<p>A distinction is made between three kinds of persistent data that may be associated with a <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code>:</p>
<p><ol class="loweralpha simple">
<li><p><em>Parameters</em>: tensors that record gradients, typically weights updated during the backward step (e.g. the <code class="docutils literal notranslate"><span class="pre">weight</span></code> of a <code class="docutils literal notranslate"><a class="reference internal" href="classtorch_1_1nn_1_1_linear.html#classtorch_1_1nn_1_1_linear"><span class="std std-ref"><span class="pre">Linear</span></span></a></code> module),</p></li>
<li><p><em>Buffers</em>: tensors that do not record gradients, typically updated during the forward step, such as running statistics (e.g. <code class="docutils literal notranslate"><span class="pre">mean</span></code> and <code class="docutils literal notranslate"><span class="pre">variance</span></code> in the <code class="docutils literal notranslate"><span class="pre">BatchNorm</span></code> module),</p></li>
<li><p>Any additional state, not necessarily tensors, required for the implementation or configuration of a <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code>.</p></li>
</ol>
</p>
<p>The first two kinds of state are special in that they may be registered with the <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> system to allow convenient access and batch configuration. For example, registered parameters in any <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> may be iterated over via the <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module_1a37b0008259770153722e6ecdb8ffade2"><span class="std std-ref"><span class="pre">parameters()</span></span></a></code> accessor. Further, changing the data type of a <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code>’s registered parameters can be done conveniently via <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module_1a50706fc09d79c3af9c7348bd76d7da17"><span class="std std-ref"><span class="pre">Module::to()</span></span></a></code>, e.g. <code class="docutils literal notranslate"><span class="pre">module-&gt;to(torch::kCUDA)</span></code> to move all parameters to GPU memory. Lastly, registered parameters and buffers are handled specially during a <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module_1afe74ce9f020f9f46527689539b4b4f66"><span class="std std-ref"><span class="pre">clone()</span></span></a></code> operation, which performs a deepcopy of a cloneable <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> hierarchy.</p>
<p>Parameters are registered with a <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> via <code class="docutils literal notranslate"><span class="pre">register_parameter</span></code>. Buffers are registered separately via <code class="docutils literal notranslate"><span class="pre">register_buffer</span></code>. These methods are part of the public API of <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> and are typically invoked from within a concrete <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code>s constructor. </p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The design and implementation of this class is largely based on the Python
API. You may want to consult the python documentation for
<a class="reference external" href="https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch vmain (2.10.0a0+git86f9f1d ))"><code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code></a> for further clarification on certain
methods or behavior.</p>
</div>
<p>Subclassed by <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; SoftshrinkImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; PReLUImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; LogSoftmaxImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; L1LossImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; SequentialImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; HardshrinkImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; GLUImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; RReLUImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; ParameterDictImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; IdentityImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; FoldImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; EmbeddingBagImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; BilinearImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; TripletMarginWithDistanceLossImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; SoftminImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; SmoothL1LossImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; MultiLabelMarginLossImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; LeakyReLUImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; FunctionalImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; ELUImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; TanhshrinkImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; PairwiseDistanceImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; LogSigmoidImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; HardtanhImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; FractionalMaxPool2dImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; FlattenImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; CrossMapLRN2dImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; TransformerEncoderLayerImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; ThresholdImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; SoftsignImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; MultiMarginLossImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; FractionalMaxPool3dImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; CTCLossImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; UnfoldImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; SiLUImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; ParameterListImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; MultiheadAttentionImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; CELUImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; UpsampleImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; TransformerImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; SELUImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; PixelUnshuffleImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; LinearImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; HingeEmbeddingLossImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; EmbeddingImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; MultiLabelSoftMarginLossImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; CrossEntropyLossImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; TripletMarginLossImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; TransformerDecoderLayerImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; SoftMarginLossImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; LocalResponseNormImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; BCELossImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; LayerNormImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; AdaptiveLogSoftmaxWithLossImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; ReLUImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; ModuleListImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; HuberLossImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; GELUImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; SoftmaxImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; Softmax2dImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; SoftplusImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; SigmoidImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; PoissonNLLLossImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; ModuleDictImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; MishImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; UnflattenImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; ReLU6Impl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; MSELossImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; CosineSimilarityImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; CosineEmbeddingLossImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; TransformerDecoderImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; TanhImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; NLLLossImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; MarginRankingLossImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; BCEWithLogitsLossImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; TransformerEncoderImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; PixelShuffleImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; KLDivLossImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; GroupNormImpl &gt;</span></a>, <a class="reference internal" href="classtorch_1_1nn_1_1_cloneable.html#classtorch_1_1nn_1_1_cloneable"><span class="std std-ref">torch::nn::Cloneable&lt; Derived &gt;</span></a></p>
<div class="breathe-sectiondef docutils container">
<p class="breathe-sectiondef-title rubric" id="breathe-section-title-public-types">Public Types</p>
<dl class="cpp type">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6Module19ModuleApplyFunctionE">
<span id="_CPPv3N5torch2nn6Module19ModuleApplyFunctionE"></span><span id="_CPPv2N5torch2nn6Module19ModuleApplyFunctionE"></span><span class="target" id="classtorch_1_1nn_1_1_module_1a8a47ce884e1eb218f07d65d5fb9a4eae"></span><span class="k"><span class="pre">using</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">ModuleApplyFunction</span></span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">function</span></span><span class="p"><span class="pre">&lt;</span></span><span class="kt"><span class="pre">void</span></span><span class="p"><span class="pre">(</span></span><a class="reference internal" href="#_CPPv4N5torch2nn6ModuleE" title="torch::nn::Module"><span class="n"><span class="pre">Module</span></span></a><span class="p"><span class="pre">&amp;</span></span><span class="p"><span class="pre">)</span></span><span class="p"><span class="pre">&gt;</span></span><a class="headerlink" href="#_CPPv4N5torch2nn6Module19ModuleApplyFunctionE" title="Permalink to this definition">#</a><br /></dt>
<dd></dd></dl>

<dl class="cpp type">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6Module24ConstModuleApplyFunctionE">
<span id="_CPPv3N5torch2nn6Module24ConstModuleApplyFunctionE"></span><span id="_CPPv2N5torch2nn6Module24ConstModuleApplyFunctionE"></span><span class="target" id="classtorch_1_1nn_1_1_module_1a621e17f1e564b3f2b795a9248a0834ee"></span><span class="k"><span class="pre">using</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">ConstModuleApplyFunction</span></span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">function</span></span><span class="p"><span class="pre">&lt;</span></span><span class="kt"><span class="pre">void</span></span><span class="p"><span class="pre">(</span></span><span class="k"><span class="pre">const</span></span><span class="w"> </span><a class="reference internal" href="#_CPPv4N5torch2nn6ModuleE" title="torch::nn::Module"><span class="n"><span class="pre">Module</span></span></a><span class="p"><span class="pre">&amp;</span></span><span class="p"><span class="pre">)</span></span><span class="p"><span class="pre">&gt;</span></span><a class="headerlink" href="#_CPPv4N5torch2nn6Module24ConstModuleApplyFunctionE" title="Permalink to this definition">#</a><br /></dt>
<dd></dd></dl>

<dl class="cpp type">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6Module24NamedModuleApplyFunctionE">
<span id="_CPPv3N5torch2nn6Module24NamedModuleApplyFunctionE"></span><span id="_CPPv2N5torch2nn6Module24NamedModuleApplyFunctionE"></span><span class="target" id="classtorch_1_1nn_1_1_module_1ad3fc42479f682663add3b5eb9e707afc"></span><span class="k"><span class="pre">using</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">NamedModuleApplyFunction</span></span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">function</span></span><span class="p"><span class="pre">&lt;</span></span><span class="kt"><span class="pre">void</span></span><span class="p"><span class="pre">(</span></span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">string</span></span><span class="p"><span class="pre">&amp;</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#_CPPv4N5torch2nn6ModuleE" title="torch::nn::Module"><span class="n"><span class="pre">Module</span></span></a><span class="p"><span class="pre">&amp;</span></span><span class="p"><span class="pre">)</span></span><span class="p"><span class="pre">&gt;</span></span><a class="headerlink" href="#_CPPv4N5torch2nn6Module24NamedModuleApplyFunctionE" title="Permalink to this definition">#</a><br /></dt>
<dd></dd></dl>

<dl class="cpp type">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6Module29ConstNamedModuleApplyFunctionE">
<span id="_CPPv3N5torch2nn6Module29ConstNamedModuleApplyFunctionE"></span><span id="_CPPv2N5torch2nn6Module29ConstNamedModuleApplyFunctionE"></span><span class="target" id="classtorch_1_1nn_1_1_module_1a321b55e7501c7bd3e2bd4ef09cb43fb8"></span><span class="k"><span class="pre">using</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">ConstNamedModuleApplyFunction</span></span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">function</span></span><span class="p"><span class="pre">&lt;</span></span><span class="kt"><span class="pre">void</span></span><span class="p"><span class="pre">(</span></span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">string</span></span><span class="p"><span class="pre">&amp;</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">const</span></span><span class="w"> </span><a class="reference internal" href="#_CPPv4N5torch2nn6ModuleE" title="torch::nn::Module"><span class="n"><span class="pre">Module</span></span></a><span class="p"><span class="pre">&amp;</span></span><span class="p"><span class="pre">)</span></span><span class="p"><span class="pre">&gt;</span></span><a class="headerlink" href="#_CPPv4N5torch2nn6Module29ConstNamedModuleApplyFunctionE" title="Permalink to this definition">#</a><br /></dt>
<dd></dd></dl>

<dl class="cpp type">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6Module26ModulePointerApplyFunctionE">
<span id="_CPPv3N5torch2nn6Module26ModulePointerApplyFunctionE"></span><span id="_CPPv2N5torch2nn6Module26ModulePointerApplyFunctionE"></span><span class="target" id="classtorch_1_1nn_1_1_module_1a068ca6621e67f3d4ef1828b719a8a347"></span><span class="k"><span class="pre">using</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">ModulePointerApplyFunction</span></span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">function</span></span><span class="p"><span class="pre">&lt;</span></span><span class="kt"><span class="pre">void</span></span><span class="p"><span class="pre">(</span></span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">shared_ptr</span></span><span class="p"><span class="pre">&lt;</span></span><a class="reference internal" href="#_CPPv4N5torch2nn6ModuleE" title="torch::nn::Module"><span class="n"><span class="pre">Module</span></span></a><span class="p"><span class="pre">&gt;</span></span><span class="p"><span class="pre">&amp;</span></span><span class="p"><span class="pre">)</span></span><span class="p"><span class="pre">&gt;</span></span><a class="headerlink" href="#_CPPv4N5torch2nn6Module26ModulePointerApplyFunctionE" title="Permalink to this definition">#</a><br /></dt>
<dd></dd></dl>

<dl class="cpp type">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6Module31NamedModulePointerApplyFunctionE">
<span id="_CPPv3N5torch2nn6Module31NamedModulePointerApplyFunctionE"></span><span id="_CPPv2N5torch2nn6Module31NamedModulePointerApplyFunctionE"></span><span class="target" id="classtorch_1_1nn_1_1_module_1a1656aeb55c051e8368db6871d536e341"></span><span class="k"><span class="pre">using</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">NamedModulePointerApplyFunction</span></span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">function</span></span><span class="p"><span class="pre">&lt;</span></span><span class="kt"><span class="pre">void</span></span><span class="p"><span class="pre">(</span></span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">string</span></span><span class="p"><span class="pre">&amp;</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">shared_ptr</span></span><span class="p"><span class="pre">&lt;</span></span><a class="reference internal" href="#_CPPv4N5torch2nn6ModuleE" title="torch::nn::Module"><span class="n"><span class="pre">Module</span></span></a><span class="p"><span class="pre">&gt;</span></span><span class="p"><span class="pre">&amp;</span></span><span class="p"><span class="pre">)</span></span><span class="p"><span class="pre">&gt;</span></span><a class="headerlink" href="#_CPPv4N5torch2nn6Module31NamedModulePointerApplyFunctionE" title="Permalink to this definition">#</a><br /></dt>
<dd></dd></dl>

</div>
<div class="breathe-sectiondef docutils container">
<p class="breathe-sectiondef-title rubric" id="breathe-section-title-public-functions">Public Functions</p>
<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6Module6ModuleENSt6stringE">
<span id="_CPPv3N5torch2nn6Module6ModuleENSt6stringE"></span><span id="_CPPv2N5torch2nn6Module6ModuleENSt6stringE"></span><span id="torch::nn::Module::Module__ss"></span><span class="target" id="classtorch_1_1nn_1_1_module_1a33ac482c601ffecdaabe46a0f364cc51"></span><span class="k"><span class="pre">explicit</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">Module</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">name</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N5torch2nn6Module6ModuleENSt6stringE" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Tells the base <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> about the name of the submodule. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6Module6ModuleEv">
<span id="_CPPv3N5torch2nn6Module6ModuleEv"></span><span id="_CPPv2N5torch2nn6Module6ModuleEv"></span><span id="torch::nn::Module::Module"></span><span class="target" id="classtorch_1_1nn_1_1_module_1a941f24af291e05af5428e125d20f486a"></span><span class="sig-name descname"><span class="n"><span class="pre">Module</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N5torch2nn6Module6ModuleEv" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Constructs the module without immediate knowledge of the submodule’s name. </p>
<p>The name of the submodule is inferred via RTTI (if possible) the first time <code class="docutils literal notranslate"><span class="pre">.</span><a class="reference internal" href="#classtorch_1_1nn_1_1_module_1a09407fc8e8eca674c18dd4436f1a7ad2"><span class="std std-ref"><span class="pre">name()</span></span></a></code> is invoked. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6Module6ModuleERK6Module">
<span id="_CPPv3N5torch2nn6Module6ModuleERK6Module"></span><span id="_CPPv2N5torch2nn6Module6ModuleERK6Module"></span><span id="torch::nn::Module::Module__ModuleCR"></span><span class="target" id="classtorch_1_1nn_1_1_module_1aa1ca4137cc67e556ee5f12c50e5a6d5a"></span><span class="sig-name descname"><span class="n"><span class="pre">Module</span></span></span><span class="sig-paren">(</span><span class="k"><span class="pre">const</span></span><span class="w"> </span><a class="reference internal" href="#_CPPv4N5torch2nn6Module6ModuleERK6Module" title="torch::nn::Module::Module"><span class="n"><span class="pre">Module</span></span></a><span class="p"><span class="pre">&amp;</span></span><span class="sig-paren">)</span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="k"><span class="pre">default</span></span><a class="headerlink" href="#_CPPv4N5torch2nn6Module6ModuleERK6Module" title="Permalink to this definition">#</a><br /></dt>
<dd></dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6ModuleaSERK6Module">
<span id="_CPPv3N5torch2nn6ModuleaSERK6Module"></span><span id="_CPPv2N5torch2nn6ModuleaSERK6Module"></span><span id="torch::nn::Module::assign-operator__ModuleCR"></span><span class="target" id="classtorch_1_1nn_1_1_module_1a3b964946bed70a46bb49e804fb6d49d1"></span><a class="reference internal" href="#_CPPv4N5torch2nn6ModuleE" title="torch::nn::Module"><span class="n"><span class="pre">Module</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="sig-name descname"><span class="k"><span class="pre">operator</span></span><span class="o"><span class="pre">=</span></span></span><span class="sig-paren">(</span><span class="k"><span class="pre">const</span></span><span class="w"> </span><a class="reference internal" href="#_CPPv4N5torch2nn6ModuleE" title="torch::nn::Module"><span class="n"><span class="pre">Module</span></span></a><span class="p"><span class="pre">&amp;</span></span><span class="sig-paren">)</span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="k"><span class="pre">default</span></span><a class="headerlink" href="#_CPPv4N5torch2nn6ModuleaSERK6Module" title="Permalink to this definition">#</a><br /></dt>
<dd></dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6Module6ModuleERR6Module">
<span id="_CPPv3N5torch2nn6Module6ModuleERR6Module"></span><span id="_CPPv2N5torch2nn6Module6ModuleERR6Module"></span><span id="torch::nn::Module::Module__ModuleRR"></span><span class="target" id="classtorch_1_1nn_1_1_module_1a30af124d97d7318634a81b93c9e88f39"></span><span class="sig-name descname"><span class="n"><span class="pre">Module</span></span></span><span class="sig-paren">(</span><a class="reference internal" href="#_CPPv4N5torch2nn6Module6ModuleERR6Module" title="torch::nn::Module::Module"><span class="n"><span class="pre">Module</span></span></a><span class="p"><span class="pre">&amp;</span></span><span class="p"><span class="pre">&amp;</span></span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">noexcept</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="k"><span class="pre">default</span></span><a class="headerlink" href="#_CPPv4N5torch2nn6Module6ModuleERR6Module" title="Permalink to this definition">#</a><br /></dt>
<dd></dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6ModuleaSERR6Module">
<span id="_CPPv3N5torch2nn6ModuleaSERR6Module"></span><span id="_CPPv2N5torch2nn6ModuleaSERR6Module"></span><span id="torch::nn::Module::assign-operator__ModuleRR"></span><span class="target" id="classtorch_1_1nn_1_1_module_1a0d5c180887227191a2e4630d8ece4a47"></span><a class="reference internal" href="#_CPPv4N5torch2nn6ModuleE" title="torch::nn::Module"><span class="n"><span class="pre">Module</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="sig-name descname"><span class="k"><span class="pre">operator</span></span><span class="o"><span class="pre">=</span></span></span><span class="sig-paren">(</span><a class="reference internal" href="#_CPPv4N5torch2nn6ModuleE" title="torch::nn::Module"><span class="n"><span class="pre">Module</span></span></a><span class="p"><span class="pre">&amp;</span></span><span class="p"><span class="pre">&amp;</span></span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">noexcept</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="k"><span class="pre">default</span></span><a class="headerlink" href="#_CPPv4N5torch2nn6ModuleaSERR6Module" title="Permalink to this definition">#</a><br /></dt>
<dd></dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6ModuleD0Ev">
<span id="_CPPv3N5torch2nn6ModuleD0Ev"></span><span id="_CPPv2N5torch2nn6ModuleD0Ev"></span><span id="torch::nn::Module::~Module"></span><span class="target" id="classtorch_1_1nn_1_1_module_1afbc08b9bf696297df27ab4e86fcec9f4"></span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">~Module</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="k"><span class="pre">default</span></span><a class="headerlink" href="#_CPPv4N5torch2nn6ModuleD0Ev" title="Permalink to this definition">#</a><br /></dt>
<dd></dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK5torch2nn6Module4nameEv">
<span id="_CPPv3NK5torch2nn6Module4nameEv"></span><span id="_CPPv2NK5torch2nn6Module4nameEv"></span><span id="torch::nn::Module::nameC"></span><span class="target" id="classtorch_1_1nn_1_1_module_1a09407fc8e8eca674c18dd4436f1a7ad2"></span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="sig-name descname"><span class="n"><span class="pre">name</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="k"><span class="pre">noexcept</span></span><a class="headerlink" href="#_CPPv4NK5torch2nn6Module4nameEv" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Returns the name of the <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code>. </p>
<p>A <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> has an associated <code class="docutils literal notranslate"><span class="pre">name</span></code>, which is a string representation of the kind of concrete <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> it represents, such as <code class="docutils literal notranslate"><span class="pre">&quot;Linear&quot;</span></code> for the <code class="docutils literal notranslate"><a class="reference internal" href="classtorch_1_1nn_1_1_linear.html#classtorch_1_1nn_1_1_linear"><span class="std std-ref"><span class="pre">Linear</span></span></a></code> module. Under most circumstances, this name is automatically inferred via runtime type information (RTTI). In the unusual circumstance that you have this feature disabled, you may want to manually name your <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code>s by passing the string name to the <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> base class’ constructor. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK5torch2nn6Module5cloneERKNSt8optionalI6DeviceEE">
<span id="_CPPv3NK5torch2nn6Module5cloneERKNSt8optionalI6DeviceEE"></span><span id="_CPPv2NK5torch2nn6Module5cloneERKNSt8optionalI6DeviceEE"></span><span id="torch::nn::Module::clone__std::optional:Device:CRC"></span><span class="target" id="classtorch_1_1nn_1_1_module_1afe74ce9f020f9f46527689539b4b4f66"></span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">shared_ptr</span></span><span class="p"><span class="pre">&lt;</span></span><a class="reference internal" href="#_CPPv4N5torch2nn6ModuleE" title="torch::nn::Module"><span class="n"><span class="pre">Module</span></span></a><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">clone</span></span></span><span class="sig-paren">(</span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">optional</span></span><span class="p"><span class="pre">&lt;</span></span><span class="n"><span class="pre">Device</span></span><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">device</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">nullopt</span></span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK5torch2nn6Module5cloneERKNSt8optionalI6DeviceEE" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Performs a recursive deep copy of the module and all its registered parameters, buffers and submodules. </p>
<p>Optionally, this method sets the current device to the one supplied before cloning. If no device is given, each parameter and buffer will be moved to the device of its source.</p>
<p><p><div class="admonition attention">
<p class="admonition-title">Attention</p>
<p>Attempting to call the <cite>clone()</cite> method inherited from the base <cite>Module</cite>
class (the one documented here) will fail. To inherit an actual
implementation of <cite>clone()</cite>, you must subclass <cite>Cloneable</cite>. <cite>Cloneable</cite>
is templatized on the concrete module type, and can thus properly copy a
<cite>Module</cite>. This method is provided on the base class’ API solely for an
easier-to-use polymorphic interface.</p>
</div>
</p>
 </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6Module5applyERK19ModuleApplyFunction">
<span id="_CPPv3N5torch2nn6Module5applyERK19ModuleApplyFunction"></span><span id="_CPPv2N5torch2nn6Module5applyERK19ModuleApplyFunction"></span><span id="torch::nn::Module::apply__ModuleApplyFunctionCR"></span><span class="target" id="classtorch_1_1nn_1_1_module_1a3e7bf8192a37c7e6593b5d1dd5d15903"></span><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">apply</span></span></span><span class="sig-paren">(</span><span class="k"><span class="pre">const</span></span><span class="w"> </span><a class="reference internal" href="#_CPPv4N5torch2nn6Module19ModuleApplyFunctionE" title="torch::nn::Module::ModuleApplyFunction"><span class="n"><span class="pre">ModuleApplyFunction</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">function</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N5torch2nn6Module5applyERK19ModuleApplyFunction" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Applies the <code class="docutils literal notranslate"><span class="pre">function</span></code> to the <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> and recursively to every submodule. </p>
<p>The function must accept a <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a><span class="pre">&amp;</span></code>.</p>
<p><p></p>
 </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK5torch2nn6Module5applyERK24ConstModuleApplyFunction">
<span id="_CPPv3NK5torch2nn6Module5applyERK24ConstModuleApplyFunction"></span><span id="_CPPv2NK5torch2nn6Module5applyERK24ConstModuleApplyFunction"></span><span id="torch::nn::Module::apply__ConstModuleApplyFunctionCRC"></span><span class="target" id="classtorch_1_1nn_1_1_module_1abf51a558416fbe54db859f2286b34275"></span><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">apply</span></span></span><span class="sig-paren">(</span><span class="k"><span class="pre">const</span></span><span class="w"> </span><a class="reference internal" href="#_CPPv4N5torch2nn6Module24ConstModuleApplyFunctionE" title="torch::nn::Module::ConstModuleApplyFunction"><span class="n"><span class="pre">ConstModuleApplyFunction</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">function</span></span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK5torch2nn6Module5applyERK24ConstModuleApplyFunction" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Applies the <code class="docutils literal notranslate"><span class="pre">function</span></code> to the <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> and recursively to every submodule. </p>
<p>The function must accept a <code class="docutils literal notranslate"><span class="pre">const</span> <a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a><span class="pre">&amp;</span></code>.</p>
<p><p></p>
 </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6Module5applyERK24NamedModuleApplyFunctionRKNSt6stringE">
<span id="_CPPv3N5torch2nn6Module5applyERK24NamedModuleApplyFunctionRKNSt6stringE"></span><span id="_CPPv2N5torch2nn6Module5applyERK24NamedModuleApplyFunctionRKNSt6stringE"></span><span id="torch::nn::Module::apply__NamedModuleApplyFunctionCR.ssCR"></span><span class="target" id="classtorch_1_1nn_1_1_module_1aac037622ec1099f031a284bb8e084832"></span><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">apply</span></span></span><span class="sig-paren">(</span><span class="k"><span class="pre">const</span></span><span class="w"> </span><a class="reference internal" href="#_CPPv4N5torch2nn6Module24NamedModuleApplyFunctionE" title="torch::nn::Module::NamedModuleApplyFunction"><span class="n"><span class="pre">NamedModuleApplyFunction</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">function</span></span>, <span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">name_prefix</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">string</span></span><span class="p"><span class="pre">(</span></span><span class="p"><span class="pre">)</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N5torch2nn6Module5applyERK24NamedModuleApplyFunctionRKNSt6stringE" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Applies the <code class="docutils literal notranslate"><span class="pre">function</span></code> to the <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> and recursively to every submodule. </p>
<p>The function must accept a <code class="docutils literal notranslate"><span class="pre">const</span> <span class="pre">std::string&amp;</span></code> for the key of the module, and a <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a><span class="pre">&amp;</span></code>. The key of the module itself is the empty string. If <code class="docutils literal notranslate"><span class="pre">name_prefix</span></code> is given, it is prepended to every key as <code class="docutils literal notranslate"><span class="pre">&lt;name_prefix&gt;.&lt;key&gt;</span></code> (and just <code class="docutils literal notranslate"><span class="pre">name_prefix</span></code> for the module itself).</p>
<p><p></p>
 </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK5torch2nn6Module5applyERK29ConstNamedModuleApplyFunctionRKNSt6stringE">
<span id="_CPPv3NK5torch2nn6Module5applyERK29ConstNamedModuleApplyFunctionRKNSt6stringE"></span><span id="_CPPv2NK5torch2nn6Module5applyERK29ConstNamedModuleApplyFunctionRKNSt6stringE"></span><span id="torch::nn::Module::apply__ConstNamedModuleApplyFunctionCR.ssCRC"></span><span class="target" id="classtorch_1_1nn_1_1_module_1a571179d108b0cbff7d7a293d1f42862e"></span><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">apply</span></span></span><span class="sig-paren">(</span><span class="k"><span class="pre">const</span></span><span class="w"> </span><a class="reference internal" href="#_CPPv4N5torch2nn6Module29ConstNamedModuleApplyFunctionE" title="torch::nn::Module::ConstNamedModuleApplyFunction"><span class="n"><span class="pre">ConstNamedModuleApplyFunction</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">function</span></span>, <span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">name_prefix</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">string</span></span><span class="p"><span class="pre">(</span></span><span class="p"><span class="pre">)</span></span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK5torch2nn6Module5applyERK29ConstNamedModuleApplyFunctionRKNSt6stringE" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Applies the <code class="docutils literal notranslate"><span class="pre">function</span></code> to the <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> and recursively to every submodule. </p>
<p>The function must accept a <code class="docutils literal notranslate"><span class="pre">const</span> <span class="pre">std::string&amp;</span></code> for the key of the module, and a <code class="docutils literal notranslate"><span class="pre">const</span> <a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a><span class="pre">&amp;</span></code>. The key of the module itself is the empty string. If <code class="docutils literal notranslate"><span class="pre">name_prefix</span></code> is given, it is prepended to every key as <code class="docutils literal notranslate"><span class="pre">&lt;name_prefix&gt;.&lt;key&gt;</span></code> (and just <code class="docutils literal notranslate"><span class="pre">name_prefix</span></code> for the module itself).</p>
<p><p></p>
 </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK5torch2nn6Module5applyERK26ModulePointerApplyFunction">
<span id="_CPPv3NK5torch2nn6Module5applyERK26ModulePointerApplyFunction"></span><span id="_CPPv2NK5torch2nn6Module5applyERK26ModulePointerApplyFunction"></span><span id="torch::nn::Module::apply__ModulePointerApplyFunctionCRC"></span><span class="target" id="classtorch_1_1nn_1_1_module_1af7a8ac88b696ad4c3d3e6d93b5a2dbf4"></span><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">apply</span></span></span><span class="sig-paren">(</span><span class="k"><span class="pre">const</span></span><span class="w"> </span><a class="reference internal" href="#_CPPv4N5torch2nn6Module26ModulePointerApplyFunctionE" title="torch::nn::Module::ModulePointerApplyFunction"><span class="n"><span class="pre">ModulePointerApplyFunction</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">function</span></span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK5torch2nn6Module5applyERK26ModulePointerApplyFunction" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Applies the <code class="docutils literal notranslate"><span class="pre">function</span></code> to the <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> and recursively to every submodule. </p>
<p>The function must accept a <code class="docutils literal notranslate"><span class="pre">const</span> <span class="pre">std::shared_ptr&lt;</span><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a><span class="pre">&gt;&amp;</span></code>.</p>
<p><p></p>
 </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK5torch2nn6Module5applyERK31NamedModulePointerApplyFunctionRKNSt6stringE">
<span id="_CPPv3NK5torch2nn6Module5applyERK31NamedModulePointerApplyFunctionRKNSt6stringE"></span><span id="_CPPv2NK5torch2nn6Module5applyERK31NamedModulePointerApplyFunctionRKNSt6stringE"></span><span id="torch::nn::Module::apply__NamedModulePointerApplyFunctionCR.ssCRC"></span><span class="target" id="classtorch_1_1nn_1_1_module_1aaf0bddf2ba739b62d2d7d90ff401bc7c"></span><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">apply</span></span></span><span class="sig-paren">(</span><span class="k"><span class="pre">const</span></span><span class="w"> </span><a class="reference internal" href="#_CPPv4N5torch2nn6Module31NamedModulePointerApplyFunctionE" title="torch::nn::Module::NamedModulePointerApplyFunction"><span class="n"><span class="pre">NamedModulePointerApplyFunction</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">function</span></span>, <span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">name_prefix</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">string</span></span><span class="p"><span class="pre">(</span></span><span class="p"><span class="pre">)</span></span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK5torch2nn6Module5applyERK31NamedModulePointerApplyFunctionRKNSt6stringE" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Applies the <code class="docutils literal notranslate"><span class="pre">function</span></code> to the <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> and recursively to every submodule. </p>
<p>The function must accept a <code class="docutils literal notranslate"><span class="pre">const</span> <span class="pre">std::string&amp;</span></code> for the key of the module, and a <code class="docutils literal notranslate"><span class="pre">const</span> <span class="pre">std::shared_ptr&lt;</span><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a><span class="pre">&gt;&amp;</span></code>. The key of the module itself is the empty string. If <code class="docutils literal notranslate"><span class="pre">name_prefix</span></code> is given, it is prepended to every key as <code class="docutils literal notranslate"><span class="pre">&lt;name_prefix&gt;.&lt;key&gt;</span></code> (and just <code class="docutils literal notranslate"><span class="pre">name_prefix</span></code> for the module itself).</p>
<p><p></p>
 </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK5torch2nn6Module10parametersEb">
<span id="_CPPv3NK5torch2nn6Module10parametersEb"></span><span id="_CPPv2NK5torch2nn6Module10parametersEb"></span><span id="torch::nn::Module::parameters__bC"></span><span class="target" id="classtorch_1_1nn_1_1_module_1a37b0008259770153722e6ecdb8ffade2"></span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">vector</span></span><span class="p"><span class="pre">&lt;</span></span><span class="n"><span class="pre">Tensor</span></span><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">parameters</span></span></span><span class="sig-paren">(</span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">recurse</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="k"><span class="pre">true</span></span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK5torch2nn6Module10parametersEb" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Returns the parameters of this <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> and if <code class="docutils literal notranslate"><span class="pre">recurse</span></code> is true, also recursively of every submodule. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK5torch2nn6Module16named_parametersEb">
<span id="_CPPv3NK5torch2nn6Module16named_parametersEb"></span><span id="_CPPv2NK5torch2nn6Module16named_parametersEb"></span><span id="torch::nn::Module::named_parameters__bC"></span><span class="target" id="classtorch_1_1nn_1_1_module_1af09f38cd506bf482c6bf1b4403787b9c"></span><a class="reference internal" href="classtorch_1_1_ordered_dict.html#_CPPv4I00EN5torch11OrderedDictE" title="torch::OrderedDict"><span class="n"><span class="pre">OrderedDict</span></span></a><span class="p"><span class="pre">&lt;</span></span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">string</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">named_parameters</span></span></span><span class="sig-paren">(</span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">recurse</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="k"><span class="pre">true</span></span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK5torch2nn6Module16named_parametersEb" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Returns an <code class="docutils literal notranslate"><a class="reference internal" href="classtorch_1_1_ordered_dict.html#classtorch_1_1_ordered_dict"><span class="std std-ref"><span class="pre">OrderedDict</span></span></a></code> with the parameters of this <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> along with their keys, and if <code class="docutils literal notranslate"><span class="pre">recurse</span></code> is true also recursively of every submodule. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK5torch2nn6Module7buffersEb">
<span id="_CPPv3NK5torch2nn6Module7buffersEb"></span><span id="_CPPv2NK5torch2nn6Module7buffersEb"></span><span id="torch::nn::Module::buffers__bC"></span><span class="target" id="classtorch_1_1nn_1_1_module_1a4fcf6732e0780b864678d6adf31ebdd1"></span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">vector</span></span><span class="p"><span class="pre">&lt;</span></span><span class="n"><span class="pre">Tensor</span></span><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">buffers</span></span></span><span class="sig-paren">(</span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">recurse</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="k"><span class="pre">true</span></span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK5torch2nn6Module7buffersEb" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Returns the buffers of this <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> and if <code class="docutils literal notranslate"><span class="pre">recurse</span></code> is true, also recursively of every submodule. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK5torch2nn6Module13named_buffersEb">
<span id="_CPPv3NK5torch2nn6Module13named_buffersEb"></span><span id="_CPPv2NK5torch2nn6Module13named_buffersEb"></span><span id="torch::nn::Module::named_buffers__bC"></span><span class="target" id="classtorch_1_1nn_1_1_module_1a1cdb416154988475ac49485b36f614c3"></span><a class="reference internal" href="classtorch_1_1_ordered_dict.html#_CPPv4I00EN5torch11OrderedDictE" title="torch::OrderedDict"><span class="n"><span class="pre">OrderedDict</span></span></a><span class="p"><span class="pre">&lt;</span></span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">string</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">named_buffers</span></span></span><span class="sig-paren">(</span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">recurse</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="k"><span class="pre">true</span></span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK5torch2nn6Module13named_buffersEb" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Returns an <code class="docutils literal notranslate"><a class="reference internal" href="classtorch_1_1_ordered_dict.html#classtorch_1_1_ordered_dict"><span class="std std-ref"><span class="pre">OrderedDict</span></span></a></code> with the buffers of this <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> along with their keys, and if <code class="docutils literal notranslate"><span class="pre">recurse</span></code> is true also recursively of every submodule. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK5torch2nn6Module7modulesEb">
<span id="_CPPv3NK5torch2nn6Module7modulesEb"></span><span id="_CPPv2NK5torch2nn6Module7modulesEb"></span><span id="torch::nn::Module::modules__bC"></span><span class="target" id="classtorch_1_1nn_1_1_module_1a90792e81478857f8eb3573d6276b5632"></span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">vector</span></span><span class="p"><span class="pre">&lt;</span></span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">shared_ptr</span></span><span class="p"><span class="pre">&lt;</span></span><a class="reference internal" href="#_CPPv4N5torch2nn6ModuleE" title="torch::nn::Module"><span class="n"><span class="pre">Module</span></span></a><span class="p"><span class="pre">&gt;</span></span><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">modules</span></span></span><span class="sig-paren">(</span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">include_self</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="k"><span class="pre">true</span></span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK5torch2nn6Module7modulesEb" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Returns the submodules of this <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> (the entire submodule hierarchy) and if <code class="docutils literal notranslate"><span class="pre">include_self</span></code> is true, also inserts a <code class="docutils literal notranslate"><span class="pre">shared_ptr</span></code> to this module in the first position. </p>
<p><p></p>
 </p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Only pass <cite>include_self</cite> as <cite>true</cite> if this <cite>Module</cite> is stored in a
<cite>shared_ptr</cite>! Otherwise an exception will be thrown. You may still call
this method with <cite>include_self</cite> set to false if your <cite>Module</cite> is not
stored in a <cite>shared_ptr</cite>.</p>
</div>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK5torch2nn6Module13named_modulesERKNSt6stringEb">
<span id="_CPPv3NK5torch2nn6Module13named_modulesERKNSt6stringEb"></span><span id="_CPPv2NK5torch2nn6Module13named_modulesERKNSt6stringEb"></span><span id="torch::nn::Module::named_modules__ssCR.bC"></span><span class="target" id="classtorch_1_1nn_1_1_module_1a697c3916423e8ba05bf0321602735cd0"></span><a class="reference internal" href="classtorch_1_1_ordered_dict.html#_CPPv4I00EN5torch11OrderedDictE" title="torch::OrderedDict"><span class="n"><span class="pre">OrderedDict</span></span></a><span class="p"><span class="pre">&lt;</span></span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">string</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">shared_ptr</span></span><span class="p"><span class="pre">&lt;</span></span><a class="reference internal" href="#_CPPv4N5torch2nn6ModuleE" title="torch::nn::Module"><span class="n"><span class="pre">Module</span></span></a><span class="p"><span class="pre">&gt;</span></span><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">named_modules</span></span></span><span class="sig-paren">(</span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">name_prefix</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">string</span></span><span class="p"><span class="pre">(</span></span><span class="p"><span class="pre">)</span></span>, <span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">include_self</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="k"><span class="pre">true</span></span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK5torch2nn6Module13named_modulesERKNSt6stringEb" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Returns an <code class="docutils literal notranslate"><a class="reference internal" href="classtorch_1_1_ordered_dict.html#classtorch_1_1_ordered_dict"><span class="std std-ref"><span class="pre">OrderedDict</span></span></a></code> of the submodules of this <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> (the entire submodule hierarchy) and their keys, and if <code class="docutils literal notranslate"><span class="pre">include_self</span></code> is true, also inserts a <code class="docutils literal notranslate"><span class="pre">shared_ptr</span></code> to this module in the first position. </p>
<p>If <code class="docutils literal notranslate"><span class="pre">name_prefix</span></code> is given, it is prepended to every key as <code class="docutils literal notranslate"><span class="pre">&lt;name_prefix&gt;.&lt;key&gt;</span></code> (and just <code class="docutils literal notranslate"><span class="pre">name_prefix</span></code> for the module itself).</p>
<p><p></p>
 </p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Only pass <cite>include_self</cite> as <cite>true</cite> if this <cite>Module</cite> is stored in a
<cite>shared_ptr</cite>! Otherwise an exception will be thrown. You may still call
this method with <cite>include_self</cite> set to false if your <cite>Module</cite> is not
stored in a <cite>shared_ptr</cite>.</p>
</div>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK5torch2nn6Module8childrenEv">
<span id="_CPPv3NK5torch2nn6Module8childrenEv"></span><span id="_CPPv2NK5torch2nn6Module8childrenEv"></span><span id="torch::nn::Module::childrenC"></span><span class="target" id="classtorch_1_1nn_1_1_module_1ab3d8e5f2bcc1387906fe5cbd0dd8316e"></span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">vector</span></span><span class="p"><span class="pre">&lt;</span></span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">shared_ptr</span></span><span class="p"><span class="pre">&lt;</span></span><a class="reference internal" href="#_CPPv4N5torch2nn6ModuleE" title="torch::nn::Module"><span class="n"><span class="pre">Module</span></span></a><span class="p"><span class="pre">&gt;</span></span><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">children</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK5torch2nn6Module8childrenEv" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Returns the direct submodules of this <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code>. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK5torch2nn6Module14named_childrenEv">
<span id="_CPPv3NK5torch2nn6Module14named_childrenEv"></span><span id="_CPPv2NK5torch2nn6Module14named_childrenEv"></span><span id="torch::nn::Module::named_childrenC"></span><span class="target" id="classtorch_1_1nn_1_1_module_1a03c7fd4a1be0614605f3fd3b3a563048"></span><a class="reference internal" href="classtorch_1_1_ordered_dict.html#_CPPv4I00EN5torch11OrderedDictE" title="torch::OrderedDict"><span class="n"><span class="pre">OrderedDict</span></span></a><span class="p"><span class="pre">&lt;</span></span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">string</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">shared_ptr</span></span><span class="p"><span class="pre">&lt;</span></span><a class="reference internal" href="#_CPPv4N5torch2nn6ModuleE" title="torch::nn::Module"><span class="n"><span class="pre">Module</span></span></a><span class="p"><span class="pre">&gt;</span></span><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">named_children</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK5torch2nn6Module14named_childrenEv" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Returns an <code class="docutils literal notranslate"><a class="reference internal" href="classtorch_1_1_ordered_dict.html#classtorch_1_1_ordered_dict"><span class="std std-ref"><span class="pre">OrderedDict</span></span></a></code> of the direct submodules of this <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> and their keys. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6Module5trainEb">
<span id="_CPPv3N5torch2nn6Module5trainEb"></span><span id="_CPPv2N5torch2nn6Module5trainEb"></span><span id="torch::nn::Module::train__b"></span><span class="target" id="classtorch_1_1nn_1_1_module_1a9d8c5525922794e8ae2ffc0c40372b09"></span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">train</span></span></span><span class="sig-paren">(</span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">on</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="k"><span class="pre">true</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N5torch2nn6Module5trainEb" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Enables “training” mode. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6Module4evalEv">
<span id="_CPPv3N5torch2nn6Module4evalEv"></span><span id="_CPPv2N5torch2nn6Module4evalEv"></span><span id="torch::nn::Module::eval"></span><span class="target" id="classtorch_1_1nn_1_1_module_1af0be79d2e17a200b5f69023ba6f02598"></span><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">eval</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N5torch2nn6Module4evalEv" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Calls train(false) to enable “eval” mode. </p>
<p>Do not override this method, override <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module_1a9d8c5525922794e8ae2ffc0c40372b09"><span class="std std-ref"><span class="pre">train()</span></span></a></code> instead. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK5torch2nn6Module11is_trainingEv">
<span id="_CPPv3NK5torch2nn6Module11is_trainingEv"></span><span id="_CPPv2NK5torch2nn6Module11is_trainingEv"></span><span id="torch::nn::Module::is_trainingC"></span><span class="target" id="classtorch_1_1nn_1_1_module_1a1b6cb063bb022e741ce9084ed591ad4f"></span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">is_training</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="k"><span class="pre">noexcept</span></span><a class="headerlink" href="#_CPPv4NK5torch2nn6Module11is_trainingEv" title="Permalink to this definition">#</a><br /></dt>
<dd><p>True if the module is in training mode. </p>
<p>Every <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> has a boolean associated with it that determines whether the <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> is currently in <em>training</em> mode (set via <code class="docutils literal notranslate"><span class="pre">.</span><a class="reference internal" href="#classtorch_1_1nn_1_1_module_1a9d8c5525922794e8ae2ffc0c40372b09"><span class="std std-ref"><span class="pre">train()</span></span></a></code>) or in <em>evaluation</em> (inference) mode (set via <code class="docutils literal notranslate"><span class="pre">.</span><a class="reference internal" href="#classtorch_1_1nn_1_1_module_1af0be79d2e17a200b5f69023ba6f02598"><span class="std std-ref"><span class="pre">eval()</span></span></a></code>). This property is exposed via <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module_1a1b6cb063bb022e741ce9084ed591ad4f"><span class="std std-ref"><span class="pre">is_training()</span></span></a></code>, and may be used by the implementation of a concrete module to modify its runtime behavior. See the <code class="docutils literal notranslate"><span class="pre">BatchNorm</span></code> or <code class="docutils literal notranslate"><a class="reference internal" href="classtorch_1_1nn_1_1_dropout.html#classtorch_1_1nn_1_1_dropout"><span class="std std-ref"><span class="pre">Dropout</span></span></a></code> modules for examples of <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code>s that use different code paths depending on this property. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6Module2toEN5torch6DeviceEN5torch5DtypeEb">
<span id="_CPPv3N5torch2nn6Module2toEN5torch6DeviceEN5torch5DtypeEb"></span><span id="_CPPv2N5torch2nn6Module2toEN5torch6DeviceEN5torch5DtypeEb"></span><span id="torch::nn::Module::to__torch::Device.torch::Dtype.b"></span><span class="target" id="classtorch_1_1nn_1_1_module_1a50706fc09d79c3af9c7348bd76d7da17"></span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">to</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">torch</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">Device</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">device</span></span>, <span class="n"><span class="pre">torch</span></span><span class="p"><span class="pre">::</span></span><a class="reference internal" href="typedef_namespacetorch_1a6369c7235ef5ea9c5fccbff406ad979e.html#_CPPv4N5torch5DtypeE" title="torch::Dtype"><span class="n"><span class="pre">Dtype</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">dtype</span></span>, <span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">non_blocking</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="k"><span class="pre">false</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N5torch2nn6Module2toEN5torch6DeviceEN5torch5DtypeEb" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Recursively casts all parameters to the given <code class="docutils literal notranslate"><span class="pre">dtype</span></code> and <code class="docutils literal notranslate"><span class="pre">device</span></code>. </p>
<p>If <code class="docutils literal notranslate"><span class="pre">non_blocking</span></code> is true and the source is in pinned memory and destination is on the GPU or vice versa, the copy is performed asynchronously with respect to the host. Otherwise, the argument has no effect. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6Module2toEN5torch5DtypeEb">
<span id="_CPPv3N5torch2nn6Module2toEN5torch5DtypeEb"></span><span id="_CPPv2N5torch2nn6Module2toEN5torch5DtypeEb"></span><span id="torch::nn::Module::to__torch::Dtype.b"></span><span class="target" id="classtorch_1_1nn_1_1_module_1aa0845eac80adb476a8efb38a25fdb8d6"></span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">to</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">torch</span></span><span class="p"><span class="pre">::</span></span><a class="reference internal" href="typedef_namespacetorch_1a6369c7235ef5ea9c5fccbff406ad979e.html#_CPPv4N5torch5DtypeE" title="torch::Dtype"><span class="n"><span class="pre">Dtype</span></span></a><span class="w"> </span><span class="n sig-param"><span class="pre">dtype</span></span>, <span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">non_blocking</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="k"><span class="pre">false</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N5torch2nn6Module2toEN5torch5DtypeEb" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Recursively casts all parameters to the given dtype. </p>
<p>If <code class="docutils literal notranslate"><span class="pre">non_blocking</span></code> is true and the source is in pinned memory and destination is on the GPU or vice versa, the copy is performed asynchronously with respect to the host. Otherwise, the argument has no effect. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6Module2toEN5torch6DeviceEb">
<span id="_CPPv3N5torch2nn6Module2toEN5torch6DeviceEb"></span><span id="_CPPv2N5torch2nn6Module2toEN5torch6DeviceEb"></span><span id="torch::nn::Module::to__torch::Device.b"></span><span class="target" id="classtorch_1_1nn_1_1_module_1a9e5a7719fac73ab52662f4ac21550043"></span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">to</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">torch</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">Device</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">device</span></span>, <span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">non_blocking</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="k"><span class="pre">false</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N5torch2nn6Module2toEN5torch6DeviceEb" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Recursively moves all parameters to the given device. </p>
<p>If <code class="docutils literal notranslate"><span class="pre">non_blocking</span></code> is true and the source is in pinned memory and destination is on the GPU or vice versa, the copy is performed asynchronously with respect to the host. Otherwise, the argument has no effect. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6Module9zero_gradEb">
<span id="_CPPv3N5torch2nn6Module9zero_gradEb"></span><span id="_CPPv2N5torch2nn6Module9zero_gradEb"></span><span id="torch::nn::Module::zero_grad__b"></span><span class="target" id="classtorch_1_1nn_1_1_module_1a97821fa3046e24716fd14b7e9bc84601"></span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">zero_grad</span></span></span><span class="sig-paren">(</span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">set_to_none</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="k"><span class="pre">true</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N5torch2nn6Module9zero_gradEb" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Recursively zeros out the <code class="docutils literal notranslate"><span class="pre">grad</span></code> value of each registered parameter. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I0EN5torch2nn6Module2asEPN10ModuleType13ContainedTypeEv">
<span id="_CPPv3I0EN5torch2nn6Module2asEv"></span><span id="_CPPv2I0EN5torch2nn6Module2asEv"></span><span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">ModuleType</span></span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="classtorch_1_1nn_1_1_module_1ab933f8f978b718c513fbc39ab70de97b"></span><a class="reference internal" href="#_CPPv4I0EN5torch2nn6Module2asEPN10ModuleType13ContainedTypeEv" title="torch::nn::Module::as::ModuleType"><span class="n"><span class="pre">ModuleType</span></span></a><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">ContainedType</span></span><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="sig-name descname"><span class="n"><span class="pre">as</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">noexcept</span></span><a class="headerlink" href="#_CPPv4I0EN5torch2nn6Module2asEPN10ModuleType13ContainedTypeEv" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Attempts to cast this <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> to the given <code class="docutils literal notranslate"><span class="pre">ModuleType</span></code>. </p>
<p>This method is useful when calling <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module_1a3e7bf8192a37c7e6593b5d1dd5d15903"><span class="std std-ref"><span class="pre">apply()</span></span></a></code>. <p><div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"> </span><span class="nf">initialize_weights</span><span class="p">(</span><span class="n">nn</span><span class="o">::</span><span class="n">Module</span><span class="o">&amp;</span><span class="w"> </span><span class="k">module</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">torch</span><span class="o">::</span><span class="n">NoGradGuard</span><span class="w"> </span><span class="n">no_grad</span><span class="p">;</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="o">*</span><span class="w"> </span><span class="n">linear</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">module</span><span class="p">.</span><span class="n">as</span><span class="o">&lt;</span><span class="n">nn</span><span class="o">::</span><span class="n">Linear</span><span class="o">&gt;</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">linear</span><span class="o">-&gt;</span><span class="n">weight</span><span class="p">.</span><span class="n">normal_</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="w"> </span><span class="mf">0.02</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>

<span class="n">MyModule</span><span class="w"> </span><span class="k">module</span><span class="p">;</span>
<span class="k">module</span><span class="o">-&gt;</span><span class="n">apply</span><span class="p">(</span><span class="n">initialize_weights</span><span class="p">);</span>
</pre></div>
</div>
</p>
 </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I0ENK5torch2nn6Module2asEPKN10ModuleType13ContainedTypeEv">
<span id="_CPPv3I0ENK5torch2nn6Module2asEv"></span><span id="_CPPv2I0ENK5torch2nn6Module2asEv"></span><span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">ModuleType</span></span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="classtorch_1_1nn_1_1_module_1ab7afebbed7aa93eed170c27ba08efce9"></span><span class="k"><span class="pre">const</span></span><span class="w"> </span><a class="reference internal" href="#_CPPv4I0ENK5torch2nn6Module2asEPKN10ModuleType13ContainedTypeEv" title="torch::nn::Module::as::ModuleType"><span class="n"><span class="pre">ModuleType</span></span></a><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">ContainedType</span></span><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="sig-name descname"><span class="n"><span class="pre">as</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="k"><span class="pre">noexcept</span></span><a class="headerlink" href="#_CPPv4I0ENK5torch2nn6Module2asEPKN10ModuleType13ContainedTypeEv" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Attempts to cast this <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> to the given <code class="docutils literal notranslate"><span class="pre">ModuleType</span></code>. </p>
<p>This method is useful when calling <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module_1a3e7bf8192a37c7e6593b5d1dd5d15903"><span class="std std-ref"><span class="pre">apply()</span></span></a></code>. <p></p>
 </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I00EN5torch2nn6Module2asEP10ModuleTypev">
<span id="_CPPv3I00EN5torch2nn6Module2asEv"></span><span id="_CPPv2I00EN5torch2nn6Module2asEv"></span><span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">ModuleType</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="n"><span class="pre">torch</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">detail</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">disable_if_module_holder_t</span></span><span class="p"><span class="pre">&lt;</span></span><a class="reference internal" href="#_CPPv4I00EN5torch2nn6Module2asEP10ModuleTypev" title="torch::nn::Module::as::ModuleType"><span class="n"><span class="pre">ModuleType</span></span></a><span class="p"><span class="pre">&gt;</span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="classtorch_1_1nn_1_1_module_1a4af0d4c015e6f453f57f078860f607ff"></span><a class="reference internal" href="#_CPPv4I00EN5torch2nn6Module2asEP10ModuleTypev" title="torch::nn::Module::as::ModuleType"><span class="n"><span class="pre">ModuleType</span></span></a><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="sig-name descname"><span class="n"><span class="pre">as</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">noexcept</span></span><a class="headerlink" href="#_CPPv4I00EN5torch2nn6Module2asEP10ModuleTypev" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Attempts to cast this <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> to the given <code class="docutils literal notranslate"><span class="pre">ModuleType</span></code>. </p>
<p>This method is useful when calling <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module_1a3e7bf8192a37c7e6593b5d1dd5d15903"><span class="std std-ref"><span class="pre">apply()</span></span></a></code>. <p><div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"> </span><span class="nf">initialize_weights</span><span class="p">(</span><span class="n">nn</span><span class="o">::</span><span class="n">Module</span><span class="o">&amp;</span><span class="w"> </span><span class="k">module</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">torch</span><span class="o">::</span><span class="n">NoGradGuard</span><span class="w"> </span><span class="n">no_grad</span><span class="p">;</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="o">*</span><span class="w"> </span><span class="n">linear</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">module</span><span class="p">.</span><span class="n">as</span><span class="o">&lt;</span><span class="n">nn</span><span class="o">::</span><span class="n">Linear</span><span class="o">&gt;</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">linear</span><span class="o">-&gt;</span><span class="n">weight</span><span class="p">.</span><span class="n">normal_</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="w"> </span><span class="mf">0.02</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>

<span class="n">MyModule</span><span class="w"> </span><span class="k">module</span><span class="p">;</span>
<span class="k">module</span><span class="p">.</span><span class="n">apply</span><span class="p">(</span><span class="n">initialize_weights</span><span class="p">);</span>
</pre></div>
</div>
</p>
 </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I00ENK5torch2nn6Module2asEPK10ModuleTypev">
<span id="_CPPv3I00ENK5torch2nn6Module2asEv"></span><span id="_CPPv2I00ENK5torch2nn6Module2asEv"></span><span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">ModuleType</span></span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="n"><span class="pre">torch</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">detail</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">disable_if_module_holder_t</span></span><span class="p"><span class="pre">&lt;</span></span><a class="reference internal" href="#_CPPv4I00ENK5torch2nn6Module2asEPK10ModuleTypev" title="torch::nn::Module::as::ModuleType"><span class="n"><span class="pre">ModuleType</span></span></a><span class="p"><span class="pre">&gt;</span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="classtorch_1_1nn_1_1_module_1a1bd17ad80f9b084d2a612142f962bc8a"></span><span class="k"><span class="pre">const</span></span><span class="w"> </span><a class="reference internal" href="#_CPPv4I00ENK5torch2nn6Module2asEPK10ModuleTypev" title="torch::nn::Module::as::ModuleType"><span class="n"><span class="pre">ModuleType</span></span></a><span class="w"> </span><span class="p"><span class="pre">*</span></span><span class="sig-name descname"><span class="n"><span class="pre">as</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="k"><span class="pre">noexcept</span></span><a class="headerlink" href="#_CPPv4I00ENK5torch2nn6Module2asEPK10ModuleTypev" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Attempts to cast this <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> to the given <code class="docutils literal notranslate"><span class="pre">ModuleType</span></code>. </p>
<p>This method is useful when calling <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module_1a3e7bf8192a37c7e6593b5d1dd5d15903"><span class="std std-ref"><span class="pre">apply()</span></span></a></code>. <p><div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"> </span><span class="nf">initialize_weights</span><span class="p">(</span><span class="n">nn</span><span class="o">::</span><span class="n">Module</span><span class="o">&amp;</span><span class="w"> </span><span class="k">module</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">torch</span><span class="o">::</span><span class="n">NoGradGuard</span><span class="w"> </span><span class="n">no_grad</span><span class="p">;</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="o">*</span><span class="w"> </span><span class="n">linear</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">module</span><span class="p">.</span><span class="n">as</span><span class="o">&lt;</span><span class="n">nn</span><span class="o">::</span><span class="n">Linear</span><span class="o">&gt;</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">linear</span><span class="o">-&gt;</span><span class="n">weight</span><span class="p">.</span><span class="n">normal_</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="w"> </span><span class="mf">0.02</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>

<span class="n">MyModule</span><span class="w"> </span><span class="k">module</span><span class="p">;</span>
<span class="k">module</span><span class="p">.</span><span class="n">apply</span><span class="p">(</span><span class="n">initialize_weights</span><span class="p">);</span>
</pre></div>
</div>
</p>
 </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK5torch2nn6Module4saveERN9serialize13OutputArchiveE">
<span id="_CPPv3NK5torch2nn6Module4saveERN9serialize13OutputArchiveE"></span><span id="_CPPv2NK5torch2nn6Module4saveERN9serialize13OutputArchiveE"></span><span id="torch::nn::Module::save__serialize::OutputArchiveRC"></span><span class="target" id="classtorch_1_1nn_1_1_module_1a0768a11c8809bf9b1e6ee0e6784f5eb0"></span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">save</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">serialize</span></span><span class="p"><span class="pre">::</span></span><a class="reference internal" href="classtorch_1_1serialize_1_1_output_archive.html#_CPPv4N5torch9serialize13OutputArchiveE" title="torch::serialize::OutputArchive"><span class="n"><span class="pre">OutputArchive</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">archive</span></span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK5torch2nn6Module4saveERN9serialize13OutputArchiveE" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Serializes the <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> into the given <code class="docutils literal notranslate"><span class="pre">OutputArchive</span></code>. </p>
<p>If the <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> contains unserializable submodules (e.g. <code class="docutils literal notranslate"><a class="reference internal" href="classtorch_1_1nn_1_1_functional.html#classtorch_1_1nn_1_1_functional"><span class="std std-ref"><span class="pre">nn::Functional</span></span></a></code>), those submodules are skipped when serializing. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6Module4loadERN9serialize12InputArchiveE">
<span id="_CPPv3N5torch2nn6Module4loadERN9serialize12InputArchiveE"></span><span id="_CPPv2N5torch2nn6Module4loadERN9serialize12InputArchiveE"></span><span id="torch::nn::Module::load__serialize::InputArchiveR"></span><span class="target" id="classtorch_1_1nn_1_1_module_1adb27486a7bd00bd53dd6f4146a9729e0"></span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">load</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">serialize</span></span><span class="p"><span class="pre">::</span></span><a class="reference internal" href="classtorch_1_1serialize_1_1_input_archive.html#_CPPv4N5torch9serialize12InputArchiveE" title="torch::serialize::InputArchive"><span class="n"><span class="pre">InputArchive</span></span></a><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">archive</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N5torch2nn6Module4loadERN9serialize12InputArchiveE" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Deserializes the <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> from the given <code class="docutils literal notranslate"><span class="pre">InputArchive</span></code>. </p>
<p>If the <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> contains unserializable submodules (e.g. <code class="docutils literal notranslate"><a class="reference internal" href="classtorch_1_1nn_1_1_functional.html#classtorch_1_1nn_1_1_functional"><span class="std std-ref"><span class="pre">nn::Functional</span></span></a></code>), we don’t check the existence of those submodules in the <code class="docutils literal notranslate"><span class="pre">InputArchive</span></code> when deserializing. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK5torch2nn6Module12pretty_printERNSt7ostreamE">
<span id="_CPPv3NK5torch2nn6Module12pretty_printERNSt7ostreamE"></span><span id="_CPPv2NK5torch2nn6Module12pretty_printERNSt7ostreamE"></span><span id="torch::nn::Module::pretty_print__osRC"></span><span class="target" id="classtorch_1_1nn_1_1_module_1ac339dba1788dac40afca87f329d58fa0"></span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">pretty_print</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">ostream</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">stream</span></span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK5torch2nn6Module12pretty_printERNSt7ostreamE" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Streams a pretty representation of the <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> into the given <code class="docutils literal notranslate"><span class="pre">stream</span></code>. </p>
<p>By default, this representation will be the name of the module (taken from <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module_1a09407fc8e8eca674c18dd4436f1a7ad2"><span class="std std-ref"><span class="pre">name()</span></span></a></code>), followed by a recursive pretty print of all of the <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code>’s submodules.</p>
<p>Override this method to change the pretty print. The input <code class="docutils literal notranslate"><span class="pre">stream</span></code> should be returned from the method, to allow easy chaining. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4NK5torch2nn6Module15is_serializableEv">
<span id="_CPPv3NK5torch2nn6Module15is_serializableEv"></span><span id="_CPPv2NK5torch2nn6Module15is_serializableEv"></span><span id="torch::nn::Module::is_serializableC"></span><span class="target" id="classtorch_1_1nn_1_1_module_1a1f46c778c11735d9141e156d4eb2f0b3"></span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">is_serializable</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><span class="w"> </span><span class="k"><span class="pre">const</span></span><a class="headerlink" href="#_CPPv4NK5torch2nn6Module15is_serializableEv" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Returns whether the <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code> is serializable. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6Module18register_parameterENSt6stringE6Tensorb">
<span id="_CPPv3N5torch2nn6Module18register_parameterENSt6stringE6Tensorb"></span><span id="_CPPv2N5torch2nn6Module18register_parameterENSt6stringE6Tensorb"></span><span id="torch::nn::Module::register_parameter__ss.Tensor.b"></span><span class="target" id="classtorch_1_1nn_1_1_module_1afd2bb60b2453f356589f3ec3188ed9d0"></span><span class="n"><span class="pre">Tensor</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="sig-name descname"><span class="n"><span class="pre">register_parameter</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">name</span></span>, <span class="n"><span class="pre">Tensor</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">tensor</span></span>, <span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">requires_grad</span></span><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="k"><span class="pre">true</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N5torch2nn6Module18register_parameterENSt6stringE6Tensorb" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Registers a parameter with this <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code>. </p>
<p>A parameter should be any gradient-recording tensor used in the implementation of your <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code>. Registering it makes it available to methods such as <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module_1a37b0008259770153722e6ecdb8ffade2"><span class="std std-ref"><span class="pre">parameters()</span></span></a></code>, <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module_1afe74ce9f020f9f46527689539b4b4f66"><span class="std std-ref"><span class="pre">clone()</span></span></a></code> or <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module_1a50706fc09d79c3af9c7348bd76d7da17"><span class="std std-ref"><span class="pre">to()</span></span></a><span class="pre">.</span></code></p>
<p>Note that registering an undefined Tensor (e.g. <code class="docutils literal notranslate"><span class="pre">module.register_parameter(&quot;param&quot;,</span> <span class="pre">Tensor())</span></code>) is allowed, and is equivalent to <code class="docutils literal notranslate"><span class="pre">module.register_parameter(&quot;param&quot;,</span> <span class="pre">None)</span></code> in Python API.</p>
<p><p><div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">MyModule</span><span class="o">::</span><span class="n">MyModule</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">weight_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">register_parameter</span><span class="p">(</span><span class="s">&quot;weight&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">randn</span><span class="p">({</span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="p">}));</span>
<span class="p">}</span>
</pre></div>
</div>
</p>
 </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6Module15register_bufferENSt6stringE6Tensor">
<span id="_CPPv3N5torch2nn6Module15register_bufferENSt6stringE6Tensor"></span><span id="_CPPv2N5torch2nn6Module15register_bufferENSt6stringE6Tensor"></span><span id="torch::nn::Module::register_buffer__ss.Tensor"></span><span class="target" id="classtorch_1_1nn_1_1_module_1af27bf7a902f9eb5d1af31126e33080c7"></span><span class="n"><span class="pre">Tensor</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="sig-name descname"><span class="n"><span class="pre">register_buffer</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">name</span></span>, <span class="n"><span class="pre">Tensor</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">tensor</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N5torch2nn6Module15register_bufferENSt6stringE6Tensor" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Registers a buffer with this <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code>. </p>
<p>A buffer is intended to be state in your module that does not record gradients, such as running statistics. Registering it makes it available to methods such as <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module_1a4fcf6732e0780b864678d6adf31ebdd1"><span class="std std-ref"><span class="pre">buffers()</span></span></a></code>, <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module_1afe74ce9f020f9f46527689539b4b4f66"><span class="std std-ref"><span class="pre">clone()</span></span></a></code> or `to().</p>
<p><p><div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">MyModule</span><span class="o">::</span><span class="n">MyModule</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">mean_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">register_buffer</span><span class="p">(</span><span class="s">&quot;mean&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">empty</span><span class="p">({</span><span class="n">num_features_</span><span class="p">}));</span>
<span class="p">}</span>
</pre></div>
</div>
</p>
 </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I0EN5torch2nn6Module15register_moduleENSt10shared_ptrI10ModuleTypeEENSt6stringENSt10shared_ptrI10ModuleTypeEE">
<span id="_CPPv3I0EN5torch2nn6Module15register_moduleENSt6stringENSt10shared_ptrI10ModuleTypeEE"></span><span id="_CPPv2I0EN5torch2nn6Module15register_moduleENSt6stringENSt10shared_ptrI10ModuleTypeEE"></span><span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">ModuleType</span></span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="classtorch_1_1nn_1_1_module_1a505feb18878e17ed60038c4ed87406f5"></span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">shared_ptr</span></span><span class="p"><span class="pre">&lt;</span></span><a class="reference internal" href="#_CPPv4I0EN5torch2nn6Module15register_moduleENSt10shared_ptrI10ModuleTypeEENSt6stringENSt10shared_ptrI10ModuleTypeEE" title="torch::nn::Module::register_module::ModuleType"><span class="n"><span class="pre">ModuleType</span></span></a><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">register_module</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">name</span></span>, <span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">shared_ptr</span></span><span class="p"><span class="pre">&lt;</span></span><a class="reference internal" href="#_CPPv4I0EN5torch2nn6Module15register_moduleENSt10shared_ptrI10ModuleTypeEENSt6stringENSt10shared_ptrI10ModuleTypeEE" title="torch::nn::Module::register_module::ModuleType"><span class="n"><span class="pre">ModuleType</span></span></a><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">module</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I0EN5torch2nn6Module15register_moduleENSt10shared_ptrI10ModuleTypeEENSt6stringENSt10shared_ptrI10ModuleTypeEE" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Registers a submodule with this <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code>. </p>
<p>Registering a module makes it available to methods such as <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module_1a90792e81478857f8eb3573d6276b5632"><span class="std std-ref"><span class="pre">modules()</span></span></a></code>, <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module_1afe74ce9f020f9f46527689539b4b4f66"><span class="std std-ref"><span class="pre">clone()</span></span></a></code> or <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module_1a50706fc09d79c3af9c7348bd76d7da17"><span class="std std-ref"><span class="pre">to()</span></span></a></code>.</p>
<p><p><div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">MyModule</span><span class="o">::</span><span class="n">MyModule</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">submodule_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">register_module</span><span class="p">(</span><span class="s">&quot;linear&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">nn</span><span class="o">::</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">));</span>
<span class="p">}</span>
</pre></div>
</div>
</p>
 </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I0EN5torch2nn6Module15register_moduleENSt10shared_ptrI10ModuleTypeEENSt6stringE12ModuleHolderI10ModuleTypeE">
<span id="_CPPv3I0EN5torch2nn6Module15register_moduleENSt6stringE12ModuleHolderI10ModuleTypeE"></span><span id="_CPPv2I0EN5torch2nn6Module15register_moduleENSt6stringE12ModuleHolderI10ModuleTypeE"></span><span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">ModuleType</span></span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="classtorch_1_1nn_1_1_module_1ae21020d776f84f91ebc8679da84c3fc7"></span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">shared_ptr</span></span><span class="p"><span class="pre">&lt;</span></span><a class="reference internal" href="#_CPPv4I0EN5torch2nn6Module15register_moduleENSt10shared_ptrI10ModuleTypeEENSt6stringE12ModuleHolderI10ModuleTypeE" title="torch::nn::Module::register_module::ModuleType"><span class="n"><span class="pre">ModuleType</span></span></a><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">register_module</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">name</span></span>, <a class="reference internal" href="classtorch_1_1nn_1_1_module_holder.html#_CPPv4I0EN5torch2nn12ModuleHolderE" title="torch::nn::ModuleHolder"><span class="n"><span class="pre">ModuleHolder</span></span></a><span class="p"><span class="pre">&lt;</span></span><a class="reference internal" href="#_CPPv4I0EN5torch2nn6Module15register_moduleENSt10shared_ptrI10ModuleTypeEENSt6stringE12ModuleHolderI10ModuleTypeE" title="torch::nn::Module::register_module::ModuleType"><span class="n"><span class="pre">ModuleType</span></span></a><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">module_holder</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I0EN5torch2nn6Module15register_moduleENSt10shared_ptrI10ModuleTypeEENSt6stringE12ModuleHolderI10ModuleTypeE" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Registers a submodule with this <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code>. </p>
<p>This method deals with <code class="docutils literal notranslate"><a class="reference internal" href="classtorch_1_1nn_1_1_module_holder.html#classtorch_1_1nn_1_1_module_holder"><span class="std std-ref"><span class="pre">ModuleHolder</span></span></a></code>s.</p>
<p>Registering a module makes it available to methods such as <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module_1a90792e81478857f8eb3573d6276b5632"><span class="std std-ref"><span class="pre">modules()</span></span></a></code>, <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module_1afe74ce9f020f9f46527689539b4b4f66"><span class="std std-ref"><span class="pre">clone()</span></span></a></code> or <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module_1a50706fc09d79c3af9c7348bd76d7da17"><span class="std std-ref"><span class="pre">to()</span></span></a></code>.</p>
<p><p><div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">MyModule</span><span class="o">::</span><span class="n">MyModule</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">submodule_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">register_module</span><span class="p">(</span><span class="s">&quot;linear&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">nn</span><span class="o">::</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">));</span>
<span class="p">}</span>
</pre></div>
</div>
</p>
 </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I0EN5torch2nn6Module14replace_moduleENSt10shared_ptrI10ModuleTypeEERKNSt6stringENSt10shared_ptrI10ModuleTypeEE">
<span id="_CPPv3I0EN5torch2nn6Module14replace_moduleERKNSt6stringENSt10shared_ptrI10ModuleTypeEE"></span><span id="_CPPv2I0EN5torch2nn6Module14replace_moduleERKNSt6stringENSt10shared_ptrI10ModuleTypeEE"></span><span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">ModuleType</span></span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="classtorch_1_1nn_1_1_module_1ad19516c3acfff03e65f5ec8194b0c1c4"></span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">shared_ptr</span></span><span class="p"><span class="pre">&lt;</span></span><a class="reference internal" href="#_CPPv4I0EN5torch2nn6Module14replace_moduleENSt10shared_ptrI10ModuleTypeEERKNSt6stringENSt10shared_ptrI10ModuleTypeEE" title="torch::nn::Module::replace_module::ModuleType"><span class="n"><span class="pre">ModuleType</span></span></a><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">replace_module</span></span></span><span class="sig-paren">(</span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">name</span></span>, <span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">shared_ptr</span></span><span class="p"><span class="pre">&lt;</span></span><a class="reference internal" href="#_CPPv4I0EN5torch2nn6Module14replace_moduleENSt10shared_ptrI10ModuleTypeEERKNSt6stringENSt10shared_ptrI10ModuleTypeEE" title="torch::nn::Module::replace_module::ModuleType"><span class="n"><span class="pre">ModuleType</span></span></a><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">module</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I0EN5torch2nn6Module14replace_moduleENSt10shared_ptrI10ModuleTypeEERKNSt6stringENSt10shared_ptrI10ModuleTypeEE" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Replaces a registered submodule with this <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code>. </p>
<p>This takes care of the registration, if you used submodule members, you should module-&gt;submodule_ = module-&gt;replace_module(“linear”, <a class="reference internal" href="classtorch_1_1nn_1_1_linear.html#classtorch_1_1nn_1_1_linear"><span class="std std-ref">torch::nn::Linear(3, 4)</span></a>); It only works when a module of the name is already registered.</p>
<p>This is useful for replacing a module after initialization, e.g. for finetuning. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4I0EN5torch2nn6Module14replace_moduleENSt10shared_ptrI10ModuleTypeEERKNSt6stringE12ModuleHolderI10ModuleTypeE">
<span id="_CPPv3I0EN5torch2nn6Module14replace_moduleERKNSt6stringE12ModuleHolderI10ModuleTypeE"></span><span id="_CPPv2I0EN5torch2nn6Module14replace_moduleERKNSt6stringE12ModuleHolderI10ModuleTypeE"></span><span class="k"><span class="pre">template</span></span><span class="p"><span class="pre">&lt;</span></span><span class="k"><span class="pre">typename</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">ModuleType</span></span></span><span class="p"><span class="pre">&gt;</span></span><br /><span class="target" id="classtorch_1_1nn_1_1_module_1aa1afbd932a9d4075676507d133b5bcc4"></span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">shared_ptr</span></span><span class="p"><span class="pre">&lt;</span></span><a class="reference internal" href="#_CPPv4I0EN5torch2nn6Module14replace_moduleENSt10shared_ptrI10ModuleTypeEERKNSt6stringE12ModuleHolderI10ModuleTypeE" title="torch::nn::Module::replace_module::ModuleType"><span class="n"><span class="pre">ModuleType</span></span></a><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">replace_module</span></span></span><span class="sig-paren">(</span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">name</span></span>, <a class="reference internal" href="classtorch_1_1nn_1_1_module_holder.html#_CPPv4I0EN5torch2nn12ModuleHolderE" title="torch::nn::ModuleHolder"><span class="n"><span class="pre">ModuleHolder</span></span></a><span class="p"><span class="pre">&lt;</span></span><a class="reference internal" href="#_CPPv4I0EN5torch2nn6Module14replace_moduleENSt10shared_ptrI10ModuleTypeEERKNSt6stringE12ModuleHolderI10ModuleTypeE" title="torch::nn::Module::replace_module::ModuleType"><span class="n"><span class="pre">ModuleType</span></span></a><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="n sig-param"><span class="pre">module_holder</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4I0EN5torch2nn6Module14replace_moduleENSt10shared_ptrI10ModuleTypeEERKNSt6stringE12ModuleHolderI10ModuleTypeE" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Replaces a registered submodule with this <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code>. </p>
<p>This method deals with <code class="docutils literal notranslate"><a class="reference internal" href="classtorch_1_1nn_1_1_module_holder.html#classtorch_1_1nn_1_1_module_holder"><span class="std std-ref"><span class="pre">ModuleHolder</span></span></a></code>s.</p>
<p>This takes care of the registration, if you used submodule members, you should module-&gt;submodule_ = module-&gt;replace_module(“linear”, linear_holder); It only works when a module of the name is already registered.</p>
<p>This is useful for replacing a module after initialization, e.g. for finetuning. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6Module17unregister_moduleERKNSt6stringE">
<span id="_CPPv3N5torch2nn6Module17unregister_moduleERKNSt6stringE"></span><span id="_CPPv2N5torch2nn6Module17unregister_moduleERKNSt6stringE"></span><span id="torch::nn::Module::unregister_module__ssCR"></span><span class="target" id="classtorch_1_1nn_1_1_module_1af136db0c676cd7238957200bf7a6cbe8"></span><span class="kt"><span class="pre">void</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">unregister_module</span></span></span><span class="sig-paren">(</span><span class="k"><span class="pre">const</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">string</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">name</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N5torch2nn6Module17unregister_moduleERKNSt6stringE" title="Permalink to this definition">#</a><br /></dt>
<dd><p>Unregisters a submodule from this <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code>. </p>
<p>If there is no such module with <code class="docutils literal notranslate"><span class="pre">name</span></code> an exception is thrown. </p>
</dd></dl>

</div>
<div class="breathe-sectiondef docutils container">
<p class="breathe-sectiondef-title rubric" id="breathe-section-title-protected-functions">Protected Functions</p>
<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6Module25_forward_has_default_argsEv">
<span id="_CPPv3N5torch2nn6Module25_forward_has_default_argsEv"></span><span id="_CPPv2N5torch2nn6Module25_forward_has_default_argsEv"></span><span id="torch::nn::Module::_forward_has_default_args"></span><span class="target" id="classtorch_1_1nn_1_1_module_1a8c27c6692037de9fdcbf8fd74566bf9a"></span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="kt"><span class="pre">bool</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">_forward_has_default_args</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N5torch2nn6Module25_forward_has_default_argsEv" title="Permalink to this definition">#</a><br /></dt>
<dd><p>The following three functions allow a module with default arguments in its forward method to be used in a <a class="reference internal" href="classtorch_1_1nn_1_1_sequential.html#classtorch_1_1nn_1_1_sequential"><span class="std std-ref">Sequential</span></a> module. </p>
<p>You should NEVER override these functions manually. Instead, you should use the <code class="docutils literal notranslate"><span class="pre">FORWARD_HAS_DEFAULT_ARGS</span></code> macro. </p>
</dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6Module26_forward_num_required_argsEv">
<span id="_CPPv3N5torch2nn6Module26_forward_num_required_argsEv"></span><span id="_CPPv2N5torch2nn6Module26_forward_num_required_argsEv"></span><span id="torch::nn::Module::_forward_num_required_args"></span><span class="target" id="classtorch_1_1nn_1_1_module_1a720585ad87eb93a419b1343a17b8fd47"></span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="kt"><span class="pre">unsigned</span></span><span class="w"> </span><span class="kt"><span class="pre">int</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">_forward_num_required_args</span></span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N5torch2nn6Module26_forward_num_required_argsEv" title="Permalink to this definition">#</a><br /></dt>
<dd></dd></dl>

<dl class="cpp function">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6Module30_forward_populate_default_argsERRNSt6vectorI8AnyValueEE">
<span id="_CPPv3N5torch2nn6Module30_forward_populate_default_argsERRNSt6vectorI8AnyValueEE"></span><span id="_CPPv2N5torch2nn6Module30_forward_populate_default_argsERRNSt6vectorI8AnyValueEE"></span><span id="torch::nn::Module::_forward_populate_default_args__std::vector:AnyValue:RR"></span><span class="target" id="classtorch_1_1nn_1_1_module_1a1a1015a228cac85e36f0edcc0d402737"></span><span class="k"><span class="pre">inline</span></span><span class="w"> </span><span class="k"><span class="pre">virtual</span></span><span class="w"> </span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">vector</span></span><span class="p"><span class="pre">&lt;</span></span><a class="reference internal" href="classtorch_1_1nn_1_1_any_value.html#_CPPv4N5torch2nn8AnyValueE" title="torch::nn::AnyValue"><span class="n"><span class="pre">AnyValue</span></span></a><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">_forward_populate_default_args</span></span></span><span class="sig-paren">(</span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">vector</span></span><span class="p"><span class="pre">&lt;</span></span><a class="reference internal" href="classtorch_1_1nn_1_1_any_value.html#_CPPv4N5torch2nn8AnyValueE" title="torch::nn::AnyValue"><span class="n"><span class="pre">AnyValue</span></span></a><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="p"><span class="pre">&amp;</span></span><span class="p"><span class="pre">&amp;</span></span><span class="n sig-param"><span class="pre">arguments</span></span><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv4N5torch2nn6Module30_forward_populate_default_argsERRNSt6vectorI8AnyValueEE" title="Permalink to this definition">#</a><br /></dt>
<dd></dd></dl>

</div>
<div class="breathe-sectiondef docutils container">
<p class="breathe-sectiondef-title rubric" id="breathe-section-title-protected-attributes">Protected Attributes</p>
<dl class="cpp var">
<dt class="sig sig-object cpp" id="_CPPv4N5torch2nn6Module11parameters_E">
<span id="_CPPv3N5torch2nn6Module11parameters_E"></span><span id="_CPPv2N5torch2nn6Module11parameters_E"></span><span id="torch::nn::Module::parameters___OrderedDict:ss.Tensor:"></span><span class="target" id="classtorch_1_1nn_1_1_module_1ac02e3ddfee45e72a89c7d6befcc9385c"></span><a class="reference internal" href="classtorch_1_1_ordered_dict.html#_CPPv4I00EN5torch11OrderedDictE" title="torch::OrderedDict"><span class="n"><span class="pre">OrderedDict</span></span></a><span class="p"><span class="pre">&lt;</span></span><span class="n"><span class="pre">std</span></span><span class="p"><span class="pre">::</span></span><span class="n"><span class="pre">string</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span><span class="p"><span class="pre">&gt;</span></span><span class="w"> </span><span class="sig-name descname"><span class="n"><span class="pre">parameters_</span></span></span><a class="headerlink" href="#_CPPv4N5torch2nn6Module11parameters_E" title="Permalink to this definition">#</a><br /></dt>
<dd><p>The registered parameters of this <code class="docutils literal notranslate"><a class="reference internal" href="#classtorch_1_1nn_1_1_module"><span class="std std-ref"><span class="pre">Module</span></span></a></code>. </p>
<p>Inorder to access parameters_ in <a class="reference internal" href="classtorch_1_1nn_1_1_parameter_dict.html#classtorch_1_1nn_1_1_parameter_dict"><span class="std std-ref">ParameterDict</span></a> and <a class="reference internal" href="classtorch_1_1nn_1_1_parameter_list.html#classtorch_1_1nn_1_1_parameter_list"><span class="std std-ref">ParameterList</span></a> </p>
</dd></dl>

</div>
</dd></dl>

</div>
</div>


                </article>
              
  </article>
  
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn"
            onclick="openGitHubIssue()"
            data-bs-title="Create a GitHub Issue"
            data-bs-placement="bottom"
            data-bs-toggle="tooltip"
            data-gtm="feedback-btn-click">Send Feedback
    </button>
  </div>
</div>

<div class="prev-next-area">
    <a class="left-prev"
       href="classtorch_1_1nn_1_1_mish_impl.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Class MishImpl</p>
      </div>
    </a>
    <a class="right-next"
       href="classtorch_1_1nn_1_1_module_dict.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Class ModuleDict</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>

<div class="footer-info">
  <p class="copyright">
    
      
        © Copyright PyTorch Contributors.
      
      <br/>
    
  </p>

  <p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="classtorch_1_1nn_1_1_mish_impl.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Class MishImpl</p>
      </div>
    </a>
    <a class="right-next"
       href="classtorch_1_1nn_1_1_module_dict.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Class ModuleDict</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
    
       <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inheritance-relationships">Inheritance Relationships</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#base-type">Base Type</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#derived-types">Derived Types</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#class-documentation">Class Documentation</a></li>
</ul>
  </nav></div>
    
       <div class="sidebar-secondary-item">
    <div class="tocsection sourcelink">
      <a href="../_sources/api/classtorch_1_1nn_1_1_module.rst.txt">
        <i class="fa-solid fa-file-lines"></i> Show Source
      </a>
    </div>
</div>
    




<div class="sidebar-secondary-item">
  <div class="sidebar-heading">PyTorch Libraries</div>
  <ul style="list-style-type: none; padding: 0; padding-bottom: 80px;">
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/ao" style="color: var(--pst-color-text-muted)">torchao</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchrec" style="color: var(--pst-color-text-muted)">torchrec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchft" style="color: var(--pst-color-text-muted)">torchft</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchcodec" style="color: var(--pst-color-text-muted)">TorchCodec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/vision" style="color: var(--pst-color-text-muted)">torchvision</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/executorch" style="color: var(--pst-color-text-muted)">ExecuTorch</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/xla" style="color: var(--pst-color-text-muted)">PyTorch on XLA Devices</a></li>
  
  </ul>
</div>

</div>
</div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4">
        <h2>Docs</h2>
        <p>Access comprehensive developer documentation for PyTorch</p>
        <a class="with-right-arrow" href="https://docs.pytorch.org/docs/stable/index.html">View Docs</a>
      </div>

      <div class="col-md-4">
        <h2>Tutorials</h2>
        <p>Get in-depth tutorials for beginners and advanced developers</p>
        <a class="with-right-arrow" href="https://docs.pytorch.org/tutorials">View Tutorials</a>
      </div>

      <div class="col-md-4">
        <h2>Resources</h2>
        <p>Find development resources and get your questions answered</p>
        <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
      </div>
    </div>
  </div>
</div>

<footer class="site-footer">
  <div class="container footer-container">

    
    <div class="newsletter" id="newsletter">

      <p class="newsletter__title is-style-max-width-800"><strong>Stay in touch</strong> for updates, event info, and
        the latest news</p>


      <script charset="utf-8" type="text/javascript" src="//js.hsforms.net/forms/embed/v2.js"></script>
      <script>
        hbspt.forms.create({
          region: "na1",
          portalId: "8112310",
          formId: "2fb2231c-000b-4ec5-88a0-1ab242549c9e"
        });
      </script>


      <p class="newsletter__privacy">By submitting this form, I consent to receive marketing emails from the LF and its
        projects regarding their events, training, research, developments, and related announcements. I understand that
        I can unsubscribe at any time using the links in the footers of the emails I receive. <a
          href="https://www.linuxfoundation.org/privacy/">Privacy Policy</a>.</p>

    </div>
    

    <div class="lf-grid">
      <ul class="social-links">
        <li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-0.51 -0.26 26.45 26.45" aria-label="Facebook">
              <path fill="currentColor"
                d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z" />
            </svg>
          </a></li>
        <li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 300 300" aria-label="X">
              <path fill="currentColor"
                d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66" />
            </svg>
          </a></li>
        <li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0.21 0.27 34.45 25.07" aria-label="YouTube">
              <path fill="currentColor"
                d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z" />
            </svg>
          </a></li>
        <li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-10.23 -10.23 531.96 531.96" aria-label="LinkedIn">
              <rect width="512" height="512" rx="0" fill="currentColor" />
              <circle fill="#000" cx="142" cy="138" r="37" />
              <path stroke="#000" stroke-width="66" d="M244 194v198M142 194v198" />
              <path fill="#000"
                d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32" />
            </svg>
          </a></li>
        <li><a href="https://pytorch.slack.com" target="_blank" title="PyTorch Slack">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.16 -0.03 21.19 21.19" aria-label="Slack">
              <path fill="currentColor"
                d="M4.896 13.27a2.147 2.147 0 0 1-2.141 2.142A2.147 2.147 0 0 1 .613 13.27c0-1.178.963-2.141 2.142-2.141h2.141v2.141zm1.08 0c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.363a2.147 2.147 0 0 1-2.142 2.141 2.147 2.147 0 0 1-2.141-2.142V13.27zm2.141-8.6a2.147 2.147 0 0 1-2.141-2.14c0-1.18.962-2.142 2.141-2.142s2.142.963 2.142 2.141v2.142H8.117zm0 1.08c1.179 0 2.141.962 2.141 2.141a2.147 2.147 0 0 1-2.141 2.142H2.755A2.147 2.147 0 0 1 .613 7.89c0-1.179.963-2.141 2.142-2.141h5.362zm8.599 2.141c0-1.179.963-2.141 2.141-2.141 1.179 0 2.143.962 2.143 2.14a2.147 2.147 0 0 1-2.142 2.142h-2.141V7.89zm-1.08 0a2.147 2.147 0 0 1-2.141 2.142 2.147 2.147 0 0 1-2.141-2.142V2.53c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.362zm-2.141 8.6c1.179 0 2.142.962 2.142 2.14a2.147 2.147 0 0 1-2.142 2.142 2.147 2.147 0 0 1-2.141-2.141V16.49h2.141zm0-1.08a2.147 2.147 0 0 1-2.141-2.141c0-1.179.962-2.142 2.141-2.142h5.362c1.179 0 2.142.963 2.142 2.142a2.147 2.147 0 0 1-2.142 2.142h-5.362z">
              </path>
            </svg>
          </a></li>
        <li><a href="https://pytorch.org/wechat" title="PyTorch on WeChat">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.14 -0.17 38.02 33.02" aria-label="WeChat">
              <path fill="currentColor"
                d="M26.289 10.976a12.972 12.972 0 0 0-8.742 3.53 10.386 10.386 0 0 0-3.224 8.795c-1.326-.164-2.535-.345-3.75-.448a2.332 2.332 0 0 0-1.273.216c-1.18.666-2.311 1.418-3.652 2.255.246-1.112.405-2.087.687-3.024a1.15 1.15 0 0 0-.523-1.52C1.737 17.902.02 13.601 1.307 9.165c1.189-4.1 4.11-6.587 8.077-7.884A13.54 13.54 0 0 1 24.18 5.617a10.135 10.135 0 0 1 2.109 5.359zM10.668 9.594a1.564 1.564 0 0 0-2.095-1.472 1.52 1.52 0 0 0-.895 1.964 1.502 1.502 0 0 0 1.391.966 1.545 1.545 0 0 0 1.598-1.46v.002zm8.15-1.566a1.567 1.567 0 0 0-1.528 1.543 1.528 1.528 0 0 0 1.571 1.492 1.52 1.52 0 0 0 1.375-2.117 1.518 1.518 0 0 0-1.415-.919l-.003.001z">
              </path>
              <path fill="currentColor"
                d="M33.914 32.137c-1.075-.478-2.062-1.196-3.11-1.306-1.049-.11-2.145.494-3.24.605a10.821 10.821 0 0 1-8.781-2.864c-4.682-4.33-4.013-10.97 1.403-14.518 4.811-3.154 11.874-2.102 15.268 2.273a8.671 8.671 0 0 1-1.002 12.095c-1.046.929-1.422 1.693-.751 2.917.102.257.174.525.213.798zM21.68 20.292a1.264 1.264 0 1 0 .01-2.528 1.264 1.264 0 0 0-.01 2.528zm7.887-2.526a1.266 1.266 0 0 0-1.256 1.21 1.247 1.247 0 1 0 1.256-1.21z">
              </path>
            </svg>
          </a></li>
      </ul>
    </div>

    <div class="privacy-policy">
      <div class="copyright">
        
        <p>
          &copy; PyTorch. Copyright © The Linux Foundation®. All rights reserved. The Linux Foundation has registered
          trademarks and uses trademarks. For more information, including terms of use, privacy policy, and trademark
          usage, please see our <a href="https://www.linuxfoundation.org/legal/policies">Policies</a> page. <a
            href="https://www.linuxfoundation.org/trademark-usage">Trademark Usage</a>. <a
            href="http://www.linuxfoundation.org/privacy">Privacy Policy</a>.
        </p>
        
      </div>
    </div>


  </div>
</footer>

<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/img/pytorch-x.svg">
  </div>
</div>
  
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright PyTorch Contributors.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 5.3.0.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  <script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "Class Module",
       "headline": "Class Module",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
       "url": "/api/classtorch_1_1nn_1_1_module.html",
       "articleBody": "Class Module# Defined in File module.h Page Contents Inheritance Relationships Base Type Derived Types Class Documentation Inheritance Relationships# Base Type# public std::enable_shared_from_this\u003c Module \u003e Derived Types# public torch::nn::Cloneable\u003c SoftshrinkImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c PReLUImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c LogSoftmaxImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c L1LossImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c SequentialImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c HardshrinkImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c GLUImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c RReLUImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c ParameterDictImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c IdentityImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c FoldImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c EmbeddingBagImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c BilinearImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c TripletMarginWithDistanceLossImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c SoftminImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c SmoothL1LossImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c MultiLabelMarginLossImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c LeakyReLUImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c FunctionalImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c ELUImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c TanhshrinkImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c PairwiseDistanceImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c LogSigmoidImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c HardtanhImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c FractionalMaxPool2dImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c FlattenImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c CrossMapLRN2dImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c TransformerEncoderLayerImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c ThresholdImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c SoftsignImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c MultiMarginLossImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c FractionalMaxPool3dImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c CTCLossImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c UnfoldImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c SiLUImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c ParameterListImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c MultiheadAttentionImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c CELUImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c UpsampleImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c TransformerImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c SELUImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c PixelUnshuffleImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c LinearImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c HingeEmbeddingLossImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c EmbeddingImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c MultiLabelSoftMarginLossImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c CrossEntropyLossImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c TripletMarginLossImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c TransformerDecoderLayerImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c SoftMarginLossImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c LocalResponseNormImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c BCELossImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c LayerNormImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c AdaptiveLogSoftmaxWithLossImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c ReLUImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c ModuleListImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c HuberLossImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c GELUImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c SoftmaxImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c Softmax2dImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c SoftplusImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c SigmoidImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c PoissonNLLLossImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c ModuleDictImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c MishImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c UnflattenImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c ReLU6Impl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c MSELossImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c CosineSimilarityImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c CosineEmbeddingLossImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c TransformerDecoderImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c TanhImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c NLLLossImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c MarginRankingLossImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c BCEWithLogitsLossImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c TransformerEncoderImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c PixelShuffleImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c KLDivLossImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c GroupNormImpl \u003e (Template Class Cloneable) public torch::nn::Cloneable\u003c Derived \u003e (Template Class Cloneable) Class Documentation# class Module : public std::enable_shared_from_this\u003cModule\u003e# The base class for all modules in PyTorch. A Module is an abstraction over the implementation of some function or algorithm, possibly associated with some persistent data. A Module may contain further Modules (\u201csubmodules\u201d), each with their own implementation, persistent data and further submodules. Modules can thus be said to form a recursive tree structure. A Module is registered as a submodule to another Module by calling register_module(), typically from within a parent module\u2019s constructor. A distinction is made between three kinds of persistent data that may be associated with a Module: Parameters: tensors that record gradients, typically weights updated during the backward step (e.g. the weight of a Linear module), Buffers: tensors that do not record gradients, typically updated during the forward step, such as running statistics (e.g. mean and variance in the BatchNorm module), Any additional state, not necessarily tensors, required for the implementation or configuration of a Module. The first two kinds of state are special in that they may be registered with the Module system to allow convenient access and batch configuration. For example, registered parameters in any Module may be iterated over via the parameters() accessor. Further, changing the data type of a Module\u2019s registered parameters can be done conveniently via Module::to(), e.g. module-\u003eto(torch::kCUDA) to move all parameters to GPU memory. Lastly, registered parameters and buffers are handled specially during a clone() operation, which performs a deepcopy of a cloneable Module hierarchy. Parameters are registered with a Module via register_parameter. Buffers are registered separately via register_buffer. These methods are part of the public API of Module and are typically invoked from within a concrete Modules constructor. Note The design and implementation of this class is largely based on the Python API. You may want to consult the python documentation for torch.nn.Module for further clarification on certain methods or behavior. Subclassed by torch::nn::Cloneable\u003c SoftshrinkImpl \u003e, torch::nn::Cloneable\u003c PReLUImpl \u003e, torch::nn::Cloneable\u003c LogSoftmaxImpl \u003e, torch::nn::Cloneable\u003c L1LossImpl \u003e, torch::nn::Cloneable\u003c SequentialImpl \u003e, torch::nn::Cloneable\u003c HardshrinkImpl \u003e, torch::nn::Cloneable\u003c GLUImpl \u003e, torch::nn::Cloneable\u003c RReLUImpl \u003e, torch::nn::Cloneable\u003c ParameterDictImpl \u003e, torch::nn::Cloneable\u003c IdentityImpl \u003e, torch::nn::Cloneable\u003c FoldImpl \u003e, torch::nn::Cloneable\u003c EmbeddingBagImpl \u003e, torch::nn::Cloneable\u003c BilinearImpl \u003e, torch::nn::Cloneable\u003c TripletMarginWithDistanceLossImpl \u003e, torch::nn::Cloneable\u003c SoftminImpl \u003e, torch::nn::Cloneable\u003c SmoothL1LossImpl \u003e, torch::nn::Cloneable\u003c MultiLabelMarginLossImpl \u003e, torch::nn::Cloneable\u003c LeakyReLUImpl \u003e, torch::nn::Cloneable\u003c FunctionalImpl \u003e, torch::nn::Cloneable\u003c ELUImpl \u003e, torch::nn::Cloneable\u003c TanhshrinkImpl \u003e, torch::nn::Cloneable\u003c PairwiseDistanceImpl \u003e, torch::nn::Cloneable\u003c LogSigmoidImpl \u003e, torch::nn::Cloneable\u003c HardtanhImpl \u003e, torch::nn::Cloneable\u003c FractionalMaxPool2dImpl \u003e, torch::nn::Cloneable\u003c FlattenImpl \u003e, torch::nn::Cloneable\u003c CrossMapLRN2dImpl \u003e, torch::nn::Cloneable\u003c TransformerEncoderLayerImpl \u003e, torch::nn::Cloneable\u003c ThresholdImpl \u003e, torch::nn::Cloneable\u003c SoftsignImpl \u003e, torch::nn::Cloneable\u003c MultiMarginLossImpl \u003e, torch::nn::Cloneable\u003c FractionalMaxPool3dImpl \u003e, torch::nn::Cloneable\u003c CTCLossImpl \u003e, torch::nn::Cloneable\u003c UnfoldImpl \u003e, torch::nn::Cloneable\u003c SiLUImpl \u003e, torch::nn::Cloneable\u003c ParameterListImpl \u003e, torch::nn::Cloneable\u003c MultiheadAttentionImpl \u003e, torch::nn::Cloneable\u003c CELUImpl \u003e, torch::nn::Cloneable\u003c UpsampleImpl \u003e, torch::nn::Cloneable\u003c TransformerImpl \u003e, torch::nn::Cloneable\u003c SELUImpl \u003e, torch::nn::Cloneable\u003c PixelUnshuffleImpl \u003e, torch::nn::Cloneable\u003c LinearImpl \u003e, torch::nn::Cloneable\u003c HingeEmbeddingLossImpl \u003e, torch::nn::Cloneable\u003c EmbeddingImpl \u003e, torch::nn::Cloneable\u003c MultiLabelSoftMarginLossImpl \u003e, torch::nn::Cloneable\u003c CrossEntropyLossImpl \u003e, torch::nn::Cloneable\u003c TripletMarginLossImpl \u003e, torch::nn::Cloneable\u003c TransformerDecoderLayerImpl \u003e, torch::nn::Cloneable\u003c SoftMarginLossImpl \u003e, torch::nn::Cloneable\u003c LocalResponseNormImpl \u003e, torch::nn::Cloneable\u003c BCELossImpl \u003e, torch::nn::Cloneable\u003c LayerNormImpl \u003e, torch::nn::Cloneable\u003c AdaptiveLogSoftmaxWithLossImpl \u003e, torch::nn::Cloneable\u003c ReLUImpl \u003e, torch::nn::Cloneable\u003c ModuleListImpl \u003e, torch::nn::Cloneable\u003c HuberLossImpl \u003e, torch::nn::Cloneable\u003c GELUImpl \u003e, torch::nn::Cloneable\u003c SoftmaxImpl \u003e, torch::nn::Cloneable\u003c Softmax2dImpl \u003e, torch::nn::Cloneable\u003c SoftplusImpl \u003e, torch::nn::Cloneable\u003c SigmoidImpl \u003e, torch::nn::Cloneable\u003c PoissonNLLLossImpl \u003e, torch::nn::Cloneable\u003c ModuleDictImpl \u003e, torch::nn::Cloneable\u003c MishImpl \u003e, torch::nn::Cloneable\u003c UnflattenImpl \u003e, torch::nn::Cloneable\u003c ReLU6Impl \u003e, torch::nn::Cloneable\u003c MSELossImpl \u003e, torch::nn::Cloneable\u003c CosineSimilarityImpl \u003e, torch::nn::Cloneable\u003c CosineEmbeddingLossImpl \u003e, torch::nn::Cloneable\u003c TransformerDecoderImpl \u003e, torch::nn::Cloneable\u003c TanhImpl \u003e, torch::nn::Cloneable\u003c NLLLossImpl \u003e, torch::nn::Cloneable\u003c MarginRankingLossImpl \u003e, torch::nn::Cloneable\u003c BCEWithLogitsLossImpl \u003e, torch::nn::Cloneable\u003c TransformerEncoderImpl \u003e, torch::nn::Cloneable\u003c PixelShuffleImpl \u003e, torch::nn::Cloneable\u003c KLDivLossImpl \u003e, torch::nn::Cloneable\u003c GroupNormImpl \u003e, torch::nn::Cloneable\u003c Derived \u003e Public Types using ModuleApplyFunction = std::function\u003cvoid(Module\u0026)\u003e# using ConstModuleApplyFunction = std::function\u003cvoid(const Module\u0026)\u003e# using NamedModuleApplyFunction = std::function\u003cvoid(const std::string\u0026, Module\u0026)\u003e# using ConstNamedModuleApplyFunction = std::function\u003cvoid(const std::string\u0026, const Module\u0026)\u003e# using ModulePointerApplyFunction = std::function\u003cvoid(const std::shared_ptr\u003cModule\u003e\u0026)\u003e# using NamedModulePointerApplyFunction = std::function\u003cvoid(const std::string\u0026, const std::shared_ptr\u003cModule\u003e\u0026)\u003e# Public Functions explicit Module(std::string name)# Tells the base Module about the name of the submodule. Module()# Constructs the module without immediate knowledge of the submodule\u2019s name. The name of the submodule is inferred via RTTI (if possible) the first time .name() is invoked. Module(const Module\u0026) = default# Module \u0026operator=(const Module\u0026) = default# Module(Module\u0026\u0026) noexcept = default# Module \u0026operator=(Module\u0026\u0026) noexcept = default# virtual ~Module() = default# const std::string \u0026name() const noexcept# Returns the name of the Module. A Module has an associated name, which is a string representation of the kind of concrete Module it represents, such as \"Linear\" for the Linear module. Under most circumstances, this name is automatically inferred via runtime type information (RTTI). In the unusual circumstance that you have this feature disabled, you may want to manually name your Modules by passing the string name to the Module base class\u2019 constructor. virtual std::shared_ptr\u003cModule\u003e clone(const std::optional\u003cDevice\u003e \u0026device = std::nullopt) const# Performs a recursive deep copy of the module and all its registered parameters, buffers and submodules. Optionally, this method sets the current device to the one supplied before cloning. If no device is given, each parameter and buffer will be moved to the device of its source. Attention Attempting to call the clone() method inherited from the base Module class (the one documented here) will fail. To inherit an actual implementation of clone(), you must subclass Cloneable. Cloneable is templatized on the concrete module type, and can thus properly copy a Module. This method is provided on the base class\u2019 API solely for an easier-to-use polymorphic interface. void apply(const ModuleApplyFunction \u0026function)# Applies the function to the Module and recursively to every submodule. The function must accept a Module\u0026. void apply(const ConstModuleApplyFunction \u0026function) const# Applies the function to the Module and recursively to every submodule. The function must accept a const Module\u0026. void apply(const NamedModuleApplyFunction \u0026function, const std::string \u0026name_prefix = std::string())# Applies the function to the Module and recursively to every submodule. The function must accept a const std::string\u0026 for the key of the module, and a Module\u0026. The key of the module itself is the empty string. If name_prefix is given, it is prepended to every key as \u003cname_prefix\u003e.\u003ckey\u003e (and just name_prefix for the module itself). void apply(const ConstNamedModuleApplyFunction \u0026function, const std::string \u0026name_prefix = std::string()) const# Applies the function to the Module and recursively to every submodule. The function must accept a const std::string\u0026 for the key of the module, and a const Module\u0026. The key of the module itself is the empty string. If name_prefix is given, it is prepended to every key as \u003cname_prefix\u003e.\u003ckey\u003e (and just name_prefix for the module itself). void apply(const ModulePointerApplyFunction \u0026function) const# Applies the function to the Module and recursively to every submodule. The function must accept a const std::shared_ptr\u003cModule\u003e\u0026. void apply(const NamedModulePointerApplyFunction \u0026function, const std::string \u0026name_prefix = std::string()) const# Applies the function to the Module and recursively to every submodule. The function must accept a const std::string\u0026 for the key of the module, and a const std::shared_ptr\u003cModule\u003e\u0026. The key of the module itself is the empty string. If name_prefix is given, it is prepended to every key as \u003cname_prefix\u003e.\u003ckey\u003e (and just name_prefix for the module itself). std::vector\u003cTensor\u003e parameters(bool recurse = true) const# Returns the parameters of this Module and if recurse is true, also recursively of every submodule. OrderedDict\u003cstd::string, Tensor\u003e named_parameters(bool recurse = true) const# Returns an OrderedDict with the parameters of this Module along with their keys, and if recurse is true also recursively of every submodule. std::vector\u003cTensor\u003e buffers(bool recurse = true) const# Returns the buffers of this Module and if recurse is true, also recursively of every submodule. OrderedDict\u003cstd::string, Tensor\u003e named_buffers(bool recurse = true) const# Returns an OrderedDict with the buffers of this Module along with their keys, and if recurse is true also recursively of every submodule. std::vector\u003cstd::shared_ptr\u003cModule\u003e\u003e modules(bool include_self = true) const# Returns the submodules of this Module (the entire submodule hierarchy) and if include_self is true, also inserts a shared_ptr to this module in the first position. Warning Only pass include_self as true if this Module is stored in a shared_ptr! Otherwise an exception will be thrown. You may still call this method with include_self set to false if your Module is not stored in a shared_ptr. OrderedDict\u003cstd::string, std::shared_ptr\u003cModule\u003e\u003e named_modules(const std::string \u0026name_prefix = std::string(), bool include_self = true) const# Returns an OrderedDict of the submodules of this Module (the entire submodule hierarchy) and their keys, and if include_self is true, also inserts a shared_ptr to this module in the first position. If name_prefix is given, it is prepended to every key as \u003cname_prefix\u003e.\u003ckey\u003e (and just name_prefix for the module itself). Warning Only pass include_self as true if this Module is stored in a shared_ptr! Otherwise an exception will be thrown. You may still call this method with include_self set to false if your Module is not stored in a shared_ptr. std::vector\u003cstd::shared_ptr\u003cModule\u003e\u003e children() const# Returns the direct submodules of this Module. OrderedDict\u003cstd::string, std::shared_ptr\u003cModule\u003e\u003e named_children() const# Returns an OrderedDict of the direct submodules of this Module and their keys. virtual void train(bool on = true)# Enables \u201ctraining\u201d mode. void eval()# Calls train(false) to enable \u201ceval\u201d mode. Do not override this method, override train() instead. virtual bool is_training() const noexcept# True if the module is in training mode. Every Module has a boolean associated with it that determines whether the Module is currently in training mode (set via .train()) or in evaluation (inference) mode (set via .eval()). This property is exposed via is_training(), and may be used by the implementation of a concrete module to modify its runtime behavior. See the BatchNorm or Dropout modules for examples of Modules that use different code paths depending on this property. virtual void to(torch::Device device, torch::Dtype dtype, bool non_blocking = false)# Recursively casts all parameters to the given dtype and device. If non_blocking is true and the source is in pinned memory and destination is on the GPU or vice versa, the copy is performed asynchronously with respect to the host. Otherwise, the argument has no effect. virtual void to(torch::Dtype dtype, bool non_blocking = false)# Recursively casts all parameters to the given dtype. If non_blocking is true and the source is in pinned memory and destination is on the GPU or vice versa, the copy is performed asynchronously with respect to the host. Otherwise, the argument has no effect. virtual void to(torch::Device device, bool non_blocking = false)# Recursively moves all parameters to the given device. If non_blocking is true and the source is in pinned memory and destination is on the GPU or vice versa, the copy is performed asynchronously with respect to the host. Otherwise, the argument has no effect. virtual void zero_grad(bool set_to_none = true)# Recursively zeros out the grad value of each registered parameter. template\u003ctypename ModuleType\u003eModuleType::ContainedType *as() noexcept# Attempts to cast this Module to the given ModuleType. This method is useful when calling apply(). void initialize_weights(nn::Module\u0026 module) { torch::NoGradGuard no_grad; if (auto* linear = module.as\u003cnn::Linear\u003e()) { linear-\u003eweight.normal_(0.0, 0.02); } } MyModule module; module-\u003eapply(initialize_weights); template\u003ctypename ModuleType\u003econst ModuleType::ContainedType *as() const noexcept# Attempts to cast this Module to the given ModuleType. This method is useful when calling apply(). template\u003ctypename ModuleType, typename = torch::detail::disable_if_module_holder_t\u003cModuleType\u003e\u003eModuleType *as() noexcept# Attempts to cast this Module to the given ModuleType. This method is useful when calling apply(). void initialize_weights(nn::Module\u0026 module) { torch::NoGradGuard no_grad; if (auto* linear = module.as\u003cnn::Linear\u003e()) { linear-\u003eweight.normal_(0.0, 0.02); } } MyModule module; module.apply(initialize_weights); template\u003ctypename ModuleType, typename = torch::detail::disable_if_module_holder_t\u003cModuleType\u003e\u003econst ModuleType *as() const noexcept# Attempts to cast this Module to the given ModuleType. This method is useful when calling apply(). void initialize_weights(nn::Module\u0026 module) { torch::NoGradGuard no_grad; if (auto* linear = module.as\u003cnn::Linear\u003e()) { linear-\u003eweight.normal_(0.0, 0.02); } } MyModule module; module.apply(initialize_weights); virtual void save(serialize::OutputArchive \u0026archive) const# Serializes the Module into the given OutputArchive. If the Module contains unserializable submodules (e.g. nn::Functional), those submodules are skipped when serializing. virtual void load(serialize::InputArchive \u0026archive)# Deserializes the Module from the given InputArchive. If the Module contains unserializable submodules (e.g. nn::Functional), we don\u2019t check the existence of those submodules in the InputArchive when deserializing. virtual void pretty_print(std::ostream \u0026stream) const# Streams a pretty representation of the Module into the given stream. By default, this representation will be the name of the module (taken from name()), followed by a recursive pretty print of all of the Module\u2019s submodules. Override this method to change the pretty print. The input stream should be returned from the method, to allow easy chaining. virtual bool is_serializable() const# Returns whether the Module is serializable. Tensor \u0026register_parameter(std::string name, Tensor tensor, bool requires_grad = true)# Registers a parameter with this Module. A parameter should be any gradient-recording tensor used in the implementation of your Module. Registering it makes it available to methods such as parameters(), clone() or to(). Note that registering an undefined Tensor (e.g. module.register_parameter(\"param\", Tensor())) is allowed, and is equivalent to module.register_parameter(\"param\", None) in Python API. MyModule::MyModule() { weight_ = register_parameter(\"weight\", torch::randn({A, B})); } Tensor \u0026register_buffer(std::string name, Tensor tensor)# Registers a buffer with this Module. A buffer is intended to be state in your module that does not record gradients, such as running statistics. Registering it makes it available to methods such as buffers(), clone() or `to(). MyModule::MyModule() { mean_ = register_buffer(\"mean\", torch::empty({num_features_})); } template\u003ctypename ModuleType\u003estd::shared_ptr\u003cModuleType\u003e register_module(std::string name, std::shared_ptr\u003cModuleType\u003e module)# Registers a submodule with this Module. Registering a module makes it available to methods such as modules(), clone() or to(). MyModule::MyModule() { submodule_ = register_module(\"linear\", torch::nn::Linear(3, 4)); } template\u003ctypename ModuleType\u003estd::shared_ptr\u003cModuleType\u003e register_module(std::string name, ModuleHolder\u003cModuleType\u003e module_holder)# Registers a submodule with this Module. This method deals with ModuleHolders. Registering a module makes it available to methods such as modules(), clone() or to(). MyModule::MyModule() { submodule_ = register_module(\"linear\", torch::nn::Linear(3, 4)); } template\u003ctypename ModuleType\u003estd::shared_ptr\u003cModuleType\u003e replace_module(const std::string \u0026name, std::shared_ptr\u003cModuleType\u003e module)# Replaces a registered submodule with this Module. This takes care of the registration, if you used submodule members, you should module-\u003esubmodule_ = module-\u003ereplace_module(\u201clinear\u201d, torch::nn::Linear(3, 4)); It only works when a module of the name is already registered. This is useful for replacing a module after initialization, e.g. for finetuning. template\u003ctypename ModuleType\u003estd::shared_ptr\u003cModuleType\u003e replace_module(const std::string \u0026name, ModuleHolder\u003cModuleType\u003e module_holder)# Replaces a registered submodule with this Module. This method deals with ModuleHolders. This takes care of the registration, if you used submodule members, you should module-\u003esubmodule_ = module-\u003ereplace_module(\u201clinear\u201d, linear_holder); It only works when a module of the name is already registered. This is useful for replacing a module after initialization, e.g. for finetuning. void unregister_module(const std::string \u0026name)# Unregisters a submodule from this Module. If there is no such module with name an exception is thrown. Protected Functions inline virtual bool _forward_has_default_args()# The following three functions allow a module with default arguments in its forward method to be used in a Sequential module. You should NEVER override these functions manually. Instead, you should use the FORWARD_HAS_DEFAULT_ARGS macro. inline virtual unsigned int _forward_num_required_args()# inline virtual std::vector\u003cAnyValue\u003e _forward_populate_default_args(std::vector\u003cAnyValue\u003e \u0026\u0026arguments)# Protected Attributes OrderedDict\u003cstd::string, Tensor\u003e parameters_# The registered parameters of this Module. Inorder to access parameters_ in ParameterDict and ParameterList",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "../_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/api/classtorch_1_1nn_1_1_module.html"
       },
       "datePublished": "2023-01-01T00:00:00Z",
       "dateModified": "2023-01-01T00:00:00Z"
     }
 </script>
  <script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
  
  </body>
</html>