

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Program Listing for File TensorBody.h &#8212; PyTorch main documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/theme.css" />
    <link rel="stylesheet" type="text/css" href="../_static/collapsible-lists/css/tree_view.css" />
    <link rel="stylesheet" type="text/css" href="../_static/cpp_theme.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/collapsible-lists/js/CollapsibleLists.compressed.js"></script>
    <script src="../_static/collapsible-lists/js/apply-collapsible-lists.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'api/program_listing_file_build_aten_src_ATen_core_TensorBody.h';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="File TensorOptions.h" href="file_aten_src_ATen_TensorOptions.h.html" />
    <link rel="prev" title="File TensorBody.h" href="file_build_aten_src_ATen_core_TensorBody.h.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->

<link rel="stylesheet" type="text/css" href="../_static/css/theme.css" crossorigin="anonymous">
<script type="text/javascript" src="../_static/js/theme.js"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400&display=swap" rel="stylesheet">
<meta property="og:image" content="../_static/img/pytorch_seo.png" />
<link rel="stylesheet" href="../_static/webfonts/all.min.css" crossorigin="anonymous">
<meta http-equiv="Content-Security-Policy"
  content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;">
<meta name="pytorch_project" content="">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" height="0" width="0"
    style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'GTM-T8XT4PS');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', 'main');
</script>
<noscript>
  <img height="1" width="1" src="https://www.facebook.com/tr?id=243028289693773&ev=PageView&noscript=1" />
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>

<script async src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>

<!--
   Search engines should not index the main version of documentation.
   Stable documentation are built without release == 'main'.
   -->
<meta name="robots" content="noindex">


  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>

  </head>

<body data-feedback-url="https://github.com/pytorch/pytorch" class="pytorch-body">
  
    <div class="container-fluid header-holder tutorials-header" id="header-holder">
   <div class="header-container-wrapper">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                <span>Learn</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started/locally">
                  <span class=dropdown-title>Get Started</span>
                </a>
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/webinars/">
                  <span class="dropdown-title">Webinars</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Community</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Landscape</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/join-ecosystem">
                  <span class="dropdown-title">Join the Ecosystem</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-hub/">
                  <span class="dropdown-title">Community Hub</span>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/">
                  <span class="dropdown-title">Forums</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contributor-awards/">
                  <span class="dropdown-title">Contributor Awards</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-events/">
                  <span class="dropdown-title">Community Events</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/programs/ambassadors/">
                  <span class="dropdown-title">PyTorch Ambassadors</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Projects</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/pytorch/">
                  <span class="dropdown-title">PyTorch</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/vllm/">
                  <span class="dropdown-title">vLLM</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/deepspeed/">
                  <span class="dropdown-title">DeepSpeed</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/host-your-project/">
                  <span class="dropdown-title">Host Your Project</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span> Docs</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/domains">
                  <span class="dropdown-title">Domains</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Blogs & News</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">Blog</span>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/announcements">
                  <span class="dropdown-title">Announcements</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/case-studies/">
                  <span class="dropdown-title">Case Studies</span>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">Newsletter</span>
                </a>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>About</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/members">
                  <span class="dropdown-title">Members</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact">
                  <span class="dropdown-title">Contact</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown main-menu-button">
              <a href="https://pytorch.org/join" data-cta="join">
                JOIN
              </a>
            </div>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu">
        <i class="fa-solid fa-ellipsis"></i>
      </a>
    </div>
  </div>
 </div>

 <!-- Begin Mobile Menu -->

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="header-container-wrapper">
      <div class="mobile-main-menu-header-container">
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu">
        </a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">
    <div class="main-menu">
      <ul>
         <li class="resources-mobile-menu-title">
           <a>Learn</a>
         </li>
         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.org/get-started/locally">Get Started</a>
           </li>
           <li>
             <a href="https://docs.pytorch.org/tutorials">Tutorials</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
           </li>
           <li>
            <a href="https://pytorch.org/webinars/">Webinars</a>
          </li>
        </ul>
         <li class="resources-mobile-menu-title">
           <a>Community</a>
         </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://landscape.pytorch.org/">Landscape</a>
          </li>
          <li>
             <a href="https://pytorch.org/join-ecosystem">Join the Ecosystem</a>
           </li>
           <li>
             <a href="https://pytorch.org/community-hub/">Community Hub</a>
           </li>
           <li>
             <a href="https://discuss.pytorch.org/">Forums</a>
           </li>
           <li>
             <a href="https://pytorch.org/resources">Developer Resources</a>
           </li>
           <li>
             <a href="https://pytorch.org/contributor-awards/">Contributor Awards</a>
           </li>
           <li>
            <a href="https://pytorch.org/community-events/">Community Events</a>
          </li>
          <li>
            <a href="https://pytorch.org/programs/ambassadors/">PyTorch Ambassadors</a>
          </li>
       </ul>

         <li class="resources-mobile-menu-title">
           <a>Projects</a>
         </li>

         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.org/projects/pytorch/">PyTorch</a>
           </li>

           <li>
             <a href="https://pytorch.org/projects/vllm/">vLLM</a>
           </li>
           <li>
            <a href="https://pytorch.org/projects/deepspeed/">DeepSpeed</a>
          </li>
          <li>
             <a href="https://pytorch.org/projects/host-your-project/">Host Your Project</a>
           </li>
         </ul>

         <li class="resources-mobile-menu-title">
           <a>Docs</a>
         </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://docs.pytorch.org/docs/stable/index.html">PyTorch</a>
          </li>

          <li>
            <a href="https://pytorch.org/domains">Domains</a>
          </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>Blog & News</a>
        </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>
          <li>
            <a href="https://pytorch.org/announcements">Announcements</a>
          </li>

          <li>
            <a href="https://pytorch.org/case-studies/">Case Studies</a>
          </li>
          <li>
            <a href="https://pytorch.org/events">Events</a>
          </li>
          <li>
             <a href="https://pytorch.org/newsletter">Newsletter</a>
           </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>About</a>
        </li>

        <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
          </li>
          <li>
            <a href="https://pytorch.org/members">Members</a>
          </li>
          <li>
            <a href="https://pytorch.org/governing-board">Governing Board</a>
          </li>
          <li>
            <a href="https://pytorch.org/tac">Technical Advisory Council</a>
         </li>
         <li>
             <a href="https://pytorch.org/credits">Cloud Credit Program</a>
          </li>
          <li>
             <a href="https://pytorch.org/staff">Staff</a>
          </li>
          <li>
             <a href="https://pytorch.org/contact">Contact</a>
          </li>
        </ul>
      </ul>
    </div>
  </div>
</div>

<!-- End Mobile Menu -->
  
  
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">
  <a href="../index.html" class="version">main</a>
</div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../installing.html">
    Installing C++ Distributions of PyTorch
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../frontend.html">
    The C++ Frontend
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="library_root.html">
    Library API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes/faq.html">
    FAQ
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes/inference_mode.html">
    Inference Mode
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../notes/maybe_owned.html">
    MaybeOwned<Tensor>
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../notes/tensor_basics.html">
    Tensor Basics
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../notes/tensor_creation.html">
    Tensor Creation API
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../notes/tensor_cuda_stream.html">
    Tensor CUDA Stream API
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../notes/tensor_indexing.html">
    Tensor Indexing API
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../notes/versioning.html">
    Library Versioning
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
        <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/pytorch" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.org/" title="PyTorch Forum" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyTorch Forum</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../installing.html">
    Installing C++ Distributions of PyTorch
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../frontend.html">
    The C++ Frontend
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="library_root.html">
    Library API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes/faq.html">
    FAQ
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes/inference_mode.html">
    Inference Mode
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes/maybe_owned.html">
    MaybeOwned<Tensor>
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes/tensor_basics.html">
    Tensor Basics
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes/tensor_creation.html">
    Tensor Creation API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes/tensor_cuda_stream.html">
    Tensor CUDA Stream API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes/tensor_indexing.html">
    Tensor Indexing API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../notes/versioning.html">
    Library Versioning
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/pytorch" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.org/" title="PyTorch Forum" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyTorch Forum</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Program Listing for File TensorBody.h</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="library_root.html" class="nav-link">Library API</a></li>
    
    
    <li class="breadcrumb-item"><a href="file_build_aten_src_ATen_core_TensorBody.h.html" class="nav-link">File TensorBody.h</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Program...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              
  
<div id="searchbox"></div>
  <article class="bd-article" id="pytorch-article">
    <!-- Hidden breadcrumb schema for SEO only -->
    <div style="display:none;" itemscope itemtype="https://schema.org/BreadcrumbList">
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <link itemprop="item" href="library_root.html">
        <meta itemprop="name" content="Library API">
        <meta itemprop="position" content="1">
      </div>
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <link itemprop="item" href="file_build_aten_src_ATen_core_TensorBody.h.html">
        <meta itemprop="name" content="File TensorBody.h">
        <meta itemprop="position" content="2">
      </div>
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <meta itemprop="name" content="Program Listing for File TensorBody.h">
        <meta itemprop="position" content="3">
      </div>
    </div>

    

    
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="section" id="program-listing-for-file-tensorbody-h">
<span id="program-listing-file-build-aten-src-aten-core-tensorbody-h"></span><h1>Program Listing for File TensorBody.h<a class="headerlink" href="#program-listing-for-file-tensorbody-h" title="Permalink to this heading">#</a></h1>
<p>↰ <a class="reference internal" href="file_build_aten_src_ATen_core_TensorBody.h.html#file-build-aten-src-aten-core-tensorbody-h"><span class="std std-ref">Return to documentation for file</span></a> (<code class="docutils literal notranslate"><span class="pre">build/aten/src/ATen/core/TensorBody.h</span></code>)</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#pragma once</span>

<span class="cp">#ifdef TORCH_ASSERT_NO_OPERATORS</span>
<span class="cp">#error This change adds a dependency on native_functions.yaml,            \</span>
<span class="cp">  meaning the file will need to be re-compiled every time an operator     \</span>
<span class="cp">  is changed or added. Consider if your change would be better placed in  \</span>
<span class="cp">  another file, or if a more specific header might achieve the same goal. \</span>
<span class="cp">  See NOTE: [Tensor vs. TensorBase]</span>
<span class="cp">#endif</span>

<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;c10/core/Device.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;c10/core/Layout.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;c10/core/MemoryFormat.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;c10/core/QScheme.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;c10/core/Stream.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;c10/core/Scalar.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;c10/core/ScalarType.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;c10/core/ScalarTypeToTypeMeta.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;c10/core/Storage.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;c10/core/TensorImpl.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;c10/core/UndefinedTensorImpl.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;c10/core/WrapDimMinimal.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;c10/util/Exception.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;c10/util/ExclusivelyOwned.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;c10/util/Deprecated.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;c10/util/MaybeOwned.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;optional&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;c10/util/OptionalArrayRef.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;c10/util/intrusive_ptr.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;c10/macros/Export.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;ATen/core/CheckMemoryFormat.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;ATen/core/DeprecatedTypePropertiesRegistry.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;ATen/core/DeprecatedTypeProperties.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;ATen/core/NamedTensor.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;ATen/core/QuantizerBase.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;c10/core/SymInt.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;ATen/core/TensorAccessor.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;ATen/core/TensorBase.h&gt;</span>


<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;ATen/MethodOperators.h&gt;</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">c10</span><span class="p">{</span>
<span class="k">template</span><span class="o">&lt;</span><span class="k">class</span><span class="w"> </span><span class="nc">T</span><span class="o">&gt;</span><span class="w"> </span><span class="k">class</span><span class="w"> </span><span class="nc">List</span><span class="p">;</span>
<span class="k">template</span><span class="o">&lt;</span><span class="k">class</span><span class="w"> </span><span class="nc">T</span><span class="o">&gt;</span><span class="w"> </span><span class="k">class</span><span class="w"> </span><span class="nc">IListRef</span><span class="p">;</span>
<span class="p">}</span>
<span class="k">namespace</span><span class="w"> </span><span class="nn">at</span><span class="w"> </span><span class="p">{</span>
<span class="k">struct</span><span class="w"> </span><span class="nc">Generator</span><span class="p">;</span>
<span class="k">struct</span><span class="w"> </span><span class="nc">Type</span><span class="p">;</span>
<span class="k">class</span><span class="w"> </span><span class="nc">DeprecatedTypeProperties</span><span class="p">;</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Tensor</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="c1">// namespace at</span>
<span class="k">namespace</span><span class="w"> </span><span class="nn">at</span><span class="w"> </span><span class="p">{</span>
<span class="k">namespace</span><span class="w"> </span><span class="nn">indexing</span><span class="w"> </span><span class="p">{</span>
<span class="k">struct</span><span class="w"> </span><span class="nc">TensorIndex</span><span class="p">;</span>
<span class="p">}</span><span class="w"> </span><span class="c1">// namespace indexing</span>
<span class="p">}</span><span class="w"> </span><span class="c1">// namespace at</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">namespace</span><span class="w"> </span><span class="nn">autograd</span><span class="w"> </span><span class="p">{</span>

<span class="k">struct</span><span class="w"> </span><span class="nc">Node</span><span class="p">;</span>

<span class="p">}}</span><span class="w"> </span><span class="c1">// namespace torch::autograd</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">at</span><span class="w"> </span><span class="p">{</span>

<span class="k">class</span><span class="w"> </span><span class="nc">OptionalTensorRef</span><span class="p">;</span>
<span class="k">class</span><span class="w"> </span><span class="nc">TensorRef</span><span class="p">;</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Tensor</span><span class="p">;</span>
<span class="k">using</span><span class="w"> </span><span class="n">TensorList</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="p">;</span>
<span class="k">using</span><span class="w"> </span><span class="n">ITensorList</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">IListRef</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="p">;</span>

<span class="k">using</span><span class="w"> </span><span class="n">Stream</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">Stream</span><span class="p">;</span>

<span class="c1">// Tensor is a &quot;generic&quot; object holding a pointer to the underlying TensorImpl object, which</span>
<span class="c1">// has an embedded reference count. In this way, Tensor is similar to boost::intrusive_ptr.</span>
<span class="c1">//</span>
<span class="c1">// For example:</span>
<span class="c1">//</span>
<span class="c1">// void func(Tensor a) {</span>
<span class="c1">//   Tensor b = a;</span>
<span class="c1">//   ...</span>
<span class="c1">// }</span>
<span class="c1">//</span>
<span class="c1">// In this example, when we say Tensor b = a, we are creating a new object that points to the</span>
<span class="c1">// same underlying TensorImpl, and bumps its reference count. When b goes out of scope, the</span>
<span class="c1">// destructor decrements the reference count by calling release() on the TensorImpl it points to.</span>
<span class="c1">// The existing constructors, operator overloads, etc. take care to implement the correct semantics.</span>
<span class="c1">//</span>
<span class="c1">// Note that Tensor can also be NULL, i.e. it is not associated with any underlying TensorImpl, and</span>
<span class="c1">// special care must be taken to handle this.</span>
<span class="k">class</span><span class="w"> </span><span class="nc">TORCH_API</span><span class="w"> </span><span class="n">Tensor</span><span class="o">:</span><span class="w"> </span><span class="k">public</span><span class="w"> </span><span class="n">TensorBase</span><span class="w"> </span><span class="p">{</span>
<span class="w"> </span><span class="k">protected</span><span class="o">:</span>
<span class="w">  </span><span class="c1">// Create a Tensor with a +0 reference count. Special care must be</span>
<span class="w">  </span><span class="c1">// taken to avoid decrementing this reference count at destruction</span>
<span class="w">  </span><span class="c1">// time. Intended to support MaybeOwnedTraits&lt;Tensor&gt;.</span>
<span class="w">  </span><span class="k">explicit</span><span class="w"> </span><span class="n">Tensor</span><span class="p">(</span><span class="n">unsafe_borrow_t</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">TensorBase</span><span class="o">&amp;</span><span class="w"> </span><span class="n">rhs</span><span class="p">)</span><span class="o">:</span><span class="w"> </span><span class="n">TensorBase</span><span class="p">(</span><span class="n">unsafe_borrow_t</span><span class="p">{},</span><span class="w"> </span><span class="n">rhs</span><span class="p">)</span><span class="w"> </span><span class="p">{}</span>
<span class="w">  </span><span class="k">friend</span><span class="w"> </span><span class="n">MaybeOwnedTraits</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="p">;</span>
<span class="w">  </span><span class="k">friend</span><span class="w"> </span><span class="n">OptionalTensorRef</span><span class="p">;</span>
<span class="w">  </span><span class="k">friend</span><span class="w"> </span><span class="n">TensorRef</span><span class="p">;</span>

<span class="w"> </span><span class="k">public</span><span class="o">:</span>
<span class="w">  </span><span class="n">Tensor</span><span class="p">()</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">default</span><span class="p">;</span>
<span class="w">  </span><span class="c1">// This constructor should not be used by end users and is an implementation</span>
<span class="w">  </span><span class="c1">// detail invoked by autogenerated code.</span>
<span class="w">  </span><span class="k">explicit</span><span class="w"> </span><span class="n">Tensor</span><span class="p">(</span>
<span class="w">      </span><span class="n">c10</span><span class="o">::</span><span class="n">intrusive_ptr</span><span class="o">&lt;</span><span class="n">TensorImpl</span><span class="p">,</span><span class="w"> </span><span class="n">UndefinedTensorImpl</span><span class="o">&gt;</span><span class="w"> </span><span class="n">tensor_impl</span><span class="p">)</span>
<span class="w">      </span><span class="o">:</span><span class="w"> </span><span class="n">TensorBase</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">tensor_impl</span><span class="p">))</span><span class="w"> </span><span class="p">{}</span>
<span class="w">  </span><span class="n">Tensor</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="n">tensor</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">default</span><span class="p">;</span>
<span class="w">  </span><span class="n">Tensor</span><span class="p">(</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="n">tensor</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">default</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Implicitly move-constructible from TensorBase, but must be explicit to increase refcount</span>
<span class="w">  </span><span class="k">explicit</span><span class="w"> </span><span class="n">Tensor</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">TensorBase</span><span class="w"> </span><span class="o">&amp;</span><span class="n">base</span><span class="p">)</span><span class="o">:</span><span class="w"> </span><span class="n">TensorBase</span><span class="p">(</span><span class="n">base</span><span class="p">)</span><span class="w"> </span><span class="p">{}</span>
<span class="w">  </span><span class="cm">/*implicit*/</span><span class="w"> </span><span class="n">Tensor</span><span class="p">(</span><span class="n">TensorBase</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="n">base</span><span class="p">)</span><span class="o">:</span><span class="w"> </span><span class="n">TensorBase</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">base</span><span class="p">))</span><span class="w"> </span><span class="p">{}</span>

<span class="w">  </span><span class="c1">// Creates a new wrapper from TensorImpl. Intentionally a free method because</span>
<span class="w">  </span><span class="c1">// it should be used with care. Checks necessary invariants</span>
<span class="w">  </span><span class="k">static</span><span class="w"> </span><span class="n">Tensor</span><span class="w"> </span><span class="n">wrap_tensor_impl</span><span class="p">(</span>
<span class="w">      </span><span class="n">c10</span><span class="o">::</span><span class="n">intrusive_ptr</span><span class="o">&lt;</span><span class="n">TensorImpl</span><span class="p">,</span><span class="w"> </span><span class="n">UndefinedTensorImpl</span><span class="o">&gt;</span><span class="w"> </span><span class="n">tensor_impl</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">TensorBase</span><span class="o">::</span><span class="n">wrap_tensor_impl</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">tensor_impl</span><span class="p">));</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">Tensor</span><span class="w"> </span><span class="n">contiguous</span><span class="p">(</span><span class="n">MemoryFormat</span><span class="w"> </span><span class="n">memory_format</span><span class="o">=</span><span class="n">MemoryFormat</span><span class="o">::</span><span class="n">Contiguous</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">TensorBase</span><span class="o">::</span><span class="n">contiguous</span><span class="p">(</span><span class="n">memory_format</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">Tensor</span><span class="w"> </span><span class="n">conj</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="k">this</span><span class="o">-&gt;</span><span class="n">is_complex</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="o">*</span><span class="k">this</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="k">switch</span><span class="w"> </span><span class="p">(</span><span class="k">this</span><span class="o">-&gt;</span><span class="n">layout</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">case</span><span class="w"> </span><span class="no">at</span><span class="o">::</span><span class="no">kSparse</span><span class="p">:</span>
<span class="w">      </span><span class="k">case</span><span class="w"> </span><span class="no">at</span><span class="o">::</span><span class="no">kSparseCsr</span><span class="p">:</span>
<span class="w">      </span><span class="k">case</span><span class="w"> </span><span class="no">at</span><span class="o">::</span><span class="no">kSparseCsc</span><span class="p">:</span>
<span class="w">      </span><span class="k">case</span><span class="w"> </span><span class="no">at</span><span class="o">::</span><span class="no">kSparseBsr</span><span class="p">:</span>
<span class="w">      </span><span class="k">case</span><span class="w"> </span><span class="no">at</span><span class="o">::</span><span class="no">kSparseBsc</span><span class="p">:</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="k">this</span><span class="o">-&gt;</span><span class="n">conj_physical</span><span class="p">();</span>
<span class="w">      </span><span class="k">default</span><span class="o">:</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="k">this</span><span class="o">-&gt;</span><span class="n">_conj</span><span class="p">();</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Aliased by Dimname overloads, so need explicit using</span>
<span class="w">  </span><span class="k">using</span><span class="w"> </span><span class="n">TensorBase</span><span class="o">::</span><span class="n">size</span><span class="p">;</span>
<span class="w">  </span><span class="k">using</span><span class="w"> </span><span class="n">TensorBase</span><span class="o">::</span><span class="n">sym_size</span><span class="p">;</span>
<span class="w">  </span><span class="k">using</span><span class="w"> </span><span class="n">TensorBase</span><span class="o">::</span><span class="n">stride</span><span class="p">;</span>

<span class="w">  </span><span class="n">c10</span><span class="o">::</span><span class="n">MaybeOwned</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">expect_contiguous</span><span class="p">(</span><span class="n">MemoryFormat</span><span class="w"> </span><span class="n">memory_format</span><span class="o">=</span><span class="n">MemoryFormat</span><span class="o">::</span><span class="n">Contiguous</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">&amp;</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Use .contiguous() instead. Trying to borrow from a prvalue Tensor</span>
<span class="w">  </span><span class="c1">// will only lead to trouble and dangling references.</span>
<span class="w">  </span><span class="n">c10</span><span class="o">::</span><span class="n">MaybeOwned</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">expect_contiguous</span><span class="p">(</span><span class="n">MemoryFormat</span><span class="w"> </span><span class="n">memory_format</span><span class="o">=</span><span class="n">MemoryFormat</span><span class="o">::</span><span class="n">Contiguous</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">delete</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// The following overloads are very intruiging.  Consider the following</span>
<span class="w">  </span><span class="c1">// program:</span>
<span class="w">  </span><span class="c1">//</span>
<span class="w">  </span><span class="c1">//    x[1] = 3;</span>
<span class="w">  </span><span class="c1">//</span>
<span class="w">  </span><span class="c1">// We would expect that the first entry of x is written to 3.  But how can we</span>
<span class="w">  </span><span class="c1">// actually achieve this?  x[1] evaluates to a tensor...</span>
<span class="w">  </span><span class="c1">//</span>
<span class="w">  </span><span class="c1">// The answer is, using a ref-qualifier.  x[1] is an rvalue, which cannot be</span>
<span class="w">  </span><span class="c1">// (profitably) assigned to in the traditional sense, so we overload</span>
<span class="w">  </span><span class="c1">// assignment to mean, &quot;Actually, copy 3 into the tensor data.&quot;  This is done</span>
<span class="w">  </span><span class="c1">// with an rvalue-reference ref-qualified overload (the methods with &amp;&amp; at the</span>
<span class="w">  </span><span class="c1">// end of their type.)</span>
<span class="w">  </span><span class="c1">//</span>
<span class="w">  </span><span class="c1">// There&#39;s one more fly in the ointment: We also want</span>
<span class="w">  </span><span class="c1">//</span>
<span class="w">  </span><span class="c1">//    Tensor x = y;</span>
<span class="w">  </span><span class="c1">//</span>
<span class="w">  </span><span class="c1">// to work, and we want it NOT to copy.  So we need a traditional operator=</span>
<span class="w">  </span><span class="c1">// overload.  But we MUST specify a mutable lvalue ref-qualifier, to</span>
<span class="w">  </span><span class="c1">// disambiguate the traditional overload from the rvalue-reference</span>
<span class="w">  </span><span class="c1">// ref-qualified overload.  Otherwise, it will be ambiguous, because</span>
<span class="w">  </span><span class="c1">// a non ref-qualified method is eligible for all situations.</span>

<span class="w">  </span><span class="c1">// Unfortunately, we have to write these constructors out manually</span>
<span class="w">  </span><span class="c1">// to work around an MSVC bug:</span>
<span class="w">  </span><span class="c1">//    error C2580: &#39;at::Tensor &amp;at::Tensor::operator =(const at::Tensor &amp;) &amp;&#39;:</span>
<span class="w">  </span><span class="c1">//    multiple versions of a defaulted special member functions are not allowed</span>
<span class="w">  </span><span class="c1">// Tensor&amp; operator=(const Tensor&amp;) &amp; = default;</span>
<span class="w">  </span><span class="c1">// Tensor&amp; operator=(Tensor&amp;&amp;) &amp; = default;</span>

<span class="w">  </span><span class="c1">// Also MSVC will wrongly issue the following warning with the aforementioned fix</span>
<span class="w">  </span><span class="c1">//    warning C4522: &#39;at::Tensor&#39;: multiple assignment operators specified</span>
<span class="w">  </span><span class="c1">// Let&#39;s just skip the warning.</span>
<span class="w">  </span><span class="c1">//</span>
<span class="w">  </span><span class="c1">// TODO: temporarily disabled</span>

<span class="w">  </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="k">operator</span><span class="o">=</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">TensorBase</span><span class="o">&amp;</span><span class="w"> </span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="k">noexcept</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">impl_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">.</span><span class="n">getIntrusivePtr</span><span class="p">();</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="o">*</span><span class="k">this</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="k">operator</span><span class="o">=</span><span class="p">(</span><span class="n">TensorBase</span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="k">noexcept</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">impl_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="p">.</span><span class="n">unsafeReleaseIntrusivePtr</span><span class="p">();</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="o">*</span><span class="k">this</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="k">operator</span><span class="o">=</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="k">noexcept</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="k">operator</span><span class="o">=</span><span class="p">(</span><span class="k">static_cast</span><span class="o">&lt;</span><span class="k">const</span><span class="w"> </span><span class="n">TensorBase</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="n">x</span><span class="p">));</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="k">operator</span><span class="o">=</span><span class="p">(</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="k">noexcept</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="k">operator</span><span class="o">=</span><span class="p">(</span><span class="k">static_cast</span><span class="o">&lt;</span><span class="n">TensorBase</span><span class="o">&amp;&amp;&gt;</span><span class="p">(</span><span class="n">x</span><span class="p">));</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="k">operator</span><span class="o">=</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="n">v</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">fill_</span><span class="p">(</span><span class="n">v</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="k">operator</span><span class="o">=</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="n">rhs</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">copy_</span><span class="p">(</span><span class="n">rhs</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="k">operator</span><span class="o">=</span><span class="p">(</span><span class="n">Tensor</span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">rhs</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">copy_</span><span class="p">(</span><span class="n">rhs</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">C10_DEPRECATED_MESSAGE</span><span class="p">(</span><span class="s">&quot;Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device().&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="n">DeprecatedTypeProperties</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">type</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">globalDeprecatedTypePropertiesRegistry</span><span class="p">().</span><span class="n">getDeprecatedTypeProperties</span><span class="p">(</span>
<span class="w">        </span><span class="n">dispatchKeyToBackend</span><span class="p">(</span><span class="n">legacyExtractDispatchKey</span><span class="p">(</span><span class="n">key_set</span><span class="p">())),</span>
<span class="w">        </span><span class="n">scalar_type</span><span class="p">());</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">Tensor</span><span class="w"> </span><span class="n">toType</span><span class="p">(</span><span class="n">ScalarType</span><span class="w"> </span><span class="n">t</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">to</span><span class="p">(</span><span class="n">options</span><span class="p">().</span><span class="n">dtype</span><span class="p">(</span><span class="n">t</span><span class="p">),</span><span class="w"> </span><span class="cm">/*non_blocking*/</span><span class="w"> </span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="cm">/*copy*/</span><span class="w"> </span><span class="nb">false</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// TODO: Deprecate me</span>
<span class="w">  </span><span class="n">Tensor</span><span class="w"> </span><span class="n">toBackend</span><span class="p">(</span><span class="n">Backend</span><span class="w"> </span><span class="n">b</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">to</span><span class="p">(</span><span class="n">options</span><span class="p">().</span><span class="n">device</span><span class="p">(</span><span class="n">backendToDeviceType</span><span class="p">(</span><span class="n">b</span><span class="p">)).</span><span class="n">layout</span><span class="p">(</span><span class="n">layout_from_backend</span><span class="p">(</span><span class="n">b</span><span class="p">)),</span><span class="w"> </span><span class="cm">/*non_blocking*/</span><span class="w"> </span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="cm">/*copy*/</span><span class="w"> </span><span class="nb">false</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">C10_DEPRECATED_MESSAGE</span><span class="p">(</span><span class="s">&quot;Tensor.is_variable() is deprecated; everything is a variable now. (If you want to assert that variable has been appropriately handled already, use at::impl::variable_excluded_from_dispatch())&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="n">is_variable</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="k">noexcept</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="o">!</span><span class="n">at</span><span class="o">::</span><span class="n">impl</span><span class="o">::</span><span class="n">variable_excluded_from_dispatch</span><span class="p">();</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">template</span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="o">&gt;</span>
<span class="w">  </span><span class="n">C10_DEPRECATED_MESSAGE</span><span class="p">(</span><span class="s">&quot;Tensor.data&lt;T&gt;() is deprecated. Please use Tensor.data_ptr&lt;T&gt;() instead.&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="n">T</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">data</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">data_ptr</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="p">();</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="o">&gt;</span>
<span class="w">  </span><span class="n">T</span><span class="w"> </span><span class="n">item</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>

<span class="w">  </span><span class="k">template</span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="p">,</span><span class="w"> </span><span class="kt">size_t</span><span class="w"> </span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">U</span><span class="o">&gt;</span><span class="w"> </span><span class="k">class</span><span class="w"> </span><span class="nc">PtrTraits</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">DefaultPtrTraits</span><span class="p">,</span><span class="w"> </span><span class="k">typename</span><span class="w"> </span><span class="nc">index_t</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kt">int64_t</span><span class="o">&gt;</span>
<span class="w">  </span><span class="n">C10_DEPRECATED_MESSAGE</span><span class="p">(</span><span class="s">&quot;packed_accessor is deprecated, use packed_accessor32 or packed_accessor64 instead&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="n">GenericPackedTensorAccessor</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="n">PtrTraits</span><span class="p">,</span><span class="n">index_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">packed_accessor</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">generic_packed_accessor</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="n">PtrTraits</span><span class="p">,</span><span class="n">index_t</span><span class="o">&gt;</span><span class="p">();</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">template</span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="p">,</span><span class="w"> </span><span class="kt">size_t</span><span class="w"> </span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">U</span><span class="o">&gt;</span><span class="w"> </span><span class="k">class</span><span class="w"> </span><span class="nc">PtrTraits</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">DefaultPtrTraits</span><span class="p">,</span><span class="w"> </span><span class="k">typename</span><span class="w"> </span><span class="nc">index_t</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kt">int64_t</span><span class="o">&gt;</span>
<span class="w">  </span><span class="n">C10_DEPRECATED_MESSAGE</span><span class="p">(</span><span class="s">&quot;packed_accessor is deprecated, use packed_accessor32 or packed_accessor64 instead&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="n">GenericPackedTensorAccessor</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="n">PtrTraits</span><span class="p">,</span><span class="n">index_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">packed_accessor</span><span class="p">()</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">delete</span><span class="p">;</span>

<span class="w">  </span><span class="n">Tensor</span><span class="w"> </span><span class="k">operator</span><span class="o">~</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">bitwise_not</span><span class="p">();</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">Tensor</span><span class="w"> </span><span class="k">operator</span><span class="o">-</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">neg</span><span class="p">();</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="k">operator</span><span class="o">+=</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">add_</span><span class="p">(</span><span class="n">other</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="k">operator</span><span class="o">+=</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">add_</span><span class="p">(</span><span class="n">other</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="k">operator</span><span class="o">-=</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">sub_</span><span class="p">(</span><span class="n">other</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="k">operator</span><span class="o">-=</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">sub_</span><span class="p">(</span><span class="n">other</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="k">operator</span><span class="o">*=</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">mul_</span><span class="p">(</span><span class="n">other</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="k">operator</span><span class="o">*=</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">mul_</span><span class="p">(</span><span class="n">other</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="k">operator</span><span class="o">/=</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">div_</span><span class="p">(</span><span class="n">other</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="k">operator</span><span class="o">/=</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">div_</span><span class="p">(</span><span class="n">other</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="k">operator</span><span class="o">&amp;=</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">bitwise_and_</span><span class="p">(</span><span class="n">other</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="k">operator</span><span class="o">|=</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">bitwise_or_</span><span class="p">(</span><span class="n">other</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="k">operator</span><span class="o">^=</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">bitwise_xor_</span><span class="p">(</span><span class="n">other</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">Tensor</span><span class="w"> </span><span class="k">operator</span><span class="p">[](</span><span class="k">const</span><span class="w"> </span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">index</span><span class="p">.</span><span class="n">isIntegral</span><span class="p">(</span><span class="nb">false</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">TORCH_CHECK_INDEX</span><span class="p">(</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Can only index tensors with integral scalars&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="k">this</span><span class="o">-&gt;</span><span class="k">operator</span><span class="p">[](</span><span class="n">index</span><span class="p">.</span><span class="n">toLong</span><span class="p">());</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">Tensor</span><span class="w"> </span><span class="k">operator</span><span class="p">[](</span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// These properties are checked in the Scalar constructor, but we already</span>
<span class="w">    </span><span class="c1">// check them here to provide more useful diagnostics for the user.</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">index</span><span class="p">.</span><span class="n">defined</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">TORCH_CHECK_INDEX</span><span class="p">(</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Can only index with tensors that are defined&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">index</span><span class="p">.</span><span class="n">dim</span><span class="p">()</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">TORCH_CHECK_INDEX</span><span class="p">(</span><span class="nb">false</span><span class="p">,</span>
<span class="w">                        </span><span class="s">&quot;Can only index with tensors that are scalars (zero-dim)&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="c1">// The Scalar(Tensor) constructor is explicit, so we need to call it.</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="k">this</span><span class="o">-&gt;</span><span class="k">operator</span><span class="p">[](</span><span class="n">index</span><span class="p">.</span><span class="n">item</span><span class="p">());</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">Tensor</span><span class="w"> </span><span class="k">operator</span><span class="p">[](</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">index</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">select</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">Tensor</span><span class="w"> </span><span class="n">index</span><span class="p">(</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">indexing</span><span class="o">::</span><span class="n">TensorIndex</span><span class="o">&gt;</span><span class="w"> </span><span class="n">indices</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">Tensor</span><span class="w"> </span><span class="nf">index</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">initializer_list</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">indexing</span><span class="o">::</span><span class="n">TensorIndex</span><span class="o">&gt;</span><span class="w"> </span><span class="n">indices</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>

<span class="w">  </span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">index_put_</span><span class="p">(</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">indexing</span><span class="o">::</span><span class="n">TensorIndex</span><span class="o">&gt;</span><span class="w"> </span><span class="n">indices</span><span class="p">,</span><span class="w"> </span><span class="n">Tensor</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">rhs</span><span class="p">);</span>
<span class="w">  </span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">index_put_</span><span class="p">(</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">indexing</span><span class="o">::</span><span class="n">TensorIndex</span><span class="o">&gt;</span><span class="w"> </span><span class="n">indices</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">Scalar</span><span class="o">&amp;</span><span class="w"> </span><span class="n">v</span><span class="p">);</span>
<span class="w">  </span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">index_put_</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">initializer_list</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">indexing</span><span class="o">::</span><span class="n">TensorIndex</span><span class="o">&gt;</span><span class="w"> </span><span class="n">indices</span><span class="p">,</span><span class="w"> </span><span class="n">Tensor</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">rhs</span><span class="p">);</span>
<span class="w">  </span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">index_put_</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">initializer_list</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">indexing</span><span class="o">::</span><span class="n">TensorIndex</span><span class="o">&gt;</span><span class="w"> </span><span class="n">indices</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">Scalar</span><span class="o">&amp;</span><span class="w"> </span><span class="n">v</span><span class="p">);</span>

<span class="w">  </span><span class="n">Tensor</span><span class="w"> </span><span class="nf">cpu</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">to</span><span class="p">(</span><span class="n">options</span><span class="p">().</span><span class="n">device</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">DeviceType</span><span class="o">::</span><span class="n">CPU</span><span class="p">),</span><span class="w"> </span><span class="cm">/*non_blocking*/</span><span class="w"> </span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="cm">/*copy*/</span><span class="w"> </span><span class="nb">false</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// TODO: The Python version also accepts arguments</span>
<span class="w">  </span><span class="n">Tensor</span><span class="w"> </span><span class="nf">cuda</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">to</span><span class="p">(</span><span class="n">options</span><span class="p">().</span><span class="n">device</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">DeviceType</span><span class="o">::</span><span class="n">CUDA</span><span class="p">),</span><span class="w"> </span><span class="cm">/*non_blocking*/</span><span class="w"> </span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="cm">/*copy*/</span><span class="w"> </span><span class="nb">false</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">Tensor</span><span class="w"> </span><span class="nf">hip</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">to</span><span class="p">(</span><span class="n">options</span><span class="p">().</span><span class="n">device</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">DeviceType</span><span class="o">::</span><span class="n">HIP</span><span class="p">),</span><span class="w"> </span><span class="cm">/*non_blocking*/</span><span class="w"> </span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="cm">/*copy*/</span><span class="w"> </span><span class="nb">false</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">Tensor</span><span class="w"> </span><span class="nf">ve</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">to</span><span class="p">(</span><span class="n">options</span><span class="p">().</span><span class="n">device</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">DeviceType</span><span class="o">::</span><span class="n">VE</span><span class="p">),</span><span class="w"> </span><span class="cm">/*non_blocking*/</span><span class="w"> </span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="cm">/*copy*/</span><span class="w"> </span><span class="nb">false</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">Tensor</span><span class="w"> </span><span class="nf">vulkan</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">to</span><span class="p">(</span><span class="n">options</span><span class="p">().</span><span class="n">device</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">DeviceType</span><span class="o">::</span><span class="n">Vulkan</span><span class="p">),</span><span class="w"> </span><span class="cm">/*non_blocking*/</span><span class="w"> </span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="cm">/*copy*/</span><span class="w"> </span><span class="nb">false</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">Tensor</span><span class="w"> </span><span class="nf">metal</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">to</span><span class="p">(</span><span class="n">options</span><span class="p">().</span><span class="n">device</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">DeviceType</span><span class="o">::</span><span class="n">Metal</span><span class="p">),</span><span class="w"> </span><span class="cm">/*non_blocking*/</span><span class="w"> </span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="cm">/*copy*/</span><span class="w"> </span><span class="nb">false</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">Tensor</span><span class="w"> </span><span class="nf">meta</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">to</span><span class="p">(</span><span class="n">options</span><span class="p">().</span><span class="n">device</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">DeviceType</span><span class="o">::</span><span class="n">Meta</span><span class="p">),</span><span class="w"> </span><span class="cm">/*non_blocking*/</span><span class="w"> </span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="cm">/*copy*/</span><span class="w"> </span><span class="nb">false</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// ~~~~~ Autograd API ~~~~~</span>


<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="nf">backward</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">gradient</span><span class="o">=</span><span class="p">{},</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">retain_graph</span><span class="o">=</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">create_graph</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">TensorList</span><span class="o">&gt;</span><span class="w"> </span><span class="n">inputs</span><span class="o">=</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// NB: Adding this wrapper to _backward here because we&#39;d like our</span>
<span class="w">    </span><span class="c1">// &#39;backwards&#39; api to accept the &#39;inputs&#39; argument optionally. Since code gen</span>
<span class="w">    </span><span class="c1">// currently does not support optional of TensorList our approach is to replace</span>
<span class="w">    </span><span class="c1">// backward in native_functions.yaml with _backward and call it here instead.</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">inputs</span><span class="p">.</span><span class="n">has_value</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">TORCH_CHECK</span><span class="p">(</span><span class="n">inputs</span><span class="p">.</span><span class="n">value</span><span class="p">().</span><span class="n">size</span><span class="p">()</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;&#39;inputs&#39; argument to backward cannot be empty&quot;</span><span class="p">)</span>
<span class="w">      </span><span class="k">this</span><span class="o">-&gt;</span><span class="n">_backward</span><span class="p">(</span><span class="n">inputs</span><span class="p">.</span><span class="n">value</span><span class="p">(),</span><span class="w"> </span><span class="n">gradient</span><span class="p">,</span><span class="w"> </span><span class="n">retain_graph</span><span class="p">,</span><span class="w"> </span><span class="n">create_graph</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">this</span><span class="o">-&gt;</span><span class="n">_backward</span><span class="p">({},</span><span class="w"> </span><span class="n">gradient</span><span class="p">,</span><span class="w"> </span><span class="n">retain_graph</span><span class="p">,</span><span class="w"> </span><span class="n">create_graph</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>





<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="nf">set_requires_grad</span><span class="p">(</span><span class="kt">bool</span><span class="w"> </span><span class="n">requires_grad</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">TensorBase</span><span class="o">::</span><span class="n">set_requires_grad</span><span class="p">(</span><span class="n">requires_grad</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="o">*</span><span class="k">this</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="nf">mutable_grad</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">impl_</span><span class="o">-&gt;</span><span class="n">mutable_grad</span><span class="p">();</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="nf">grad</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="n">maybe_grad</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">impl_</span><span class="o">-&gt;</span><span class="n">grad</span><span class="p">();</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">is_leaf</span><span class="p">()</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="o">!</span><span class="n">retains_grad</span><span class="p">()</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="o">!</span><span class="n">maybe_grad</span><span class="p">.</span><span class="n">defined</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">TORCH_WARN</span><span class="p">(</span>
<span class="w">        </span><span class="s">&quot;The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad &quot;</span>
<span class="w">        </span><span class="s">&quot;attribute won&#39;t be populated during autograd.backward(). If you indeed want the .grad &quot;</span>
<span class="w">        </span><span class="s">&quot;field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. &quot;</span>
<span class="w">        </span><span class="s">&quot;If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor &quot;</span>
<span class="w">        </span><span class="s">&quot;instead. See github.com/pytorch/pytorch/pull/30531 for more information.&quot;</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">maybe_grad</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// The Forward AD API functions below are low level and are not to be used by end</span>
<span class="w">  </span><span class="c1">// users who should use the API provided in torch/csrc/autograd.h</span>

<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="nf">_fw_grad</span><span class="p">(</span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">level</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">impl_</span><span class="o">-&gt;</span><span class="n">_fw_grad</span><span class="p">(</span><span class="n">level</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="k">this</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="nf">_set_fw_grad</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">TensorBase</span><span class="o">&amp;</span><span class="w"> </span><span class="n">new_grad</span><span class="p">,</span><span class="w"> </span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">level</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">is_inplace_op</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">impl_</span><span class="o">-&gt;</span><span class="n">_set_fw_grad</span><span class="p">(</span><span class="n">new_grad</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="k">this</span><span class="p">,</span><span class="w"> </span><span class="n">level</span><span class="p">,</span><span class="w"> </span><span class="n">is_inplace_op</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>


<span class="w">  </span><span class="c1">// STOP.  Thinking of adding a method here, which only makes use</span>
<span class="w">  </span><span class="c1">// of other ATen methods?  Define it in native_functions.yaml.</span>

<span class="w">  </span><span class="c1">//example</span>
<span class="w">  </span><span class="c1">//Tensor * add(Tensor &amp; b);</span>
<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="nf">__dispatch__backward</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span><span class="w"> </span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">gradient</span><span class="o">=</span><span class="p">{},</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">retain_graph</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">create_graph</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="nf">__dispatch_set_data</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">new_data</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">__dispatch_data</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="nf">__dispatch_is_leaf</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int64_t</span><span class="w"> </span><span class="nf">__dispatch_output_nr</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int64_t</span><span class="w"> </span><span class="nf">__dispatch__version</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">__dispatch_requires_grad_</span><span class="p">(</span><span class="kt">bool</span><span class="w"> </span><span class="n">requires_grad</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="nf">__dispatch_retain_grad</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="nf">__dispatch_retains_grad</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">_fw_primal</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">level</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">rename_</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="o">&gt;</span><span class="w"> </span><span class="n">names</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">rename</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="o">&gt;</span><span class="w"> </span><span class="n">names</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">align_to</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">names</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">align_to</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">order</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">ellipsis_idx</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">align_as</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">refine_names</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">names</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">abs</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">abs_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">absolute</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">absolute_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">angle</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">sgn</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">sgn_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">chalf</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span><span class="w"> </span><span class="n">memory_format</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">_conj</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">__dispatch_conj</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">_conj_physical</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">conj_physical</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">conj_physical_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">resolve_conj</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">resolve_neg</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">_neg_view</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">acos</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">acos_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">arccos</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">arccos_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">add</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">add_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">add</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">add_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">addmv</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mat</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">vec</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">addmv_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mat</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">vec</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">addr</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">vec1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">vec2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">addr_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">vec1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">vec2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">_is_all_true</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">_is_any_true</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">all</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">all</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">OptionalIntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">all</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="nf">allclose</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">rtol</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">atol</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">equal_nan</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">any</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">any</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">OptionalIntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">any</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">argmax</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dim</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">argmin</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dim</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">acosh</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">acosh_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">arccosh</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">arccosh_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">asinh</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">asinh_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">arcsinh</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">arcsinh_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">atanh</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">atanh_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">arctanh</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">arctanh_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">as_strided</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">storage_offset</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">as_strided_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="o">&gt;</span><span class="w"> </span><span class="n">storage_offset</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">as_strided_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">storage_offset</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">as_strided__symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="o">&gt;</span><span class="w"> </span><span class="n">storage_offset</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">asin</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">asin_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">arcsin</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">arcsin_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">atan</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">atan_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">arctan</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">arctan_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">baddbmm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">batch1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">batch2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">baddbmm_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">batch1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">batch2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">bernoulli</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">bernoulli_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">bernoulli_</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">bernoulli</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">bincount</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">weights</span><span class="o">=</span><span class="p">{},</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">minlength</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">bincount_symint</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">weights</span><span class="o">=</span><span class="p">{},</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">minlength</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">bitwise_not</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">bitwise_not_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">copysign</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">copysign_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">copysign</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">copysign_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">_lazy_clone</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">logical_not</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">logical_not_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">logical_xor</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">logical_xor_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">logical_and</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">logical_and_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">logical_or</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">logical_or_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">bmm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mat2</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">broadcast_to</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">broadcast_to_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">ceil</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">ceil_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">unsafe_chunk</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">chunks</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">chunk</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">chunks</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">tensor_split</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">sections</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">tensor_split_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">sections</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">tensor_split</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">indices</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">tensor_split_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">indices</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">tensor_split</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">tensor_indices_or_sections</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">clamp</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">min</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">max</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">clamp</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">min</span><span class="o">=</span><span class="p">{},</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">max</span><span class="o">=</span><span class="p">{})</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">clamp_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">min</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">max</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">clamp_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">min</span><span class="o">=</span><span class="p">{},</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">max</span><span class="o">=</span><span class="p">{})</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">clamp_max</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">max</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">clamp_max</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">max</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">clamp_max_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">max</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">clamp_max_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">max</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">clamp_min</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">min</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">clamp_min</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">min</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">clamp_min_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">min</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">clamp_min_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">min</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">clip</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">min</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">max</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">clip</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">min</span><span class="o">=</span><span class="p">{},</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">max</span><span class="o">=</span><span class="p">{})</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">clip_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">min</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">max</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">clip_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">min</span><span class="o">=</span><span class="p">{},</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">max</span><span class="o">=</span><span class="p">{})</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">__dispatch_contiguous</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="w"> </span><span class="n">memory_format</span><span class="o">=</span><span class="n">c10</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">::</span><span class="n">Contiguous</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">copy_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">non_blocking</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">cos</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">cos_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">cosh</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">cosh_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">count_nonzero</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">count_nonzero</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dim</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">cov</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">correction</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">fweights</span><span class="o">=</span><span class="p">{},</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">aweights</span><span class="o">=</span><span class="p">{})</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">corrcoef</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">cummax</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">cummax</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">cummin</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">cummin</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">cumprod</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">cumprod_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">cumprod</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">cumprod_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">cumsum</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">cumsum_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">cumsum</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">cumsum_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">diag_embed</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim1</span><span class="o">=</span><span class="mi">-2</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim2</span><span class="o">=</span><span class="mi">-1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">diagflat</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">diagonal</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim2</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">diagonal</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">outdim</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim1</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim2</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">fill_diagonal_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">fill_value</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">wrap</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">diff</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">prepend</span><span class="o">=</span><span class="p">{},</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">append</span><span class="o">=</span><span class="p">{})</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">div</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">div_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">div</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span><span class="w"> </span><span class="n">rounding_mode</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">div_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span><span class="w"> </span><span class="n">rounding_mode</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">div</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">div_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">div</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span><span class="w"> </span><span class="n">rounding_mode</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">div_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span><span class="w"> </span><span class="n">rounding_mode</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">divide</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">divide_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">divide</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">divide_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">divide</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span><span class="w"> </span><span class="n">rounding_mode</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">divide_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span><span class="w"> </span><span class="n">rounding_mode</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">divide</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span><span class="w"> </span><span class="n">rounding_mode</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">divide_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span><span class="w"> </span><span class="n">rounding_mode</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">true_divide</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">true_divide_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">true_divide</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">true_divide_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">dot</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">tensor</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">vdot</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">new_empty</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span><span class="w"> </span><span class="n">options</span><span class="o">=</span><span class="p">{})</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">new_empty</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">new_empty_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span><span class="w"> </span><span class="n">options</span><span class="o">=</span><span class="p">{})</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">new_empty_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">new_empty_strided</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span><span class="w"> </span><span class="n">options</span><span class="o">=</span><span class="p">{})</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">new_empty_strided</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">new_empty_strided_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span><span class="w"> </span><span class="n">options</span><span class="o">=</span><span class="p">{})</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">new_empty_strided_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">new_full</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">fill_value</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span><span class="w"> </span><span class="n">options</span><span class="o">=</span><span class="p">{})</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">new_full</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">fill_value</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">new_full_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">fill_value</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span><span class="w"> </span><span class="n">options</span><span class="o">=</span><span class="p">{})</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">new_full_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">fill_value</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">new_zeros</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span><span class="w"> </span><span class="n">options</span><span class="o">=</span><span class="p">{})</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">new_zeros</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">new_zeros_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span><span class="w"> </span><span class="n">options</span><span class="o">=</span><span class="p">{})</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">new_zeros_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">new_ones</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span><span class="w"> </span><span class="n">options</span><span class="o">=</span><span class="p">{})</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">new_ones</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">new_ones_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span><span class="w"> </span><span class="n">options</span><span class="o">=</span><span class="p">{})</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">new_ones_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">resize_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span><span class="w"> </span><span class="n">memory_format</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">resize__symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span><span class="w"> </span><span class="n">memory_format</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">erf</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">erf_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">erfc</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">erfc_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">exp</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">exp_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">exp2</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">exp2_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">expm1</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">expm1_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">expand</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">implicit</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">expand_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">implicit</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">expand_as</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">flatten</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">start_dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">end_dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">flatten</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">start_dim</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">end_dim</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">out_dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">flatten</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">start_dim</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">end_dim</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">out_dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">flatten</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">dims</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">out_dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">unflatten</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">sizes</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">unflatten_symint</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">sizes</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">unflatten</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">sizes</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">names</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">unflatten_symint</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">sizes</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">names</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">fill_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">fill_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">floor</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">floor_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">floor_divide</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">floor_divide_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">floor_divide</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">floor_divide_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">frac</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">frac_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">gcd</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">gcd_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">lcm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">lcm_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">index</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">List</span><span class="o">&lt;::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">indices</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">index_copy_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">index_copy</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">index_copy_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">index_copy</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">index_put_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">List</span><span class="o">&lt;::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">indices</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">values</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">accumulate</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">index_put</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">List</span><span class="o">&lt;::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">indices</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">values</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">accumulate</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">isclose</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">rtol</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">atol</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">equal_nan</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">isnan</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="nf">is_distributed</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="nf">__dispatch_is_floating_point</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="nf">__dispatch_is_complex</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="nf">__dispatch_is_conj</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="nf">__dispatch__is_zerotensor</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="nf">__dispatch_is_neg</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">isreal</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="nf">is_nonzero</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="nf">is_same_size</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="nf">__dispatch_is_signed</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="nf">__dispatch_is_inference</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">kron</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">kthvalue</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">kthvalue_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">kthvalue</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">kthvalue_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">nan_to_num</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="w"> </span><span class="n">nan</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="w"> </span><span class="n">posinf</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="w"> </span><span class="n">neginf</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">nan_to_num_</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="w"> </span><span class="n">nan</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="w"> </span><span class="n">posinf</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="w"> </span><span class="n">neginf</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">ldexp</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">ldexp_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">log</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">log_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">log10</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">log10_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">log1p</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">log1p_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">log2</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">log2_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">logaddexp</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">logaddexp2</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">xlogy</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">xlogy</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">xlogy_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">xlogy_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">log_softmax</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">log_softmax</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">logcumsumexp</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">logcumsumexp</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">logsumexp</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">logsumexp</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">matmul</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">matrix_power</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">matrix_exp</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">aminmax</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dim</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">max</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">max</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">amax</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="p">{},</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">OptionalIntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">mean</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">nanmean</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">OptionalIntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">median</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">median</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">median</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">nanmedian</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">nanmedian</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">nanmedian</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">min</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">min</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">amin</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="p">{},</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">mm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mat2</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">mode</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">mode</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">mul</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">mul_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">mul</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">mul_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">multiply</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">multiply_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">multiply</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">multiply_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">mv</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">vec</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">mvlgamma</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">p</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">mvlgamma_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">p</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">narrow_copy</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">length</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">narrow_copy_symint</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">length</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">narrow</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">length</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">narrow_symint</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">length</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">narrow</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">length</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">narrow_symint</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">length</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">permute</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dims</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">movedim</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">destination</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">movedim</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">destination</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">moveaxis</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">destination</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">moveaxis</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">destination</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">numpy_T</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">matrix_H</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">mT</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">mH</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">adjoint</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="nf">is_pinned</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span><span class="w"> </span><span class="n">device</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">pin_memory</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span><span class="w"> </span><span class="n">device</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">pinverse</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">rcond</span><span class="o">=</span><span class="mf">1e-15</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">rad2deg</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">rad2deg_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">deg2rad</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">deg2rad_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">ravel</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">reciprocal</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">reciprocal_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">neg</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">neg_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">negative</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">negative_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">repeat</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">repeats</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">repeat_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">repeats</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">repeat_interleave</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">repeats</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dim</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">output_size</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">repeat_interleave_symint</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">repeats</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dim</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="o">&gt;</span><span class="w"> </span><span class="n">output_size</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">repeat_interleave</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">repeats</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dim</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">output_size</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">repeat_interleave_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">repeats</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dim</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="o">&gt;</span><span class="w"> </span><span class="n">output_size</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">reshape</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">shape</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">reshape_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">shape</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">_reshape_alias</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">_reshape_alias_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">reshape_as</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">round</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">round_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">round</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">decimals</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">round_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">decimals</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">relu</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">relu_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">prelu</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">weight</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">hardshrink</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">lambd</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">hardshrink_backward</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">grad_out</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">lambd</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">rsqrt</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">rsqrt_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">select</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">index</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">select</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">index</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">select_symint</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">index</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">sigmoid</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">sigmoid_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">logit</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="w"> </span><span class="n">eps</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">logit_</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="w"> </span><span class="n">eps</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">sin</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">sin_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">sinc</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">sinc_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">sinh</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">sinh_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">detach</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">detach_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int64_t</span><span class="w"> </span><span class="nf">size</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">slice</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">start</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">end</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">slice_symint</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="o">&gt;</span><span class="w"> </span><span class="n">start</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="o">&gt;</span><span class="w"> </span><span class="n">end</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">slice_inverse</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">start</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">end</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">slice_inverse_symint</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="o">&gt;</span><span class="w"> </span><span class="n">start</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="o">&gt;</span><span class="w"> </span><span class="n">end</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">slice_scatter</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">start</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">end</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">slice_scatter_symint</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="o">&gt;</span><span class="w"> </span><span class="n">start</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="o">&gt;</span><span class="w"> </span><span class="n">end</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">select_scatter</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">index</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">select_scatter_symint</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">index</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">diagonal_scatter</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim2</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">as_strided_scatter</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">storage_offset</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">as_strided_scatter_symint</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="o">&gt;</span><span class="w"> </span><span class="n">storage_offset</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">smm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mat2</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">softmax</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">softmax</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">unsafe_split</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">split_size</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">unsafe_split_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">split_size</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">split</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">split_size</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">split_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">split_size</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">split</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">split_size</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">split_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">split_size</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">unsafe_split_with_sizes</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">split_sizes</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">unsafe_split_with_sizes_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">split_sizes</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">split_with_sizes</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">split_sizes</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">split_with_sizes_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">split_sizes</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">hsplit</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">sections</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">hsplit</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">indices</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">vsplit</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">sections</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">vsplit</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">indices</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dsplit</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">sections</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dsplit</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">indices</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">squeeze</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">squeeze</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">squeeze</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">squeeze</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">squeeze_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">squeeze_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">squeeze_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">squeeze_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">sspaddmm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mat1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mat2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">stft</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">n_fft</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">hop_length</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">win_length</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">window</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">normalized</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">onesided</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">return_complex</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">align_to_window</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">stft</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">n_fft</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">hop_length</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">win_length</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">window</span><span class="o">=</span><span class="p">{},</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">center</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="w"> </span><span class="n">pad_mode</span><span class="o">=</span><span class="s">&quot;reflect&quot;</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">normalized</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">onesided</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">return_complex</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">align_to_window</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">istft</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">n_fft</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">hop_length</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">win_length</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">window</span><span class="o">=</span><span class="p">{},</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">center</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">normalized</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">onesided</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">length</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">return_complex</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int64_t</span><span class="w"> </span><span class="nf">stride</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">OptionalIntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">nansum</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">OptionalIntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">hash_tensor</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="p">{},</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">mode</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">sum_to_size</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">sum_to_size_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">sqrt</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">sqrt_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">square</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">square_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">std</span><span class="p">(</span><span class="kt">bool</span><span class="w"> </span><span class="n">unbiased</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">std</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">OptionalIntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">unbiased</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">std</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">OptionalIntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">correction</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">std</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">unbiased</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">std</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">correction</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">prod</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">prod</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">prod</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">t</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">t_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">tan</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">tan_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">tanh</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">tanh_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">tile</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dims</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">tile_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">dims</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">transpose</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim0</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">transpose</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim0</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">transpose_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim0</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">flip</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dims</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">fliplr</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">flipud</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">roll</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">shifts</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dims</span><span class="o">=</span><span class="p">{})</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">roll_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">shifts</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dims</span><span class="o">=</span><span class="p">{})</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">rot90</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dims</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">})</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">_nested_tensor_size</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">_nested_tensor_strides</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">_nested_tensor_storage_offsets</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">trunc</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">trunc_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">fix</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">fix_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">type_as</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">unsqueeze</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">unsqueeze_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">var</span><span class="p">(</span><span class="kt">bool</span><span class="w"> </span><span class="n">unbiased</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">var</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">OptionalIntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">unbiased</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">var</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">OptionalIntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">correction</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">var</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">unbiased</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">var</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">correction</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">view_as</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">where</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">condition</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">where</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">condition</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">norm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">norm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">norm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">norm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">norm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">norm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">frexp</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">clone</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span><span class="w"> </span><span class="n">memory_format</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">positive</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">resize_as_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">the_template</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span><span class="w"> </span><span class="n">memory_format</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">resize_as_sparse_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">the_template</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">zero_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">sub</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">sub_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">sub</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">sub_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">subtract</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">subtract_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">subtract</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">subtract_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">heaviside</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">values</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">heaviside_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">values</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">addmm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mat1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mat2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">addmm_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mat1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mat2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">_addmm_activation</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mat1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mat2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">use_gelu</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">sparse_resize_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">sparse_dim</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dense_dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">sparse_resize_and_clear_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">sparse_dim</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dense_dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">sparse_mask</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mask</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">_sparse_mask_projection</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mask</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">accumulate_matches</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">to_dense</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">masked_grad</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">_to_dense</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">masked_grad</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int64_t</span><span class="w"> </span><span class="nf">sparse_dim</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int64_t</span><span class="w"> </span><span class="nf">_dimI</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int64_t</span><span class="w"> </span><span class="nf">dense_dim</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int64_t</span><span class="w"> </span><span class="nf">_dimV</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int64_t</span><span class="w"> </span><span class="nf">_nnz</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">coalesce</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="nf">is_coalesced</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">_indices</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">_values</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">_coalesced_</span><span class="p">(</span><span class="kt">bool</span><span class="w"> </span><span class="n">coalesced</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">indices</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">values</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">crow_indices</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">col_indices</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">ccol_indices</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">row_indices</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">unbind</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">unbind</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">to_sparse</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">sparse_dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">_to_sparse</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">sparse_dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">to_sparse</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span><span class="w"> </span><span class="n">layout</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">OptionalIntArrayRef</span><span class="w"> </span><span class="n">blocksize</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dense_dim</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">_to_sparse</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span><span class="w"> </span><span class="n">layout</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">OptionalIntArrayRef</span><span class="w"> </span><span class="n">blocksize</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dense_dim</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">to_sparse_csr</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dense_dim</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">_to_sparse_csr</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dense_dim</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">to_sparse_csc</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dense_dim</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">_to_sparse_csc</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dense_dim</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">to_sparse_bsr</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">blocksize</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dense_dim</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">_to_sparse_bsr</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">blocksize</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dense_dim</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">to_sparse_bsc</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">blocksize</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dense_dim</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">_to_sparse_bsc</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">blocksize</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dense_dim</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">to_mkldnn</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">dequantize</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">double</span><span class="w"> </span><span class="nf">q_scale</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int64_t</span><span class="w"> </span><span class="nf">q_zero_point</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">q_per_channel_scales</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">q_per_channel_zero_points</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">int64_t</span><span class="w"> </span><span class="nf">q_per_channel_axis</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">int_repr</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">QScheme</span><span class="w"> </span><span class="nf">qscheme</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">_autocast_to_reduced_precision</span><span class="p">(</span><span class="kt">bool</span><span class="w"> </span><span class="n">cuda_enabled</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">cpu_enabled</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="w"> </span><span class="n">cuda_dtype</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="w"> </span><span class="n">cpu_dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">_autocast_to_full_precision</span><span class="p">(</span><span class="kt">bool</span><span class="w"> </span><span class="n">cuda_enabled</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">cpu_enabled</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">to</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span><span class="w"> </span><span class="n">options</span><span class="o">=</span><span class="p">{},</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">non_blocking</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">copy</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span><span class="w"> </span><span class="n">memory_format</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">to</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">non_blocking</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">copy</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span><span class="w"> </span><span class="n">memory_format</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">to</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">non_blocking</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">copy</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span><span class="w"> </span><span class="n">memory_format</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">to</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">non_blocking</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">copy</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span><span class="w"> </span><span class="n">memory_format</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">to</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">non_blocking</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">copy</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span><span class="w"> </span><span class="n">memory_format</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="nf">item</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">set_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Storage</span><span class="w"> </span><span class="n">source</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">set_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Storage</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">storage_offset</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="o">=</span><span class="p">{})</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">set__symint</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Storage</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">storage_offset</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="o">=</span><span class="p">{})</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">set_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">storage_offset</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="o">=</span><span class="p">{})</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">set__symint</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">storage_offset</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="o">=</span><span class="p">{})</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">set_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">set_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="nf">is_set_to</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">tensor</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">masked_fill_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mask</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">masked_fill</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mask</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">masked_fill_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mask</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">masked_fill</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mask</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">masked_scatter_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mask</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">masked_scatter</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mask</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">view</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">view_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">view</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">put_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">accumulate</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">put</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">accumulate</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">index_add_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">index_add</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">index_add</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">index_reduce_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="w"> </span><span class="n">reduce</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">include_self</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">index_reduce</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="w"> </span><span class="n">reduce</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">include_self</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">index_fill_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">index_fill</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">index_fill_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">index_fill</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">index_fill_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">index_fill_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">index_fill</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">index_fill</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">scatter</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">scatter_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">scatter</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">scatter_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">scatter</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="w"> </span><span class="n">reduce</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">scatter_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="w"> </span><span class="n">reduce</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">scatter</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="w"> </span><span class="n">reduce</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">scatter_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="w"> </span><span class="n">reduce</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">scatter</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">scatter</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">scatter_add</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">scatter_add_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">scatter_add</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">scatter_reduce</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="w"> </span><span class="n">reduce</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">include_self</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">scatter_reduce_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="w"> </span><span class="n">reduce</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">include_self</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">eq_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">eq_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">bitwise_and</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">bitwise_and</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">bitwise_and_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">bitwise_and_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">__and__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">__and__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">__iand__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">__iand__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">bitwise_or</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">bitwise_or</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">bitwise_or_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">bitwise_or_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">__or__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">__or__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">__ior__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">__ior__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">bitwise_xor</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">bitwise_xor</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">bitwise_xor_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">bitwise_xor_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">__xor__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">__xor__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">__ixor__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">__ixor__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">__lshift__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">__lshift__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">__ilshift__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">__ilshift__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">bitwise_left_shift</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">bitwise_left_shift_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">bitwise_left_shift</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">bitwise_left_shift_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">__rshift__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">__rshift__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">__irshift__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">__irshift__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">bitwise_right_shift</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">bitwise_right_shift_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">bitwise_right_shift</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">bitwise_right_shift_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">tril_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">diagonal</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">triu_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">diagonal</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">digamma_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">lerp_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">end</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">weight</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">lerp_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">end</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">weight</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">addbmm_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">batch1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">batch2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">addbmm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">batch1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">batch2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">random_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">from</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">to</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">random_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">to</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">random_</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">uniform_</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">from</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">to</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">cauchy_</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">median</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">log_normal_</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">std</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">exponential_</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">lambd</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">geometric_</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">diag</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">diagonal</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">cross</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dim</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">triu</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">diagonal</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">tril</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">diagonal</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">trace</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">ne</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">ne</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">ne_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">ne_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">not_equal</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">not_equal</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">not_equal_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">not_equal_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">eq</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">eq</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">ge</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">ge</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">ge_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">ge_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">greater_equal</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">greater_equal</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">greater_equal_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">greater_equal_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">le</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">le</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">le_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">le_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">less_equal</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">less_equal</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">less_equal_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">less_equal_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">gt</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">gt</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">gt_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">gt_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">greater</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">greater</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">greater_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">greater_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">lt</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">lt</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">lt_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">lt_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">less</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">less</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">less_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">less_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">take</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">take_along_dim</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">indices</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dim</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">index_select</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">index_select</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">masked_select</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mask</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">nonzero</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">nonzero_static</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">fill_value</span><span class="o">=</span><span class="mi">-1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">nonzero_static_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">fill_value</span><span class="o">=</span><span class="mi">-1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">nonzero_numpy</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">argwhere</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">gather</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">sparse_grad</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">gather</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">sparse_grad</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">addcmul</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">tensor1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">tensor2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">addcmul_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">tensor1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">tensor2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">addcdiv</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">tensor1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">tensor2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">addcdiv_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">tensor1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">tensor2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">triangular_solve</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">upper</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">transpose</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">unitriangular</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">svd</span><span class="p">(</span><span class="kt">bool</span><span class="w"> </span><span class="n">some</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">compute_uv</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">swapaxes</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">axis0</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">axis1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">swapaxes_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">axis0</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">axis1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">swapdims</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim0</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">swapdims_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim0</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">cholesky</span><span class="p">(</span><span class="kt">bool</span><span class="w"> </span><span class="n">upper</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">cholesky_solve</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">input2</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">upper</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">cholesky_inverse</span><span class="p">(</span><span class="kt">bool</span><span class="w"> </span><span class="n">upper</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">qr</span><span class="p">(</span><span class="kt">bool</span><span class="w"> </span><span class="n">some</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">geqrf</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">orgqr</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">input2</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">ormqr</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">input2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">input3</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">left</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">transpose</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">lu_solve</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">LU_data</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">LU_pivots</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">multinomial</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">num_samples</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">replacement</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">multinomial_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">num_samples</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">replacement</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">lgamma_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">lgamma</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">digamma</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">polygamma</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">polygamma_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">erfinv</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">erfinv_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">i0</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">i0_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">sign</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">sign_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">signbit</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">dist</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">atan2_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">atan2</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">arctan2</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">arctan2_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">lerp</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">end</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">weight</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">lerp</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">end</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">weight</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">histc</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">max</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">histogram</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">bins</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">weight</span><span class="o">=</span><span class="p">{},</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">density</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">histogram</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="n">range</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">weight</span><span class="o">=</span><span class="p">{},</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">density</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">fmod</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">fmod_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">fmod</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">fmod_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">hypot</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">hypot_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">igamma</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">igamma_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">igammac</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">igammac_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">nextafter</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">nextafter_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">remainder</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">remainder_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">remainder</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">remainder_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">min</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">fmin</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">max</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">fmax</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">maximum</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">max</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">minimum</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">min</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">quantile</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">q</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dim</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="w"> </span><span class="n">interpolation</span><span class="o">=</span><span class="s">&quot;linear&quot;</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">quantile</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">q</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dim</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="w"> </span><span class="n">interpolation</span><span class="o">=</span><span class="s">&quot;linear&quot;</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">nanquantile</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">q</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dim</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="w"> </span><span class="n">interpolation</span><span class="o">=</span><span class="s">&quot;linear&quot;</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">nanquantile</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">q</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dim</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="w"> </span><span class="n">interpolation</span><span class="o">=</span><span class="s">&quot;linear&quot;</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">sort</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">descending</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">sort</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">stable</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">descending</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">sort</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">descending</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">sort</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">stable</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">descending</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">msort</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">argsort</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">descending</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">argsort</span><span class="p">(</span><span class="kt">bool</span><span class="w"> </span><span class="n">stable</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">descending</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">argsort</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">descending</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">topk</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">largest</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">sorted</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">topk_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="o">=</span><span class="mi">-1</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">largest</span><span class="o">=</span><span class="nb">true</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">sorted</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">all</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">any</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">renorm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">maxnorm</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">renorm_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">maxnorm</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">unfold</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dimension</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">step</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="nf">equal</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">pow</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">exponent</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">pow</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">exponent</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">pow_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">exponent</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">pow_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">exponent</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">float_power</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">exponent</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">float_power</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">exponent</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">float_power_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">exponent</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">float_power_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">exponent</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">normal_</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">std</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">alias</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">isfinite</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">isinf</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="nf">record_stream</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Stream</span><span class="w"> </span><span class="n">s</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">isposinf</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">isneginf</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">det</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">slogdet</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">logdet</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">inverse</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">inner</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">outer</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">vec2</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">ger</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">vec2</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">to_padded_tensor</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">padding</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">OptionalIntArrayRef</span><span class="w"> </span><span class="n">output_size</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">to_padded_tensor_symint</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">padding</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">OptionalSymIntArrayRef</span><span class="w"> </span><span class="n">output_size</span><span class="o">=::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Special C++ only overloads for std()-like functions (See gh-40287)</span>
<span class="w">  </span><span class="c1">// These are needed because int -&gt; bool conversion takes precedence over int -&gt; IntArrayRef</span>
<span class="w">  </span><span class="c1">// So, for example std(0) would select the std(unbiased=False) overload</span>

<span class="w">  </span><span class="n">Tensor</span><span class="w"> </span><span class="nf">var</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">var</span><span class="p">(</span><span class="n">IntArrayRef</span><span class="p">{</span><span class="n">dim</span><span class="p">});</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">Tensor</span><span class="w"> </span><span class="nf">std</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">std</span><span class="p">(</span><span class="n">IntArrayRef</span><span class="p">{</span><span class="n">dim</span><span class="p">});</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// We changed .dtype() to return a TypeMeta in #12766. Ideally, we want the</span>
<span class="w">  </span><span class="c1">// at::kDouble and its friends to be TypeMeta&#39;s, but that hasn&#39;t happened yet.</span>
<span class="w">  </span><span class="c1">// Before that change, we make this method to maintain BC for C++ usage like</span>
<span class="w">  </span><span class="c1">// `x.to(y.dtype)`.</span>
<span class="w">  </span><span class="c1">// TODO: remove following two after at::kDouble and its friends are TypeMeta&#39;s.</span>
<span class="w">  </span><span class="kr">inline</span><span class="w"> </span><span class="n">Tensor</span><span class="w"> </span><span class="nf">to</span><span class="p">(</span><span class="n">caffe2</span><span class="o">::</span><span class="n">TypeMeta</span><span class="w"> </span><span class="n">type_meta</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">non_blocking</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">copy</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="k">this</span><span class="o">-&gt;</span><span class="n">to</span><span class="p">(</span><span class="cm">/*scalar_type=*/</span><span class="n">typeMetaToScalarType</span><span class="p">(</span><span class="n">type_meta</span><span class="p">),</span><span class="w"> </span><span class="n">non_blocking</span><span class="p">,</span><span class="w"> </span><span class="n">copy</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="kr">inline</span><span class="w"> </span><span class="n">Tensor</span><span class="w"> </span><span class="nf">to</span><span class="p">(</span><span class="n">Device</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="n">caffe2</span><span class="o">::</span><span class="n">TypeMeta</span><span class="w"> </span><span class="n">type_meta</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">non_blocking</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">copy</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="k">this</span><span class="o">-&gt;</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="cm">/*scalar_type=*/</span><span class="n">typeMetaToScalarType</span><span class="p">(</span><span class="n">type_meta</span><span class="p">),</span><span class="w"> </span><span class="n">non_blocking</span><span class="p">,</span><span class="w"> </span><span class="n">copy</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">F</span><span class="p">,</span><span class="w"> </span><span class="k">typename</span><span class="p">...</span><span class="w"> </span><span class="n">Args</span><span class="o">&gt;</span>
<span class="w">  </span><span class="k">decltype</span><span class="p">(</span><span class="k">auto</span><span class="p">)</span><span class="w"> </span><span class="n">m</span><span class="p">(</span><span class="n">F</span><span class="w"> </span><span class="n">func</span><span class="p">,</span><span class="w"> </span><span class="n">Args</span><span class="o">&amp;&amp;</span><span class="p">...</span><span class="w"> </span><span class="n">params</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">forward</span><span class="o">&lt;</span><span class="n">Args</span><span class="o">&gt;</span><span class="p">(</span><span class="n">params</span><span class="p">)...);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">tensor_data</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">TensorBase</span><span class="o">::</span><span class="n">tensor_data</span><span class="p">();</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">variable_data</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">TensorBase</span><span class="o">::</span><span class="n">variable_data</span><span class="p">();</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Hooks</span>
<span class="w">  </span><span class="c1">//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span>

<span class="w">  </span><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="o">&gt;</span>
<span class="w">  </span><span class="k">using</span><span class="w"> </span><span class="n">hook_return_void_t</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">enable_if_t</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">is_void</span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">std</span><span class="o">::</span><span class="n">invoke_result_t</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&amp;</span><span class="p">,</span><span class="w"> </span><span class="n">Tensor</span><span class="o">&gt;&gt;::</span><span class="n">value</span><span class="p">,</span><span class="w"> </span><span class="kt">unsigned</span><span class="o">&gt;</span><span class="p">;</span>
<span class="w">  </span><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="o">&gt;</span>
<span class="w">  </span><span class="k">using</span><span class="w"> </span><span class="n">hook_return_var_t</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">enable_if_t</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">is_same_v</span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">std</span><span class="o">::</span><span class="n">invoke_result_t</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&amp;</span><span class="p">,</span><span class="w"> </span><span class="n">Tensor</span><span class="o">&gt;</span><span class="p">,</span><span class="w"> </span><span class="n">Tensor</span><span class="o">&gt;</span><span class="p">,</span><span class="w"> </span><span class="kt">unsigned</span><span class="o">&gt;</span><span class="p">;</span>

<span class="w">  </span><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="o">&gt;</span>
<span class="w">  </span><span class="n">hook_return_void_t</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="w"> </span><span class="n">register_hook</span><span class="p">(</span><span class="n">T</span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">hook</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>
<span class="w">  </span><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="o">&gt;</span>
<span class="w">  </span><span class="n">hook_return_var_t</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="w"> </span><span class="n">register_hook</span><span class="p">(</span><span class="n">T</span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">hook</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>

<span class="w">  </span><span class="c1">// Variable methods</span>
<span class="w">  </span><span class="c1">//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span>

<span class="w">  </span><span class="n">Tensor</span><span class="w"> </span><span class="nf">data</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">TensorBase</span><span class="o">::</span><span class="n">data</span><span class="p">();</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="nf">_backward</span><span class="p">(</span><span class="n">TensorList</span><span class="w"> </span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">gradient</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">keep_graph</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">create_graph</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="p">;</span>

<span class="w">  </span><span class="k">const</span><span class="w"> </span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="nf">requires_grad_</span><span class="p">(</span><span class="kt">bool</span><span class="w"> </span><span class="n">_requires_grad</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">TensorBase</span><span class="o">::</span><span class="n">requires_grad_</span><span class="p">(</span><span class="n">_requires_grad</span><span class="p">);</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="o">*</span><span class="k">this</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">};</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">detail</span><span class="w"> </span><span class="p">{</span>
<span class="c1">// Helper creator for Tensor class which doesn&#39;t requires the users to pass</span>
<span class="c1">// in an intrusive_ptr instead it just converts the argument passed to</span>
<span class="c1">// requested intrusive_ptr type.</span>
<span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="p">,</span><span class="w"> </span><span class="k">typename</span><span class="p">...</span><span class="w"> </span><span class="n">Args</span><span class="o">&gt;</span>
<span class="n">Tensor</span><span class="w"> </span><span class="n">make_tensor</span><span class="p">(</span><span class="n">Args</span><span class="o">&amp;&amp;</span><span class="p">...</span><span class="w"> </span><span class="n">args</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">Tensor</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">make_intrusive</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">forward</span><span class="o">&lt;</span><span class="n">Args</span><span class="o">&gt;</span><span class="p">(</span><span class="n">args</span><span class="p">)...));</span>
<span class="p">}</span>

<span class="p">}</span><span class="w"> </span><span class="c1">// namespace detail</span>

<span class="p">}</span><span class="w"> </span><span class="c1">// namespace at</span>


<span class="k">namespace</span><span class="w"> </span><span class="nn">at</span><span class="w"> </span><span class="p">{</span>

<span class="c1">// aten::_backward(Tensor self, Tensor[] inputs, Tensor? gradient=None, bool? retain_graph=None, bool create_graph=False) -&gt; ()</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="nf">Tensor::__dispatch__backward</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorList</span><span class="w"> </span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">gradient</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">retain_graph</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">create_graph</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">gradient</span><span class="p">,</span><span class="w"> </span><span class="n">retain_graph</span><span class="p">,</span><span class="w"> </span><span class="n">create_graph</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::set_data(Tensor(a!) self, Tensor new_data) -&gt; ()</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="nf">Tensor::__dispatch_set_data</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">new_data</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">set_data</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">new_data</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::data(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::__dispatch_data</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">data</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::is_leaf(Tensor self) -&gt; bool</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="nf">Tensor::__dispatch_is_leaf</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">is_leaf</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::output_nr(Tensor self) -&gt; int</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="nf">Tensor::__dispatch_output_nr</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">output_nr</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::_version(Tensor self) -&gt; int</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="nf">Tensor::__dispatch__version</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_version</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::requires_grad_(Tensor(a!) self, bool requires_grad=True) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::__dispatch_requires_grad_</span><span class="p">(</span><span class="kt">bool</span><span class="w"> </span><span class="n">requires_grad</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">requires_grad_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">requires_grad</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::retain_grad(Tensor(a!) self) -&gt; ()</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="nf">Tensor::__dispatch_retain_grad</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">retain_grad</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::retains_grad(Tensor self) -&gt; bool</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="nf">Tensor::__dispatch_retains_grad</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">retains_grad</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::_fw_primal(Tensor(a) self, int level) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::_fw_primal</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">level</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_fw_primal</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">level</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rename_(Tensor(a!) self, Dimname[]? names) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::rename_</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="o">&gt;</span><span class="w"> </span><span class="n">names</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rename_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">names</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rename(Tensor(a) self, Dimname[]? names) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::rename</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="o">&gt;</span><span class="w"> </span><span class="n">names</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rename</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">names</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::align_to(Tensor(a) self, Dimname[] names) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::align_to</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">names</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">align_to</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">names</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::align_to.ellipsis_idx(Tensor(a) self, Dimname[] order, int ellipsis_idx) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::align_to</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">order</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">ellipsis_idx</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">align_to_ellipsis_idx</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">order</span><span class="p">,</span><span class="w"> </span><span class="n">ellipsis_idx</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::align_as(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::align_as</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">align_as</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::refine_names(Tensor(a) self, Dimname[] names) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::refine_names</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">names</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">refine_names</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">names</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::abs(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::abs</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">abs</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::abs_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::abs_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">abs_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::absolute(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::absolute</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">absolute</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::absolute_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::absolute_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">absolute_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::angle(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::angle</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">angle</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::sgn(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::sgn</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sgn</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::sgn_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::sgn_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sgn_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::chalf(Tensor self, *, MemoryFormat? memory_format=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::chalf</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span><span class="w"> </span><span class="n">memory_format</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">chalf</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">memory_format</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_conj(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::_conj</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_conj</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::conj(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::__dispatch_conj</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">conj</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::_conj_physical(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::_conj_physical</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_conj_physical</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::conj_physical(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::conj_physical</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">conj_physical</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::conj_physical_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::conj_physical_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">conj_physical_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::resolve_conj(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::resolve_conj</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">resolve_conj</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::resolve_neg(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::resolve_neg</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">resolve_neg</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::_neg_view(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::_neg_view</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_neg_view</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::acos(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::acos</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">acos</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::acos_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::acos_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">acos_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::arccos(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::arccos</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arccos</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::arccos_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::arccos_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arccos_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::add</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">add_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::add_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::add_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">add__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::add</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">add_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::add_.Scalar(Tensor(a!) self, Scalar other, Scalar alpha=1) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::add_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">add__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addmv(Tensor self, Tensor mat, Tensor vec, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::addmv</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mat</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">vec</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">beta</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addmv</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">mat</span><span class="p">,</span><span class="w"> </span><span class="n">vec</span><span class="p">,</span><span class="w"> </span><span class="n">beta</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addmv_(Tensor(a!) self, Tensor mat, Tensor vec, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::addmv_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mat</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">vec</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">beta</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addmv_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">mat</span><span class="p">,</span><span class="w"> </span><span class="n">vec</span><span class="p">,</span><span class="w"> </span><span class="n">beta</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addr(Tensor self, Tensor vec1, Tensor vec2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::addr</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">vec1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">vec2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">beta</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addr</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">vec1</span><span class="p">,</span><span class="w"> </span><span class="n">vec2</span><span class="p">,</span><span class="w"> </span><span class="n">beta</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addr_(Tensor(a!) self, Tensor vec1, Tensor vec2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::addr_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">vec1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">vec2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">beta</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addr_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">vec1</span><span class="p">,</span><span class="w"> </span><span class="n">vec2</span><span class="p">,</span><span class="w"> </span><span class="n">beta</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_is_all_true(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::_is_all_true</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_is_all_true</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::_is_any_true(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::_is_any_true</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_is_any_true</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::all.dim(Tensor self, int dim, bool keepdim=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::all</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">all_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::all.dims(Tensor self, int[]? dim=None, bool keepdim=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::all</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">OptionalIntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">all_dims</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::all.dimname(Tensor self, Dimname dim, bool keepdim=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::all</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">all_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::allclose(Tensor self, Tensor other, float rtol=1e-05, float atol=1e-08, bool equal_nan=False) -&gt; bool</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="nf">Tensor::allclose</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">rtol</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">atol</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">equal_nan</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">allclose</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="n">rtol</span><span class="p">,</span><span class="w"> </span><span class="n">atol</span><span class="p">,</span><span class="w"> </span><span class="n">equal_nan</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::any.dim(Tensor self, int dim, bool keepdim=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::any</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">any_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::any.dims(Tensor self, int[]? dim=None, bool keepdim=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::any</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">OptionalIntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">any_dims</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::any.dimname(Tensor self, Dimname dim, bool keepdim=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::any</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">any_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::argmax(Tensor self, int? dim=None, bool keepdim=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::argmax</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">argmax</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::argmin(Tensor self, int? dim=None, bool keepdim=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::argmin</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">argmin</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::acosh(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::acosh</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">acosh</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::acosh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::acosh_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">acosh_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::arccosh(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::arccosh</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arccosh</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::arccosh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::arccosh_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arccosh_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::asinh(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::asinh</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">asinh</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::asinh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::asinh_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">asinh_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::arcsinh(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::arcsinh</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arcsinh</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::arcsinh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::arcsinh_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arcsinh_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::atanh(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::atanh</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">atanh</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::atanh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::atanh_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">atanh_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::arctanh(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::arctanh</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arctanh</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::arctanh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::arctanh_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arctanh_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::as_strided</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">storage_offset</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">as_strided</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">size</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">stride</span><span class="p">),</span><span class="w"> </span><span class="n">storage_offset</span><span class="p">.</span><span class="n">has_value</span><span class="p">()</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">make_optional</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="p">(</span><span class="o">*</span><span class="n">storage_offset</span><span class="p">))</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::as_strided_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="o">&gt;</span><span class="w"> </span><span class="n">storage_offset</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">as_strided</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">stride</span><span class="p">,</span><span class="w"> </span><span class="n">storage_offset</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::as_strided_(Tensor(a!) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::as_strided_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">storage_offset</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">as_strided_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">size</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">stride</span><span class="p">),</span><span class="w"> </span><span class="n">storage_offset</span><span class="p">.</span><span class="n">has_value</span><span class="p">()</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">make_optional</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="p">(</span><span class="o">*</span><span class="n">storage_offset</span><span class="p">))</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::as_strided_(Tensor(a!) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::as_strided__symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="o">&gt;</span><span class="w"> </span><span class="n">storage_offset</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">as_strided_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">stride</span><span class="p">,</span><span class="w"> </span><span class="n">storage_offset</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::asin(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::asin</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">asin</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::asin_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::asin_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">asin_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::arcsin(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::arcsin</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arcsin</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::arcsin_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::arcsin_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arcsin_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::atan(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::atan</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">atan</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::atan_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::atan_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">atan_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::arctan(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::arctan</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arctan</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::arctan_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::arctan_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arctan_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::baddbmm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">batch1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">batch2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">beta</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">baddbmm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">batch1</span><span class="p">,</span><span class="w"> </span><span class="n">batch2</span><span class="p">,</span><span class="w"> </span><span class="n">beta</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::baddbmm_(Tensor(a!) self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::baddbmm_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">batch1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">batch2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">beta</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">baddbmm_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">batch1</span><span class="p">,</span><span class="w"> </span><span class="n">batch2</span><span class="p">,</span><span class="w"> </span><span class="n">beta</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bernoulli(Tensor self, *, Generator? generator=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::bernoulli</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bernoulli</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bernoulli_.Tensor(Tensor(a!) self, Tensor p, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::bernoulli_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bernoulli__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bernoulli_.float(Tensor(a!) self, float p=0.5, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::bernoulli_</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bernoulli__float</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bernoulli.p(Tensor self, float p, *, Generator? generator=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::bernoulli</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bernoulli_p</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bincount(Tensor self, Tensor? weights=None, SymInt minlength=0) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::bincount</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">weights</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">minlength</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bincount</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">weights</span><span class="p">,</span><span class="w"> </span><span class="n">minlength</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bincount(Tensor self, Tensor? weights=None, SymInt minlength=0) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::bincount_symint</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">weights</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">minlength</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bincount</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">weights</span><span class="p">,</span><span class="w"> </span><span class="n">minlength</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_not(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::bitwise_not</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_not</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_not_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::bitwise_not_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_not_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::copysign.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::copysign</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">copysign_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::copysign_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::copysign_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">copysign__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::copysign.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::copysign</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">copysign_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::copysign_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::copysign_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">copysign__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_lazy_clone(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::_lazy_clone</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_lazy_clone</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::logical_not(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::logical_not</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logical_not</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::logical_not_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::logical_not_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logical_not_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::logical_xor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::logical_xor</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logical_xor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logical_xor_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::logical_xor_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logical_xor_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logical_and(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::logical_and</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logical_and</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logical_and_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::logical_and_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logical_and_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logical_or(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::logical_or</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logical_or</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logical_or_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::logical_or_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logical_or_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bmm(Tensor self, Tensor mat2) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::bmm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mat2</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bmm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">mat2</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::broadcast_to(Tensor(a) self, SymInt[] size) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::broadcast_to</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">broadcast_to</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">size</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::broadcast_to(Tensor(a) self, SymInt[] size) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::broadcast_to_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">broadcast_to</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ceil(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">Tensor::ceil</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ceil</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::ceil_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="nf">Tensor::ceil_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ceil_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::unsafe_chunk(Tensor self, int chunks, int dim=0) -&gt; Tensor[]</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">unsafe_chunk</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">chunks</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">unsafe_chunk</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">chunks</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::chunk(Tensor(a -&gt; *) self, int chunks, int dim=0) -&gt; Tensor(a)[]</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">chunk</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">chunks</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">chunk</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">chunks</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::tensor_split.sections(Tensor(a -&gt; *) self, SymInt sections, int dim=0) -&gt; Tensor(a)[]</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">tensor_split</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">sections</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tensor_split_sections</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">sections</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::tensor_split.sections(Tensor(a -&gt; *) self, SymInt sections, int dim=0) -&gt; Tensor(a)[]</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">tensor_split_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">sections</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tensor_split_sections</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">sections</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::tensor_split.indices(Tensor(a -&gt; *) self, SymInt[] indices, int dim=0) -&gt; Tensor(a)[]</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">tensor_split</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">indices</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tensor_split_indices</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">indices</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::tensor_split.indices(Tensor(a -&gt; *) self, SymInt[] indices, int dim=0) -&gt; Tensor(a)[]</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">tensor_split_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">indices</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tensor_split_indices</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">indices</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::tensor_split.tensor_indices_or_sections(Tensor(a -&gt; *) self, Tensor tensor_indices_or_sections, int dim=0) -&gt; Tensor(a)[]</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">tensor_split</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">tensor_indices_or_sections</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tensor_split_tensor_indices_or_sections</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">tensor_indices_or_sections</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp(Tensor self, Scalar? min=None, Scalar? max=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">clamp</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">min</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">max</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">min</span><span class="p">,</span><span class="w"> </span><span class="n">max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp.Tensor(Tensor self, Tensor? min=None, Tensor? max=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">clamp</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">min</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">max</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">min</span><span class="p">,</span><span class="w"> </span><span class="n">max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp_(Tensor(a!) self, Scalar? min=None, Scalar? max=None) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">clamp_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">min</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">max</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">min</span><span class="p">,</span><span class="w"> </span><span class="n">max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp_.Tensor(Tensor(a!) self, Tensor? min=None, Tensor? max=None) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">clamp_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">min</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">max</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">min</span><span class="p">,</span><span class="w"> </span><span class="n">max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp_max(Tensor self, Scalar max) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">clamp_max</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">max</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_max</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp_max.Tensor(Tensor self, Tensor max) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">clamp_max</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">max</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_max_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp_max_(Tensor(a!) self, Scalar max) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">clamp_max_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">max</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_max_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp_max_.Tensor(Tensor(a!) self, Tensor max) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">clamp_max_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">max</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_max__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp_min(Tensor self, Scalar min) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">clamp_min</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">min</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_min</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">min</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp_min.Tensor(Tensor self, Tensor min) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">clamp_min</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">min</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_min_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">min</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp_min_(Tensor(a!) self, Scalar min) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">clamp_min_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">min</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_min_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">min</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clamp_min_.Tensor(Tensor(a!) self, Tensor min) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">clamp_min_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">min</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clamp_min__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">min</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clip(Tensor self, Scalar? min=None, Scalar? max=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">clip</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">min</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">max</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clip</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">min</span><span class="p">,</span><span class="w"> </span><span class="n">max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clip.Tensor(Tensor self, Tensor? min=None, Tensor? max=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">clip</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">min</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">max</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clip_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">min</span><span class="p">,</span><span class="w"> </span><span class="n">max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clip_(Tensor(a!) self, Scalar? min=None, Scalar? max=None) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">clip_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">min</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">max</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clip_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">min</span><span class="p">,</span><span class="w"> </span><span class="n">max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::clip_.Tensor(Tensor(a!) self, Tensor? min=None, Tensor? max=None) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">clip_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">min</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">max</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clip__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">min</span><span class="p">,</span><span class="w"> </span><span class="n">max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=contiguous_format) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">__dispatch_contiguous</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="w"> </span><span class="n">memory_format</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">contiguous</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">memory_format</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">copy_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">non_blocking</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">copy_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">non_blocking</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cos(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">cos</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cos</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::cos_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">cos_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cos_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::cosh(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">cosh</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cosh</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::cosh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">cosh_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cosh_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::count_nonzero.dim_IntList(Tensor self, int[] dim) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">count_nonzero_dim_IntList</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::count_nonzero(Tensor self, int? dim=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">count_nonzero</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">count_nonzero</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cov(Tensor self, *, int correction=1, Tensor? fweights=None, Tensor? aweights=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">cov</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">correction</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">fweights</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">aweights</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cov</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">correction</span><span class="p">,</span><span class="w"> </span><span class="n">fweights</span><span class="p">,</span><span class="w"> </span><span class="n">aweights</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::corrcoef(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">corrcoef</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">corrcoef</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::cummax(Tensor self, int dim) -&gt; (Tensor values, Tensor indices)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">cummax</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cummax</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cummax.dimname(Tensor self, Dimname dim) -&gt; (Tensor values, Tensor indices)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">cummax</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cummax_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cummin(Tensor self, int dim) -&gt; (Tensor values, Tensor indices)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">cummin</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cummin</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cummin.dimname(Tensor self, Dimname dim) -&gt; (Tensor values, Tensor indices)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">cummin</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cummin_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cumprod(Tensor self, int dim, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">cumprod</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cumprod</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cumprod_(Tensor(a!) self, int dim, *, ScalarType? dtype=None) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">cumprod_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cumprod_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cumprod.dimname(Tensor self, Dimname dim, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">cumprod</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cumprod_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cumprod_.dimname(Tensor(a!) self, Dimname dim, *, ScalarType? dtype=None) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">cumprod_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cumprod__dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cumsum(Tensor self, int dim, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">cumsum</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cumsum</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cumsum_(Tensor(a!) self, int dim, *, ScalarType? dtype=None) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">cumsum_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cumsum_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cumsum.dimname(Tensor self, Dimname dim, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">cumsum</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cumsum_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cumsum_.dimname(Tensor(a!) self, Dimname dim, *, ScalarType? dtype=None) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">cumsum_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cumsum__dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::diag_embed(Tensor self, int offset=0, int dim1=-2, int dim2=-1) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">diag_embed</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">offset</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim1</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim2</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">diag_embed</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">offset</span><span class="p">,</span><span class="w"> </span><span class="n">dim1</span><span class="p">,</span><span class="w"> </span><span class="n">dim2</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::diagflat(Tensor self, int offset=0) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">diagflat</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">offset</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">diagflat</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">offset</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::diagonal(Tensor(a) self, int offset=0, int dim1=0, int dim2=1) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">diagonal</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">offset</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim1</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim2</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">diagonal</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">offset</span><span class="p">,</span><span class="w"> </span><span class="n">dim1</span><span class="p">,</span><span class="w"> </span><span class="n">dim2</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::diagonal.Dimname(Tensor(a) self, *, Dimname outdim, Dimname dim1, Dimname dim2, int offset=0) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">diagonal</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">outdim</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim1</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim2</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">offset</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">diagonal_Dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">outdim</span><span class="p">,</span><span class="w"> </span><span class="n">dim1</span><span class="p">,</span><span class="w"> </span><span class="n">dim2</span><span class="p">,</span><span class="w"> </span><span class="n">offset</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fill_diagonal_(Tensor(a!) self, Scalar fill_value, bool wrap=False) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">fill_diagonal_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">fill_value</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">wrap</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fill_diagonal_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">fill_value</span><span class="p">,</span><span class="w"> </span><span class="n">wrap</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::diff(Tensor self, int n=1, int dim=-1, Tensor? prepend=None, Tensor? append=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">diff</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">prepend</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">append</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">diff</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">prepend</span><span class="p">,</span><span class="w"> </span><span class="n">append</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::div.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">div</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">div_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::div_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">div_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">div__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::div.Tensor_mode(Tensor self, Tensor other, *, str? rounding_mode) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">div</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span><span class="w"> </span><span class="n">rounding_mode</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">div_Tensor_mode</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="n">rounding_mode</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::div_.Tensor_mode(Tensor(a!) self, Tensor other, *, str? rounding_mode) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">div_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span><span class="w"> </span><span class="n">rounding_mode</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">div__Tensor_mode</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="n">rounding_mode</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::div.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">div</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">div_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::div_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">div_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">div__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::div.Scalar_mode(Tensor self, Scalar other, *, str? rounding_mode) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">div</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span><span class="w"> </span><span class="n">rounding_mode</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">div_Scalar_mode</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="n">rounding_mode</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::div_.Scalar_mode(Tensor(a!) self, Scalar other, *, str? rounding_mode) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">div_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span><span class="w"> </span><span class="n">rounding_mode</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">div__Scalar_mode</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="n">rounding_mode</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::divide.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">divide</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">divide_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::divide_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">divide_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">divide__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::divide.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">divide</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">divide_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::divide_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">divide_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">divide__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::divide.Tensor_mode(Tensor self, Tensor other, *, str? rounding_mode) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">divide</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span><span class="w"> </span><span class="n">rounding_mode</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">divide_Tensor_mode</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="n">rounding_mode</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::divide_.Tensor_mode(Tensor(a!) self, Tensor other, *, str? rounding_mode) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">divide_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span><span class="w"> </span><span class="n">rounding_mode</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">divide__Tensor_mode</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="n">rounding_mode</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::divide.Scalar_mode(Tensor self, Scalar other, *, str? rounding_mode) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">divide</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span><span class="w"> </span><span class="n">rounding_mode</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">divide_Scalar_mode</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="n">rounding_mode</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::divide_.Scalar_mode(Tensor(a!) self, Scalar other, *, str? rounding_mode) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">divide_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="o">&gt;</span><span class="w"> </span><span class="n">rounding_mode</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">divide__Scalar_mode</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="n">rounding_mode</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::true_divide.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">true_divide</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">true_divide_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::true_divide_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">true_divide_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">true_divide__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::true_divide.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">true_divide</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">true_divide_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::true_divide_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">true_divide_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">true_divide__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::dot(Tensor self, Tensor tensor) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">dot</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">tensor</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">dot</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">tensor</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::vdot(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">vdot</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">vdot</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::new_empty(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">new_empty</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span><span class="w"> </span><span class="n">options</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">new_empty</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">size</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::new_empty(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">new_empty</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">new_empty</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">size</span><span class="p">),</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::new_empty(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">new_empty_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span><span class="w"> </span><span class="n">options</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">new_empty</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::new_empty(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">new_empty_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">new_empty</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::new_empty_strided(Tensor self, SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">new_empty_strided</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span><span class="w"> </span><span class="n">options</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">new_empty_strided</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">size</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">stride</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::new_empty_strided(Tensor self, SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">new_empty_strided</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">new_empty_strided</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">size</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">stride</span><span class="p">),</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::new_empty_strided(Tensor self, SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">new_empty_strided_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span><span class="w"> </span><span class="n">options</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">new_empty_strided</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">stride</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::new_empty_strided(Tensor self, SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">new_empty_strided_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">new_empty_strided</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">stride</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::new_full(Tensor self, SymInt[] size, Scalar fill_value, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">new_full</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">fill_value</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span><span class="w"> </span><span class="n">options</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">new_full</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">size</span><span class="p">),</span><span class="w"> </span><span class="n">fill_value</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::new_full(Tensor self, SymInt[] size, Scalar fill_value, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">new_full</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">fill_value</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">new_full</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">size</span><span class="p">),</span><span class="w"> </span><span class="n">fill_value</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::new_full(Tensor self, SymInt[] size, Scalar fill_value, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">new_full_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">fill_value</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span><span class="w"> </span><span class="n">options</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">new_full</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">fill_value</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::new_full(Tensor self, SymInt[] size, Scalar fill_value, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">new_full_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">fill_value</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">new_full</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">fill_value</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::new_zeros(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span><span class="w"> </span><span class="n">options</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">new_zeros</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">size</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::new_zeros(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">new_zeros</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">size</span><span class="p">),</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::new_zeros(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">new_zeros_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span><span class="w"> </span><span class="n">options</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">new_zeros</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::new_zeros(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">new_zeros_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">new_zeros</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::new_ones(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">new_ones</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span><span class="w"> </span><span class="n">options</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">new_ones</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">size</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::new_ones(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">new_ones</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">new_ones</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">size</span><span class="p">),</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::new_ones(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">new_ones_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span><span class="w"> </span><span class="n">options</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">new_ones</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">());</span>
<span class="p">}</span>

<span class="c1">// aten::new_ones(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">new_ones_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">new_ones</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">resize_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span><span class="w"> </span><span class="n">memory_format</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">resize_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">size</span><span class="p">),</span><span class="w"> </span><span class="n">memory_format</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">resize__symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span><span class="w"> </span><span class="n">memory_format</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">resize_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">memory_format</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::erf(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">erf</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">erf</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::erf_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">erf_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">erf_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::erfc(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">erfc</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">erfc</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::erfc_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">erfc_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">erfc_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::exp(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">exp</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">exp</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::exp_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">exp_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">exp_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::exp2(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">exp2</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">exp2</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::exp2_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">exp2_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">exp2_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::expm1(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">expm1</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">expm1</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::expm1_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">expm1_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">expm1_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">expand</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">implicit</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">expand</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">size</span><span class="p">),</span><span class="w"> </span><span class="n">implicit</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">expand_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">implicit</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">expand</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">implicit</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::expand_as(Tensor(a) self, Tensor other) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">expand_as</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">expand_as</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::flatten.using_ints(Tensor(a) self, int start_dim=0, int end_dim=-1) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">flatten</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">start_dim</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">end_dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">flatten_using_ints</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">start_dim</span><span class="p">,</span><span class="w"> </span><span class="n">end_dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::flatten.named_out_dim(Tensor(a) self, int start_dim, int end_dim, Dimname out_dim) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">flatten</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">start_dim</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">end_dim</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">out_dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">flatten_named_out_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">start_dim</span><span class="p">,</span><span class="w"> </span><span class="n">end_dim</span><span class="p">,</span><span class="w"> </span><span class="n">out_dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::flatten.using_names(Tensor(a) self, Dimname start_dim, Dimname end_dim, Dimname out_dim) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">flatten</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">start_dim</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">end_dim</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">out_dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">flatten_using_names</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">start_dim</span><span class="p">,</span><span class="w"> </span><span class="n">end_dim</span><span class="p">,</span><span class="w"> </span><span class="n">out_dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::flatten.DimnameList(Tensor(a) self, Dimname[] dims, Dimname out_dim) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">flatten</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">dims</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">out_dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">flatten_DimnameList</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dims</span><span class="p">,</span><span class="w"> </span><span class="n">out_dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::unflatten.int(Tensor(a) self, int dim, SymInt[] sizes) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">unflatten</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">sizes</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">unflatten_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">sizes</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::unflatten.int(Tensor(a) self, int dim, SymInt[] sizes) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">unflatten_symint</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">sizes</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">unflatten_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">sizes</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::unflatten.Dimname(Tensor(a) self, Dimname dim, SymInt[] sizes, Dimname[] names) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">unflatten</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">sizes</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">names</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">unflatten_Dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">sizes</span><span class="p">),</span><span class="w"> </span><span class="n">names</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::unflatten.Dimname(Tensor(a) self, Dimname dim, SymInt[] sizes, Dimname[] names) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">unflatten_symint</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">sizes</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">names</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">unflatten_Dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">sizes</span><span class="p">,</span><span class="w"> </span><span class="n">names</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fill_.Scalar(Tensor(a!) self, Scalar value) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">fill_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fill__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fill_.Tensor(Tensor(a!) self, Tensor value) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">fill_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fill__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::floor(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">floor</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">floor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::floor_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">floor_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">floor_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::floor_divide(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">floor_divide</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">floor_divide</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::floor_divide_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">floor_divide_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">floor_divide__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::floor_divide.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">floor_divide</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">floor_divide_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::floor_divide_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">floor_divide_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">floor_divide__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::frac(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">frac</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">frac</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::frac_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">frac_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">frac_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::gcd(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">gcd</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gcd</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gcd_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">gcd_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gcd_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lcm(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">lcm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lcm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lcm_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">lcm_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lcm_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index.Tensor(Tensor self, Tensor?[] indices) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">index</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">List</span><span class="o">&lt;::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">indices</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_copy_(Tensor(a!) self, int dim, Tensor index, Tensor source) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">index_copy_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_copy_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">source</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_copy(Tensor self, int dim, Tensor index, Tensor source) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">index_copy</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_copy</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">source</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_copy_.dimname(Tensor(a!) self, Dimname dim, Tensor index, Tensor source) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">index_copy_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_copy__dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">source</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_copy.dimname(Tensor self, Dimname dim, Tensor index, Tensor source) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">index_copy</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_copy_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">source</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_put_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">index_put_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">List</span><span class="o">&lt;::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">indices</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">values</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">accumulate</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_put_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">indices</span><span class="p">,</span><span class="w"> </span><span class="n">values</span><span class="p">,</span><span class="w"> </span><span class="n">accumulate</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_put(Tensor self, Tensor?[] indices, Tensor values, bool accumulate=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">index_put</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">List</span><span class="o">&lt;::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">indices</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">values</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">accumulate</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_put</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">indices</span><span class="p">,</span><span class="w"> </span><span class="n">values</span><span class="p">,</span><span class="w"> </span><span class="n">accumulate</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::isclose(Tensor self, Tensor other, float rtol=1e-05, float atol=1e-08, bool equal_nan=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">isclose</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">rtol</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">atol</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">equal_nan</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">isclose</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="n">rtol</span><span class="p">,</span><span class="w"> </span><span class="n">atol</span><span class="p">,</span><span class="w"> </span><span class="n">equal_nan</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::isnan(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">isnan</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">isnan</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::is_distributed(Tensor self) -&gt; bool</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">is_distributed</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">is_distributed</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::is_floating_point(Tensor self) -&gt; bool</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">__dispatch_is_floating_point</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">is_floating_point</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::is_complex(Tensor self) -&gt; bool</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">__dispatch_is_complex</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">is_complex</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::is_conj(Tensor self) -&gt; bool</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">__dispatch_is_conj</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">is_conj</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::_is_zerotensor(Tensor self) -&gt; bool</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">__dispatch__is_zerotensor</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_is_zerotensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::is_neg(Tensor self) -&gt; bool</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">__dispatch_is_neg</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">is_neg</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::isreal(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">isreal</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">isreal</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::is_nonzero(Tensor self) -&gt; bool</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">is_nonzero</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">is_nonzero</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::is_same_size(Tensor self, Tensor other) -&gt; bool</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">is_same_size</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">is_same_size</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::is_signed(Tensor self) -&gt; bool</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">__dispatch_is_signed</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">is_signed</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::is_inference(Tensor self) -&gt; bool</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">__dispatch_is_inference</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">is_inference</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::kron(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">kron</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">kron</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::kthvalue(Tensor self, SymInt k, int dim=-1, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">kthvalue</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">kthvalue</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::kthvalue(Tensor self, SymInt k, int dim=-1, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">kthvalue_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">kthvalue</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::kthvalue.dimname(Tensor self, SymInt k, Dimname dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">kthvalue</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">kthvalue_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::kthvalue.dimname(Tensor self, SymInt k, Dimname dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">kthvalue_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">kthvalue_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nan_to_num(Tensor self, float? nan=None, float? posinf=None, float? neginf=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">nan_to_num</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="w"> </span><span class="n">nan</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="w"> </span><span class="n">posinf</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="w"> </span><span class="n">neginf</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nan_to_num</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">nan</span><span class="p">,</span><span class="w"> </span><span class="n">posinf</span><span class="p">,</span><span class="w"> </span><span class="n">neginf</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nan_to_num_(Tensor(a!) self, float? nan=None, float? posinf=None, float? neginf=None) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">nan_to_num_</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="w"> </span><span class="n">nan</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="w"> </span><span class="n">posinf</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="w"> </span><span class="n">neginf</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nan_to_num_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">nan</span><span class="p">,</span><span class="w"> </span><span class="n">posinf</span><span class="p">,</span><span class="w"> </span><span class="n">neginf</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ldexp.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">ldexp</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ldexp_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ldexp_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">ldexp_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ldexp_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">log</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::log_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">log_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::log10(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">log10</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log10</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::log10_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">log10_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log10_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::log1p(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">log1p</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log1p</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::log1p_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">log1p_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log1p_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::log2(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">log2</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log2</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::log2_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">log2_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log2_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::logaddexp(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">logaddexp</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logaddexp</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logaddexp2(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">logaddexp2</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logaddexp2</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::xlogy.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">xlogy</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">xlogy_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::xlogy.Scalar_Other(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">xlogy</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">xlogy_Scalar_Other</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::xlogy_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">xlogy_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">xlogy__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::xlogy_.Scalar_Other(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">xlogy_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">xlogy__Scalar_Other</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log_softmax.int(Tensor self, int dim, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">log_softmax</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log_softmax_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log_softmax.Dimname(Tensor self, Dimname dim, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log_softmax_Dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logcumsumexp(Tensor self, int dim) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">logcumsumexp</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logcumsumexp</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logcumsumexp.dimname(Tensor self, Dimname dim) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">logcumsumexp</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logcumsumexp_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logsumexp(Tensor self, int[1] dim, bool keepdim=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">logsumexp</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logsumexp</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logsumexp.names(Tensor self, Dimname[1] dim, bool keepdim=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">logsumexp</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logsumexp_names</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::matmul(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">matmul</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">matmul</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::matrix_power(Tensor self, int n) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">matrix_power</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">matrix_power</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::matrix_exp(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">matrix_exp</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">matrix_exp</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::aminmax(Tensor self, *, int? dim=None, bool keepdim=False) -&gt; (Tensor min, Tensor max)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">aminmax</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">aminmax</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max.dim(Tensor self, int dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">max</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max.names_dim(Tensor self, Dimname dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">max</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_names_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::amax(Tensor self, int[1] dim=[], bool keepdim=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">amax</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">amax</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mean(Tensor self, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">mean</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mean</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mean.dim(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">mean</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">OptionalIntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mean_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mean.names_dim(Tensor self, Dimname[1] dim, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">mean</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mean_names_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nanmean(Tensor self, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">nanmean</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">OptionalIntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nanmean</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::median(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">median</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">median</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::median.dim(Tensor self, int dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">median</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">median_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::median.names_dim(Tensor self, Dimname dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">median</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">median_names_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nanmedian(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">nanmedian</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nanmedian</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::nanmedian.dim(Tensor self, int dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">nanmedian</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nanmedian_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nanmedian.names_dim(Tensor self, Dimname dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">nanmedian</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nanmedian_names_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::min.dim(Tensor self, int dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">min</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">min_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::min.names_dim(Tensor self, Dimname dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">min</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">min_names_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::amin(Tensor self, int[1] dim=[], bool keepdim=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">amin</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">amin</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mm(Tensor self, Tensor mat2) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">mm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mat2</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">mat2</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mode(Tensor self, int dim=-1, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">mode</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mode</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mode.dimname(Tensor self, Dimname dim, bool keepdim=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">mode</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mode_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mul.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">mul</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mul_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mul_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">mul_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mul__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mul.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">mul</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mul_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mul_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">mul_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mul__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::multiply.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">multiply</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">multiply_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::multiply_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">multiply_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">multiply__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::multiply.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">multiply</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">multiply_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::multiply_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">multiply_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">multiply__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mv(Tensor self, Tensor vec) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">mv</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">vec</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mv</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">vec</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mvlgamma(Tensor self, int p) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">mvlgamma</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">p</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mvlgamma</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">p</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::mvlgamma_(Tensor(a!) self, int p) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">mvlgamma_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">p</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mvlgamma_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">p</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::narrow_copy(Tensor self, int dim, SymInt start, SymInt length) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">narrow_copy</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">length</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">narrow_copy</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="n">length</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::narrow_copy(Tensor self, int dim, SymInt start, SymInt length) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">narrow_copy_symint</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">length</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">narrow_copy</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="n">length</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">narrow</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">length</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">narrow</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="n">length</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">narrow_symint</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">length</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">narrow</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="n">length</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::narrow.Tensor(Tensor(a) self, int dim, Tensor start, SymInt length) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">narrow</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">length</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">narrow_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="n">length</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::narrow.Tensor(Tensor(a) self, int dim, Tensor start, SymInt length) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">narrow_symint</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">length</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">narrow_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="n">length</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::permute(Tensor(a) self, int[] dims) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">permute</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dims</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">permute</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dims</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::movedim.intlist(Tensor(a) self, int[] source, int[] destination) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">movedim</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">destination</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">movedim_intlist</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="n">destination</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::movedim.int(Tensor(a) self, int source, int destination) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">movedim</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">destination</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">movedim_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="n">destination</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::moveaxis.intlist(Tensor(a) self, int[] source, int[] destination) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">moveaxis</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">destination</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">moveaxis_intlist</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="n">destination</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::moveaxis.int(Tensor(a) self, int source, int destination) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">moveaxis</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">destination</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">moveaxis_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="n">destination</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::numpy_T(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">numpy_T</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">numpy_T</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::matrix_H(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">matrix_H</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">matrix_H</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::mT(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">mT</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mT</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::mH(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">mH</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">mH</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::adjoint(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">adjoint</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">adjoint</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::is_pinned(Tensor self, Device? device=None) -&gt; bool</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">is_pinned</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span><span class="w"> </span><span class="n">device</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">is_pinned</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">device</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::pin_memory(Tensor(a) self, Device? device=None) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">pin_memory</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span><span class="w"> </span><span class="n">device</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">pin_memory</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">device</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::pinverse(Tensor self, float rcond=1e-15) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">pinverse</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">rcond</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">pinverse</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">rcond</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rad2deg(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">rad2deg</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rad2deg</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::rad2deg_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">rad2deg_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rad2deg_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::deg2rad(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">deg2rad</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">deg2rad</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::deg2rad_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">deg2rad_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">deg2rad_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::ravel(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">ravel</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ravel</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::reciprocal(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">reciprocal</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">reciprocal</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::reciprocal_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">reciprocal_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">reciprocal_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::neg(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">neg</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">neg</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::neg_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">neg_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">neg_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::negative(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">negative</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">negative</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::negative_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">negative_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">negative_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::repeat(Tensor self, SymInt[] repeats) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">repeat</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">repeats</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">repeat</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">repeats</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::repeat(Tensor self, SymInt[] repeats) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">repeat_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">repeats</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">repeat</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">repeats</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::repeat_interleave.self_Tensor(Tensor self, Tensor repeats, int? dim=None, *, SymInt? output_size=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">repeats</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">output_size</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">repeat_interleave_self_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">repeats</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">output_size</span><span class="p">.</span><span class="n">has_value</span><span class="p">()</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">make_optional</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="p">(</span><span class="o">*</span><span class="n">output_size</span><span class="p">))</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::repeat_interleave.self_Tensor(Tensor self, Tensor repeats, int? dim=None, *, SymInt? output_size=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">repeat_interleave_symint</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">repeats</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="o">&gt;</span><span class="w"> </span><span class="n">output_size</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">repeat_interleave_self_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">repeats</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">output_size</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::repeat_interleave.self_int(Tensor self, SymInt repeats, int? dim=None, *, SymInt? output_size=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">repeats</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">output_size</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">repeat_interleave_self_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">repeats</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">output_size</span><span class="p">.</span><span class="n">has_value</span><span class="p">()</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">make_optional</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="p">(</span><span class="o">*</span><span class="n">output_size</span><span class="p">))</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::repeat_interleave.self_int(Tensor self, SymInt repeats, int? dim=None, *, SymInt? output_size=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">repeat_interleave_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">repeats</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="o">&gt;</span><span class="w"> </span><span class="n">output_size</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">repeat_interleave_self_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">repeats</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">output_size</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::reshape(Tensor(a) self, SymInt[] shape) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">reshape</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">shape</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">reshape</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">shape</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::reshape(Tensor(a) self, SymInt[] shape) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">reshape_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">shape</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">reshape</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">shape</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">_reshape_alias</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_reshape_alias</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">size</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">stride</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">_reshape_alias_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_reshape_alias</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">stride</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::reshape_as(Tensor(a) self, Tensor other) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">reshape_as</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">reshape_as</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::round(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">round</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">round</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::round_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">round_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">round_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::round.decimals(Tensor self, *, int decimals) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">round</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">decimals</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">round_decimals</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">decimals</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::round_.decimals(Tensor(a!) self, *, int decimals) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">round_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">decimals</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">round__decimals</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">decimals</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::relu(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">relu</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">relu</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::relu_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">relu_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">relu_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::prelu(Tensor self, Tensor weight) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">prelu</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">weight</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">prelu</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">weight</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hardshrink(Tensor self, Scalar lambd=0.5) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">hardshrink</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">lambd</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hardshrink</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">lambd</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hardshrink_backward(Tensor grad_out, Tensor self, Scalar lambd) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">hardshrink_backward</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">grad_out</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">lambd</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hardshrink_backward</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">grad_out</span><span class="p">,</span><span class="w"> </span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">lambd</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rsqrt(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">rsqrt</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rsqrt</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::rsqrt_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">rsqrt_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rsqrt_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::select.Dimname(Tensor(a) self, Dimname dim, int index) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">select</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">index</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">select_Dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::select.int(Tensor(a) self, int dim, SymInt index) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">select</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">index</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">select_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::select.int(Tensor(a) self, int dim, SymInt index) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">select_symint</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">index</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">select_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sigmoid(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sigmoid</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sigmoid</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::sigmoid_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sigmoid_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sigmoid_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::logit(Tensor self, float? eps=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">logit</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="w"> </span><span class="n">eps</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logit</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">eps</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::logit_(Tensor(a!) self, float? eps=None) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">logit_</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span><span class="w"> </span><span class="n">eps</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logit_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">eps</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sin(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sin</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sin</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::sin_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sin_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sin_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::sinc(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sinc</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sinc</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::sinc_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sinc_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sinc_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::sinh(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sinh</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sinh</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::sinh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sinh_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sinh_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::detach(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">detach</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">detach</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::detach_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">detach_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">detach_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::size.Dimname(Tensor self, Dimname dim) -&gt; int</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">size</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">size_Dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">slice</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">end</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">step</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slice_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">start</span><span class="p">.</span><span class="n">has_value</span><span class="p">()</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">make_optional</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="p">(</span><span class="o">*</span><span class="n">start</span><span class="p">))</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="n">end</span><span class="p">.</span><span class="n">has_value</span><span class="p">()</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">make_optional</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="p">(</span><span class="o">*</span><span class="n">end</span><span class="p">))</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="n">step</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">slice_symint</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="o">&gt;</span><span class="w"> </span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="o">&gt;</span><span class="w"> </span><span class="n">end</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">step</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slice_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="n">end</span><span class="p">,</span><span class="w"> </span><span class="n">step</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slice_inverse(Tensor(a) self, Tensor src, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">slice_inverse</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">end</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">step</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slice_inverse</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">start</span><span class="p">.</span><span class="n">has_value</span><span class="p">()</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">make_optional</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="p">(</span><span class="o">*</span><span class="n">start</span><span class="p">))</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="n">end</span><span class="p">.</span><span class="n">has_value</span><span class="p">()</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">make_optional</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="p">(</span><span class="o">*</span><span class="n">end</span><span class="p">))</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="n">step</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slice_inverse(Tensor(a) self, Tensor src, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">slice_inverse_symint</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="o">&gt;</span><span class="w"> </span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="o">&gt;</span><span class="w"> </span><span class="n">end</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">step</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slice_inverse</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="n">end</span><span class="p">,</span><span class="w"> </span><span class="n">step</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slice_scatter(Tensor self, Tensor src, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">slice_scatter</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">end</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">step</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slice_scatter</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">start</span><span class="p">.</span><span class="n">has_value</span><span class="p">()</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">make_optional</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="p">(</span><span class="o">*</span><span class="n">start</span><span class="p">))</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="n">end</span><span class="p">.</span><span class="n">has_value</span><span class="p">()</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">make_optional</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="p">(</span><span class="o">*</span><span class="n">end</span><span class="p">))</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">,</span><span class="w"> </span><span class="n">step</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::slice_scatter(Tensor self, Tensor src, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">slice_scatter_symint</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="o">&gt;</span><span class="w"> </span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="o">&gt;</span><span class="w"> </span><span class="n">end</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">step</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slice_scatter</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="n">end</span><span class="p">,</span><span class="w"> </span><span class="n">step</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::select_scatter(Tensor self, Tensor src, int dim, SymInt index) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">select_scatter</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">index</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">select_scatter</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::select_scatter(Tensor self, Tensor src, int dim, SymInt index) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">select_scatter_symint</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">index</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">select_scatter</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::diagonal_scatter(Tensor self, Tensor src, int offset=0, int dim1=0, int dim2=1) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">diagonal_scatter</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">offset</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim1</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim2</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">diagonal_scatter</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">offset</span><span class="p">,</span><span class="w"> </span><span class="n">dim1</span><span class="p">,</span><span class="w"> </span><span class="n">dim2</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::as_strided_scatter(Tensor self, Tensor src, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">as_strided_scatter</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">storage_offset</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">as_strided_scatter</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">size</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">stride</span><span class="p">),</span><span class="w"> </span><span class="n">storage_offset</span><span class="p">.</span><span class="n">has_value</span><span class="p">()</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">make_optional</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="p">(</span><span class="o">*</span><span class="n">storage_offset</span><span class="p">))</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::as_strided_scatter(Tensor self, Tensor src, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">as_strided_scatter_symint</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="o">&gt;</span><span class="w"> </span><span class="n">storage_offset</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">as_strided_scatter</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">stride</span><span class="p">,</span><span class="w"> </span><span class="n">storage_offset</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::smm(Tensor self, Tensor mat2) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">smm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mat2</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">smm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">mat2</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::softmax.int(Tensor self, int dim, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">softmax</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">softmax_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::softmax.Dimname(Tensor self, Dimname dim, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">softmax</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">softmax_Dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::unsafe_split.Tensor(Tensor self, SymInt split_size, int dim=0) -&gt; Tensor[]</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">unsafe_split</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">split_size</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">unsafe_split_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">split_size</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::unsafe_split.Tensor(Tensor self, SymInt split_size, int dim=0) -&gt; Tensor[]</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">unsafe_split_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">split_size</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">unsafe_split_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">split_size</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::split.Tensor(Tensor(a -&gt; *) self, SymInt split_size, int dim=0) -&gt; Tensor(a)[]</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">split</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">split_size</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">split_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">split_size</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::split.Tensor(Tensor(a -&gt; *) self, SymInt split_size, int dim=0) -&gt; Tensor(a)[]</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">split_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">split_size</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">split_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">split_size</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::split.sizes(Tensor(a -&gt; *) self, SymInt[] split_size, int dim=0) -&gt; Tensor(a)[]</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">split</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">split_size</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">split_sizes</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">split_size</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::split.sizes(Tensor(a -&gt; *) self, SymInt[] split_size, int dim=0) -&gt; Tensor(a)[]</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">split_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">split_size</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">split_sizes</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">split_size</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::unsafe_split_with_sizes(Tensor self, SymInt[] split_sizes, int dim=0) -&gt; Tensor[]</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">unsafe_split_with_sizes</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">split_sizes</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">unsafe_split_with_sizes</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">split_sizes</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::unsafe_split_with_sizes(Tensor self, SymInt[] split_sizes, int dim=0) -&gt; Tensor[]</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">unsafe_split_with_sizes_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">split_sizes</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">unsafe_split_with_sizes</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">split_sizes</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::split_with_sizes(Tensor(a -&gt; *) self, SymInt[] split_sizes, int dim=0) -&gt; Tensor(a)[]</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">split_with_sizes</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">split_sizes</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">split_with_sizes</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">split_sizes</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::split_with_sizes(Tensor(a -&gt; *) self, SymInt[] split_sizes, int dim=0) -&gt; Tensor(a)[]</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">split_with_sizes_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">split_sizes</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">split_with_sizes</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">split_sizes</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hsplit.int(Tensor(a -&gt; *) self, int sections) -&gt; Tensor(a)[]</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">hsplit</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">sections</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hsplit_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">sections</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hsplit.array(Tensor(a -&gt; *) self, int[] indices) -&gt; Tensor(a)[]</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">hsplit</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">indices</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hsplit_array</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::vsplit.int(Tensor(a -&gt; *) self, int sections) -&gt; Tensor(a)[]</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">vsplit</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">sections</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">vsplit_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">sections</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::vsplit.array(Tensor(a -&gt; *) self, int[] indices) -&gt; Tensor(a)[]</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">vsplit</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">indices</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">vsplit_array</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::dsplit.int(Tensor(a -&gt; *) self, int sections) -&gt; Tensor(a)[]</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">dsplit</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">sections</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">dsplit_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">sections</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::dsplit.array(Tensor(a -&gt; *) self, int[] indices) -&gt; Tensor(a)[]</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">dsplit</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">indices</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">dsplit_array</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">indices</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::squeeze(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">squeeze</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">squeeze</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::squeeze.dim(Tensor(a) self, int dim) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">squeeze</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">squeeze_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::squeeze.dimname(Tensor(a) self, Dimname dim) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">squeeze</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">squeeze_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::squeeze.dims(Tensor(a) self, int[] dim) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">squeeze</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">squeeze_dims</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::squeeze_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">squeeze_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">squeeze_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::squeeze_.dim(Tensor(a!) self, int dim) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">squeeze_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">squeeze__dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::squeeze_.dims(Tensor(a!) self, int[] dim) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">squeeze_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">squeeze__dims</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::squeeze_.dimname(Tensor(a!) self, Dimname dim) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">squeeze_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">squeeze__dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sspaddmm(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sspaddmm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mat1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mat2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">beta</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sspaddmm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">mat1</span><span class="p">,</span><span class="w"> </span><span class="n">mat2</span><span class="p">,</span><span class="w"> </span><span class="n">beta</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::stft(Tensor self, int n_fft, int? hop_length=None, int? win_length=None, Tensor? window=None, bool normalized=False, bool? onesided=None, bool? return_complex=None, bool? align_to_window=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">stft</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">n_fft</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">hop_length</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">win_length</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">window</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">normalized</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">onesided</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">return_complex</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">align_to_window</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">stft</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">n_fft</span><span class="p">,</span><span class="w"> </span><span class="n">hop_length</span><span class="p">,</span><span class="w"> </span><span class="n">win_length</span><span class="p">,</span><span class="w"> </span><span class="n">window</span><span class="p">,</span><span class="w"> </span><span class="n">normalized</span><span class="p">,</span><span class="w"> </span><span class="n">onesided</span><span class="p">,</span><span class="w"> </span><span class="n">return_complex</span><span class="p">,</span><span class="w"> </span><span class="n">align_to_window</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::stft.center(Tensor self, int n_fft, int? hop_length=None, int? win_length=None, Tensor? window=None, bool center=True, str pad_mode=&quot;reflect&quot;, bool normalized=False, bool? onesided=None, bool? return_complex=None, bool? align_to_window=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">stft</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">n_fft</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">hop_length</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">win_length</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">window</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">center</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="w"> </span><span class="n">pad_mode</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">normalized</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">onesided</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">return_complex</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">align_to_window</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">stft_center</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">n_fft</span><span class="p">,</span><span class="w"> </span><span class="n">hop_length</span><span class="p">,</span><span class="w"> </span><span class="n">win_length</span><span class="p">,</span><span class="w"> </span><span class="n">window</span><span class="p">,</span><span class="w"> </span><span class="n">center</span><span class="p">,</span><span class="w"> </span><span class="n">pad_mode</span><span class="p">,</span><span class="w"> </span><span class="n">normalized</span><span class="p">,</span><span class="w"> </span><span class="n">onesided</span><span class="p">,</span><span class="w"> </span><span class="n">return_complex</span><span class="p">,</span><span class="w"> </span><span class="n">align_to_window</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::istft(Tensor self, int n_fft, int? hop_length=None, int? win_length=None, Tensor? window=None, bool center=True, bool normalized=False, bool? onesided=None, int? length=None, bool return_complex=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">istft</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">n_fft</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">hop_length</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">win_length</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">window</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">center</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">normalized</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">onesided</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">length</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">return_complex</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">istft</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">n_fft</span><span class="p">,</span><span class="w"> </span><span class="n">hop_length</span><span class="p">,</span><span class="w"> </span><span class="n">win_length</span><span class="p">,</span><span class="w"> </span><span class="n">window</span><span class="p">,</span><span class="w"> </span><span class="n">center</span><span class="p">,</span><span class="w"> </span><span class="n">normalized</span><span class="p">,</span><span class="w"> </span><span class="n">onesided</span><span class="p">,</span><span class="w"> </span><span class="n">length</span><span class="p">,</span><span class="w"> </span><span class="n">return_complex</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::stride.Dimname(Tensor self, Dimname dim) -&gt; int</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">stride</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">stride_Dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sum(Tensor self, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sum</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sum</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sum</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">OptionalIntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sum_dim_IntList</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sum.dim_DimnameList(Tensor self, Dimname[1] dim, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sum</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sum_dim_DimnameList</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nansum(Tensor self, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">nansum</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">OptionalIntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nansum</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hash_tensor(Tensor self, int[1] dim=[], *, bool keepdim=False, int mode=0) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">hash_tensor</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">mode</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hash_tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="n">mode</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sum_to_size(Tensor self, SymInt[] size) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sum_to_size</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sum_to_size</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">size</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::sum_to_size(Tensor self, SymInt[] size) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sum_to_size_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sum_to_size</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sqrt(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sqrt</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sqrt</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::sqrt_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sqrt_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sqrt_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::square(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">square</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">square</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::square_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">square_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">square_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::std(Tensor self, bool unbiased=True) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">std</span><span class="p">(</span><span class="kt">bool</span><span class="w"> </span><span class="n">unbiased</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">unbiased</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::std.dim(Tensor self, int[1]? dim, bool unbiased=True, bool keepdim=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">std</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">OptionalIntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">unbiased</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">std_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">unbiased</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::std.correction(Tensor self, int[1]? dim=None, *, Scalar? correction=None, bool keepdim=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">std</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">OptionalIntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">correction</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">std_correction</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">correction</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::std.names_dim(Tensor self, Dimname[1] dim, bool unbiased=True, bool keepdim=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">std</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">unbiased</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">std_names_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">unbiased</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::std.correction_names(Tensor self, Dimname[1] dim, *, Scalar? correction=None, bool keepdim=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">std</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">correction</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">std_correction_names</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">correction</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::prod(Tensor self, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">prod</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">prod</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::prod.dim_int(Tensor self, int dim, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">prod</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">prod_dim_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::prod.dim_Dimname(Tensor self, Dimname dim, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">prod</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">prod_dim_Dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::t(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">t</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">t</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::t_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">t_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">t_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::tan(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">tan</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tan</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::tan_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">tan_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tan_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::tanh(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">tanh</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tanh</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::tanh_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">tanh_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tanh_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::tile(Tensor self, SymInt[] dims) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">tile</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dims</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tile</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">dims</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::tile(Tensor self, SymInt[] dims) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">tile_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">dims</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tile</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dims</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::transpose.int(Tensor(a) self, int dim0, int dim1) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">transpose</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim0</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">transpose_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim0</span><span class="p">,</span><span class="w"> </span><span class="n">dim1</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::transpose.Dimname(Tensor(a) self, Dimname dim0, Dimname dim1) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">transpose</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim0</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">transpose_Dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim0</span><span class="p">,</span><span class="w"> </span><span class="n">dim1</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::transpose_(Tensor(a!) self, int dim0, int dim1) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">transpose_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim0</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">transpose_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim0</span><span class="p">,</span><span class="w"> </span><span class="n">dim1</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::flip(Tensor self, int[] dims) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">flip</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dims</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">flip</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dims</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fliplr(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">fliplr</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fliplr</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::flipud(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">flipud</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">flipud</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::roll(Tensor self, SymInt[1] shifts, int[1] dims=[]) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">roll</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">shifts</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dims</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">roll</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">shifts</span><span class="p">),</span><span class="w"> </span><span class="n">dims</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::roll(Tensor self, SymInt[1] shifts, int[1] dims=[]) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">roll_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">shifts</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dims</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">roll</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">shifts</span><span class="p">,</span><span class="w"> </span><span class="n">dims</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::rot90(Tensor self, int k=1, int[] dims=[0,1]) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">rot90</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dims</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">rot90</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">dims</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_nested_tensor_size(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">_nested_tensor_size</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_nested_tensor_size</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::_nested_tensor_strides(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">_nested_tensor_strides</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_nested_tensor_strides</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::_nested_tensor_storage_offsets(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">_nested_tensor_storage_offsets</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_nested_tensor_storage_offsets</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::trunc(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">trunc</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">trunc</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::trunc_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">trunc_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">trunc_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::fix(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">fix</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fix</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::fix_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">fix_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fix_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::type_as(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">type_as</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">type_as</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::unsqueeze(Tensor(a) self, int dim) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">unsqueeze</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">unsqueeze</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::unsqueeze_(Tensor(a!) self, int dim) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">unsqueeze_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">unsqueeze_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::var(Tensor self, bool unbiased=True) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">var</span><span class="p">(</span><span class="kt">bool</span><span class="w"> </span><span class="n">unbiased</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">var</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">unbiased</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::var.dim(Tensor self, int[1]? dim, bool unbiased=True, bool keepdim=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">var</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">OptionalIntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">unbiased</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">var_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">unbiased</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::var.correction(Tensor self, int[1]? dim=None, *, Scalar? correction=None, bool keepdim=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">var</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">OptionalIntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">correction</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">var_correction</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">correction</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::var.names_dim(Tensor self, Dimname[1] dim, bool unbiased=True, bool keepdim=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">var</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">unbiased</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">var_names_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">unbiased</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::var.correction_names(Tensor self, Dimname[1] dim, *, Scalar? correction=None, bool keepdim=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">var</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">correction</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">var_correction_names</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">correction</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::view_as(Tensor(a) self, Tensor other) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">view_as</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">view_as</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::where.self(Tensor condition, Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">where</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">condition</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">where_self</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span><span class="w"> </span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::where.ScalarOther(Tensor condition, Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">where</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">condition</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">where_ScalarOther</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span><span class="w"> </span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::norm.ScalarOpt_dtype(Tensor self, Scalar? p, *, ScalarType dtype) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">norm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">norm_ScalarOpt_dtype</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::norm.Scalar(Tensor self, Scalar p=2) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">norm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">p</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">norm_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">p</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::norm.ScalarOpt_dim_dtype(Tensor self, Scalar? p, int[1] dim, bool keepdim, *, ScalarType dtype) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">norm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">norm_ScalarOpt_dim_dtype</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::norm.ScalarOpt_dim(Tensor self, Scalar? p, int[1] dim, bool keepdim=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">norm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">norm_ScalarOpt_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::norm.names_ScalarOpt_dim_dtype(Tensor self, Scalar? p, Dimname[1] dim, bool keepdim, *, ScalarType dtype) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">norm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">norm_names_ScalarOpt_dim_dtype</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::norm.names_ScalarOpt_dim(Tensor self, Scalar? p, Dimname[1] dim, bool keepdim=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">norm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">DimnameList</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">norm_names_ScalarOpt_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::frexp.Tensor(Tensor self) -&gt; (Tensor mantissa, Tensor exponent)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">frexp</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">frexp_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">clone</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span><span class="w"> </span><span class="n">memory_format</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">clone</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">memory_format</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::positive(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">positive</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">positive</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::resize_as_(Tensor(a!) self, Tensor the_template, *, MemoryFormat? memory_format=None) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">resize_as_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">the_template</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span><span class="w"> </span><span class="n">memory_format</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">resize_as_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">the_template</span><span class="p">,</span><span class="w"> </span><span class="n">memory_format</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::resize_as_sparse_(Tensor(a!) self, Tensor the_template) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">resize_as_sparse_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">the_template</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">resize_as_sparse_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">the_template</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::zero_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">zero_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">zero_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::sub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sub</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sub_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sub_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sub_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sub__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sub.Scalar(Tensor self, Scalar other, Scalar alpha=1) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sub</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sub_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sub_.Scalar(Tensor(a!) self, Scalar other, Scalar alpha=1) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sub_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sub__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::subtract.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">subtract</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">subtract_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::subtract_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">subtract_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">subtract__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::subtract.Scalar(Tensor self, Scalar other, Scalar alpha=1) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">subtract</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">subtract_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::subtract_.Scalar(Tensor(a!) self, Scalar other, Scalar alpha=1) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">subtract_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">subtract__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::heaviside(Tensor self, Tensor values) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">heaviside</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">values</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">heaviside</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">values</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::heaviside_(Tensor(a!) self, Tensor values) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">heaviside_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">values</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">heaviside_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">values</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addmm(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">addmm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mat1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mat2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">beta</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addmm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">mat1</span><span class="p">,</span><span class="w"> </span><span class="n">mat2</span><span class="p">,</span><span class="w"> </span><span class="n">beta</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addmm_(Tensor(a!) self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">addmm_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mat1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mat2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">beta</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addmm_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">mat1</span><span class="p">,</span><span class="w"> </span><span class="n">mat2</span><span class="p">,</span><span class="w"> </span><span class="n">beta</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_addmm_activation(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1, bool use_gelu=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">_addmm_activation</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mat1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mat2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">beta</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">use_gelu</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_addmm_activation</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">mat1</span><span class="p">,</span><span class="w"> </span><span class="n">mat2</span><span class="p">,</span><span class="w"> </span><span class="n">beta</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">,</span><span class="w"> </span><span class="n">use_gelu</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sparse_resize_(Tensor(a!) self, int[] size, int sparse_dim, int dense_dim) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sparse_resize_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">sparse_dim</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dense_dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sparse_resize_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">sparse_dim</span><span class="p">,</span><span class="w"> </span><span class="n">dense_dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sparse_resize_and_clear_(Tensor(a!) self, int[] size, int sparse_dim, int dense_dim) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sparse_resize_and_clear_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">sparse_dim</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dense_dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sparse_resize_and_clear_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">sparse_dim</span><span class="p">,</span><span class="w"> </span><span class="n">dense_dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sparse_mask(Tensor self, Tensor mask) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sparse_mask</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mask</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sparse_mask</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">mask</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_sparse_mask_projection(Tensor self, Tensor mask, bool accumulate_matches=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">_sparse_mask_projection</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mask</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">accumulate_matches</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_sparse_mask_projection</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">mask</span><span class="p">,</span><span class="w"> </span><span class="n">accumulate_matches</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::to_dense(Tensor self, ScalarType? dtype=None, *, bool? masked_grad=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">to_dense</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">masked_grad</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">to_dense</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="n">masked_grad</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_to_dense(Tensor self, ScalarType? dtype=None, bool? masked_grad=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">_to_dense</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">masked_grad</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_to_dense</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="n">masked_grad</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sparse_dim(Tensor self) -&gt; int</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sparse_dim</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sparse_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::_dimI(Tensor self) -&gt; int</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">_dimI</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_dimI</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::dense_dim(Tensor self) -&gt; int</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">dense_dim</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">dense_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::_dimV(Tensor self) -&gt; int</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">_dimV</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_dimV</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::_nnz(Tensor self) -&gt; int</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">_nnz</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_nnz</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::coalesce(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">coalesce</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">coalesce</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::is_coalesced(Tensor self) -&gt; bool</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">is_coalesced</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">is_coalesced</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::_indices(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">_indices</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_indices</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::_values(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">_values</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_values</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::_coalesced_(Tensor(a!) self, bool coalesced) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">_coalesced_</span><span class="p">(</span><span class="kt">bool</span><span class="w"> </span><span class="n">coalesced</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_coalesced_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">coalesced</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::indices(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">indices</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">indices</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::values(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">values</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">values</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::crow_indices(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">crow_indices</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">crow_indices</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::col_indices(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">col_indices</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">col_indices</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::ccol_indices(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">ccol_indices</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ccol_indices</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::row_indices(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">row_indices</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">row_indices</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::unbind.int(Tensor(a -&gt; *) self, int dim=0) -&gt; Tensor(a)[]</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">unbind</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">unbind_int</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::unbind.Dimname(Tensor(a -&gt; *) self, Dimname dim) -&gt; Tensor(a)[]</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">unbind</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">unbind_Dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::to_sparse.sparse_dim(Tensor self, int sparse_dim) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">to_sparse</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">sparse_dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">to_sparse_sparse_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">sparse_dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_to_sparse.sparse_dim(Tensor self, int sparse_dim) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">_to_sparse</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">sparse_dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_to_sparse_sparse_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">sparse_dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::to_sparse(Tensor self, *, Layout? layout=None, int[2]? blocksize=None, int? dense_dim=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">to_sparse</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">OptionalIntArrayRef</span><span class="w"> </span><span class="n">blocksize</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dense_dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">to_sparse</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="n">blocksize</span><span class="p">,</span><span class="w"> </span><span class="n">dense_dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_to_sparse(Tensor self, *, Layout? layout=None, int[2]? blocksize=None, int? dense_dim=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">_to_sparse</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">OptionalIntArrayRef</span><span class="w"> </span><span class="n">blocksize</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dense_dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_to_sparse</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="n">blocksize</span><span class="p">,</span><span class="w"> </span><span class="n">dense_dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::to_sparse_csr(Tensor self, int? dense_dim=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">to_sparse_csr</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dense_dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">to_sparse_csr</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dense_dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_to_sparse_csr(Tensor self, int? dense_dim=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">_to_sparse_csr</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dense_dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_to_sparse_csr</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dense_dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::to_sparse_csc(Tensor self, int? dense_dim=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">to_sparse_csc</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dense_dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">to_sparse_csc</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dense_dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_to_sparse_csc(Tensor self, int? dense_dim=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">_to_sparse_csc</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dense_dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_to_sparse_csc</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dense_dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::to_sparse_bsr(Tensor self, int[2] blocksize, int? dense_dim=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">to_sparse_bsr</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">blocksize</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dense_dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">to_sparse_bsr</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">blocksize</span><span class="p">,</span><span class="w"> </span><span class="n">dense_dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_to_sparse_bsr(Tensor self, int[2] blocksize, int? dense_dim=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">_to_sparse_bsr</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">blocksize</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dense_dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_to_sparse_bsr</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">blocksize</span><span class="p">,</span><span class="w"> </span><span class="n">dense_dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::to_sparse_bsc(Tensor self, int[2] blocksize, int? dense_dim=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">to_sparse_bsc</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">blocksize</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dense_dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">to_sparse_bsc</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">blocksize</span><span class="p">,</span><span class="w"> </span><span class="n">dense_dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_to_sparse_bsc(Tensor self, int[2] blocksize, int? dense_dim=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">_to_sparse_bsc</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">blocksize</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dense_dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_to_sparse_bsc</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">blocksize</span><span class="p">,</span><span class="w"> </span><span class="n">dense_dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::to_mkldnn(Tensor self, ScalarType? dtype=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">to_mkldnn</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">to_mkldnn</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::dequantize.self(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">dequantize</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">dequantize_self</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::q_scale(Tensor self) -&gt; float</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">q_scale</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">q_scale</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::q_zero_point(Tensor self) -&gt; int</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">q_zero_point</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">q_zero_point</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::q_per_channel_scales(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">q_per_channel_scales</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">q_per_channel_scales</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::q_per_channel_zero_points(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">q_per_channel_zero_points</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">q_per_channel_zero_points</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::q_per_channel_axis(Tensor self) -&gt; int</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">q_per_channel_axis</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">q_per_channel_axis</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::int_repr(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">int_repr</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">int_repr</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::qscheme(Tensor self) -&gt; QScheme</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">QScheme</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">qscheme</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">qscheme</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::_autocast_to_reduced_precision(Tensor(a) self, bool cuda_enabled, bool cpu_enabled, ScalarType cuda_dtype, ScalarType cpu_dtype) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">_autocast_to_reduced_precision</span><span class="p">(</span><span class="kt">bool</span><span class="w"> </span><span class="n">cuda_enabled</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">cpu_enabled</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="w"> </span><span class="n">cuda_dtype</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="w"> </span><span class="n">cpu_dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_autocast_to_reduced_precision</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">cuda_enabled</span><span class="p">,</span><span class="w"> </span><span class="n">cpu_enabled</span><span class="p">,</span><span class="w"> </span><span class="n">cuda_dtype</span><span class="p">,</span><span class="w"> </span><span class="n">cpu_dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::_autocast_to_full_precision(Tensor(a) self, bool cuda_enabled, bool cpu_enabled) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">_autocast_to_full_precision</span><span class="p">(</span><span class="kt">bool</span><span class="w"> </span><span class="n">cuda_enabled</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">cpu_enabled</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">_autocast_to_full_precision</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">cuda_enabled</span><span class="p">,</span><span class="w"> </span><span class="n">cpu_enabled</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">to</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">TensorOptions</span><span class="w"> </span><span class="n">options</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">non_blocking</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">copy</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span><span class="w"> </span><span class="n">memory_format</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">to_dtype_layout</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">optTypeMetaToScalarType</span><span class="p">(</span><span class="n">options</span><span class="p">.</span><span class="n">dtype_opt</span><span class="p">()),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">layout_opt</span><span class="p">(),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">device_opt</span><span class="p">(),</span><span class="w"> </span><span class="n">options</span><span class="p">.</span><span class="n">pinned_memory_opt</span><span class="p">(),</span><span class="w"> </span><span class="n">non_blocking</span><span class="p">,</span><span class="w"> </span><span class="n">copy</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">impl</span><span class="o">::</span><span class="n">check_tensor_options_and_extract_memory_format</span><span class="p">(</span><span class="n">options</span><span class="p">,</span><span class="w"> </span><span class="n">memory_format</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">to</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Layout</span><span class="o">&gt;</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="o">&gt;</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">non_blocking</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">copy</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span><span class="w"> </span><span class="n">memory_format</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">to_dtype_layout</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="n">layout</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="n">pin_memory</span><span class="p">,</span><span class="w"> </span><span class="n">non_blocking</span><span class="p">,</span><span class="w"> </span><span class="n">copy</span><span class="p">,</span><span class="w"> </span><span class="n">memory_format</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">to</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Device</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">non_blocking</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">copy</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span><span class="w"> </span><span class="n">memory_format</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">to_device</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="n">non_blocking</span><span class="p">,</span><span class="w"> </span><span class="n">copy</span><span class="p">,</span><span class="w"> </span><span class="n">memory_format</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">to</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">non_blocking</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">copy</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span><span class="w"> </span><span class="n">memory_format</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">to_dtype</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dtype</span><span class="p">,</span><span class="w"> </span><span class="n">non_blocking</span><span class="p">,</span><span class="w"> </span><span class="n">copy</span><span class="p">,</span><span class="w"> </span><span class="n">memory_format</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::to.other(Tensor(a) self, Tensor other, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">to</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">non_blocking</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">copy</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">MemoryFormat</span><span class="o">&gt;</span><span class="w"> </span><span class="n">memory_format</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">to_other</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="n">non_blocking</span><span class="p">,</span><span class="w"> </span><span class="n">copy</span><span class="p">,</span><span class="w"> </span><span class="n">memory_format</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::item(Tensor self) -&gt; Scalar</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">item</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">item</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::set_.source_Storage(Tensor(a!) self, Storage source) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">set_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Storage</span><span class="w"> </span><span class="n">source</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">set__source_Storage</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">source</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::set_.source_Storage_storage_offset(Tensor(a!) self, Storage source, SymInt storage_offset, SymInt[] size, SymInt[] stride=[]) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">set_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Storage</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">storage_offset</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">set__source_Storage_storage_offset</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="n">storage_offset</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">size</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">stride</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::set_.source_Storage_storage_offset(Tensor(a!) self, Storage source, SymInt storage_offset, SymInt[] size, SymInt[] stride=[]) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">set__symint</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Storage</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">storage_offset</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">set__source_Storage_storage_offset</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="n">storage_offset</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">stride</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::set_.source_Tensor_storage_offset(Tensor(a!) self, Tensor source, SymInt storage_offset, SymInt[] size, SymInt[] stride=[]) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">set_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">storage_offset</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">set__source_Tensor_storage_offset</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="n">storage_offset</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">size</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">stride</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::set_.source_Tensor_storage_offset(Tensor(a!) self, Tensor source, SymInt storage_offset, SymInt[] size, SymInt[] stride=[]) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">set__symint</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">storage_offset</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">stride</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">set__source_Tensor_storage_offset</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="n">storage_offset</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">stride</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::set_.source_Tensor(Tensor(a!) self, Tensor source) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">set_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">set__source_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">source</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::set_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">set_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">set_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::is_set_to(Tensor self, Tensor tensor) -&gt; bool</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">is_set_to</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">tensor</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">is_set_to</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">tensor</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::masked_fill_.Scalar(Tensor(a!) self, Tensor mask, Scalar value) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">masked_fill_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mask</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">masked_fill__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">mask</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::masked_fill.Scalar(Tensor self, Tensor mask, Scalar value) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">masked_fill</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mask</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">masked_fill_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">mask</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::masked_fill_.Tensor(Tensor(a!) self, Tensor mask, Tensor value) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">masked_fill_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mask</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">masked_fill__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">mask</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::masked_fill.Tensor(Tensor self, Tensor mask, Tensor value) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">masked_fill</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mask</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">masked_fill_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">mask</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::masked_scatter_(Tensor(a!) self, Tensor mask, Tensor source) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">masked_scatter_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mask</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">masked_scatter_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">mask</span><span class="p">,</span><span class="w"> </span><span class="n">source</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::masked_scatter(Tensor self, Tensor mask, Tensor source) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">masked_scatter</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mask</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">masked_scatter</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">mask</span><span class="p">,</span><span class="w"> </span><span class="n">source</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::view(Tensor(a) self, SymInt[] size) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">view</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">IntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">view</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="n">size</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::view(Tensor(a) self, SymInt[] size) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">view_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymIntArrayRef</span><span class="w"> </span><span class="n">size</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">view</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::view.dtype(Tensor(a) self, ScalarType dtype) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">view</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">ScalarType</span><span class="w"> </span><span class="n">dtype</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">view_dtype</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dtype</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::put_(Tensor(a!) self, Tensor index, Tensor source, bool accumulate=False) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">put_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">accumulate</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">put_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="n">accumulate</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::put(Tensor self, Tensor index, Tensor source, bool accumulate=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">put</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">accumulate</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">put</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="n">accumulate</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_add_(Tensor(a!) self, int dim, Tensor index, Tensor source, *, Scalar alpha=1) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">index_add_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_add_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_add(Tensor self, int dim, Tensor index, Tensor source, *, Scalar alpha=1) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">index_add</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_add</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_add.dimname(Tensor self, Dimname dim, Tensor index, Tensor source, *, Scalar alpha=1) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">index_add</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_add_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_reduce_(Tensor(a!) self, int dim, Tensor index, Tensor source, str reduce, *, bool include_self=True) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">index_reduce_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="w"> </span><span class="n">reduce</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">include_self</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_reduce_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="n">reduce</span><span class="p">,</span><span class="w"> </span><span class="n">include_self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_reduce(Tensor self, int dim, Tensor index, Tensor source, str reduce, *, bool include_self=True) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">index_reduce</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="w"> </span><span class="n">reduce</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">include_self</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_reduce</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="n">reduce</span><span class="p">,</span><span class="w"> </span><span class="n">include_self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_fill_.int_Scalar(Tensor(a!) self, int dim, Tensor index, Scalar value) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">index_fill_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_fill__int_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_fill.int_Scalar(Tensor self, int dim, Tensor index, Scalar value) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">index_fill</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_fill_int_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_fill_.int_Tensor(Tensor(a!) self, int dim, Tensor index, Tensor value) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">index_fill_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_fill__int_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_fill.int_Tensor(Tensor self, int dim, Tensor index, Tensor value) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">index_fill</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_fill_int_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_fill_.Dimname_Scalar(Tensor(a!) self, Dimname dim, Tensor index, Scalar value) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">index_fill_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_fill__Dimname_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_fill_.Dimname_Tensor(Tensor(a!) self, Dimname dim, Tensor index, Tensor value) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">index_fill_</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_fill__Dimname_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_fill.Dimname_Scalar(Tensor self, Dimname dim, Tensor index, Scalar value) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">index_fill</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_fill_Dimname_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_fill.Dimname_Tensor(Tensor self, Dimname dim, Tensor index, Tensor value) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">index_fill</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_fill_Dimname_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter.src(Tensor self, int dim, Tensor index, Tensor src) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">scatter</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter_src</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">src</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter_.src(Tensor(a!) self, int dim, Tensor index, Tensor src) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">scatter_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter__src</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">src</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter.value(Tensor self, int dim, Tensor index, Scalar value) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">scatter</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter_value</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter_.value(Tensor(a!) self, int dim, Tensor index, Scalar value) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">scatter_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter__value</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter.reduce(Tensor self, int dim, Tensor index, Tensor src, *, str reduce) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">scatter</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="w"> </span><span class="n">reduce</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter_reduce</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">reduce</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter_.reduce(Tensor(a!) self, int dim, Tensor index, Tensor src, *, str reduce) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">scatter_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="w"> </span><span class="n">reduce</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter__reduce</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">reduce</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter.value_reduce(Tensor self, int dim, Tensor index, Scalar value, *, str reduce) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">scatter</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="w"> </span><span class="n">reduce</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter_value_reduce</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p">,</span><span class="w"> </span><span class="n">reduce</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter_.value_reduce(Tensor(a!) self, int dim, Tensor index, Scalar value, *, str reduce) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">scatter_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="w"> </span><span class="n">reduce</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter__value_reduce</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p">,</span><span class="w"> </span><span class="n">reduce</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter.dimname_src(Tensor self, Dimname dim, Tensor index, Tensor src) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">scatter</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter_dimname_src</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">src</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter.dimname_value(Tensor self, Dimname dim, Tensor index, Scalar value) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">scatter</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter_dimname_value</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter_add(Tensor self, int dim, Tensor index, Tensor src) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">scatter_add</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter_add</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">src</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter_add_(Tensor(a!) self, int dim, Tensor index, Tensor src) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">scatter_add_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter_add_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">src</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter_add.dimname(Tensor self, Dimname dim, Tensor index, Tensor src) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">scatter_add</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter_add_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">src</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter_reduce.two(Tensor self, int dim, Tensor index, Tensor src, str reduce, *, bool include_self=True) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">scatter_reduce</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="w"> </span><span class="n">reduce</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">include_self</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter_reduce_two</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">reduce</span><span class="p">,</span><span class="w"> </span><span class="n">include_self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::scatter_reduce_.two(Tensor(a!) self, int dim, Tensor index, Tensor src, str reduce, *, bool include_self=True) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">scatter_reduce_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="w"> </span><span class="n">reduce</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">include_self</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">scatter_reduce__two</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">reduce</span><span class="p">,</span><span class="w"> </span><span class="n">include_self</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::eq_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">eq_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">eq__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::eq_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">eq_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">eq__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_and.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">bitwise_and</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_and_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_and.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">bitwise_and</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_and_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_and_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">bitwise_and_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_and__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_and_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">bitwise_and_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_and__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__and__.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">__and__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__and___Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__and__.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">__and__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__and___Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__iand__.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">__iand__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__iand___Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__iand__.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">__iand__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__iand___Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_or.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">bitwise_or</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_or_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_or.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">bitwise_or</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_or_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_or_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">bitwise_or_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_or__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_or_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">bitwise_or_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_or__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__or__.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">__or__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__or___Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__or__.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">__or__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__or___Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__ior__.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">__ior__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__ior___Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__ior__.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">__ior__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__ior___Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_xor.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">bitwise_xor</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_xor_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_xor.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">bitwise_xor</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_xor_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_xor_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">bitwise_xor_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_xor__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_xor_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">bitwise_xor_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_xor__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__xor__.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">__xor__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__xor___Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__xor__.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">__xor__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__xor___Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__ixor__.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">__ixor__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__ixor___Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__ixor__.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">__ixor__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__ixor___Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__lshift__.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">__lshift__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__lshift___Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__lshift__.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">__lshift__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__lshift___Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__ilshift__.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">__ilshift__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__ilshift___Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__ilshift__.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">__ilshift__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__ilshift___Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_left_shift.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">bitwise_left_shift</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_left_shift_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_left_shift_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">bitwise_left_shift_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_left_shift__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_left_shift.Tensor_Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">bitwise_left_shift</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_left_shift_Tensor_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_left_shift_.Tensor_Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">bitwise_left_shift_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_left_shift__Tensor_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__rshift__.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">__rshift__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__rshift___Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__rshift__.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">__rshift__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__rshift___Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__irshift__.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">__irshift__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__irshift___Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::__irshift__.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">__irshift__</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">__irshift___Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_right_shift.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">bitwise_right_shift</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_right_shift_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_right_shift_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">bitwise_right_shift_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_right_shift__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_right_shift.Tensor_Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">bitwise_right_shift</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_right_shift_Tensor_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::bitwise_right_shift_.Tensor_Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">bitwise_right_shift_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">bitwise_right_shift__Tensor_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::tril_(Tensor(a!) self, int diagonal=0) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">tril_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">diagonal</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tril_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">diagonal</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::triu_(Tensor(a!) self, int diagonal=0) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">triu_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">diagonal</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">triu_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">diagonal</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::digamma_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">digamma_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">digamma_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::lerp_.Scalar(Tensor(a!) self, Tensor end, Scalar weight) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">lerp_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">end</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">weight</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lerp__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">end</span><span class="p">,</span><span class="w"> </span><span class="n">weight</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lerp_.Tensor(Tensor(a!) self, Tensor end, Tensor weight) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">lerp_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">end</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">weight</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lerp__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">end</span><span class="p">,</span><span class="w"> </span><span class="n">weight</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addbmm_(Tensor(a!) self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">addbmm_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">batch1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">batch2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">beta</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addbmm_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">batch1</span><span class="p">,</span><span class="w"> </span><span class="n">batch2</span><span class="p">,</span><span class="w"> </span><span class="n">beta</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">addbmm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">batch1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">batch2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">beta</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">alpha</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addbmm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">batch1</span><span class="p">,</span><span class="w"> </span><span class="n">batch2</span><span class="p">,</span><span class="w"> </span><span class="n">beta</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::random_.from(Tensor(a!) self, int from, int? to, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">random_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">from</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">to</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">random__from</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">from</span><span class="p">,</span><span class="w"> </span><span class="n">to</span><span class="p">,</span><span class="w"> </span><span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::random_.to(Tensor(a!) self, int to, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">random_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">to</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">random__to</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">to</span><span class="p">,</span><span class="w"> </span><span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::random_(Tensor(a!) self, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">random_</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">random_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::uniform_(Tensor(a!) self, float from=0, float to=1, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">uniform_</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">from</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">to</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">uniform_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">from</span><span class="p">,</span><span class="w"> </span><span class="n">to</span><span class="p">,</span><span class="w"> </span><span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cauchy_(Tensor(a!) self, float median=0, float sigma=1, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">cauchy_</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">median</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">sigma</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cauchy_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">median</span><span class="p">,</span><span class="w"> </span><span class="n">sigma</span><span class="p">,</span><span class="w"> </span><span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::log_normal_(Tensor(a!) self, float mean=1, float std=2, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">log_normal_</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">mean</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">std</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">log_normal_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">mean</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="p">,</span><span class="w"> </span><span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::exponential_(Tensor(a!) self, float lambd=1, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">exponential_</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">lambd</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">exponential_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">lambd</span><span class="p">,</span><span class="w"> </span><span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">geometric_</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">geometric_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::diag(Tensor self, int diagonal=0) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">diag</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">diagonal</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">diag</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">diagonal</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cross(Tensor self, Tensor other, int? dim=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">cross</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cross</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::triu(Tensor self, int diagonal=0) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">triu</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">diagonal</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">triu</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">diagonal</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::tril(Tensor self, int diagonal=0) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">tril</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">diagonal</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">tril</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">diagonal</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::trace(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">trace</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">trace</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::ne.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">ne</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ne_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ne.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">ne</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ne_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ne_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">ne_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ne__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ne_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">ne_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ne__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::not_equal.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">not_equal</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">not_equal_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::not_equal.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">not_equal</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">not_equal_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::not_equal_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">not_equal_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">not_equal__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::not_equal_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">not_equal_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">not_equal__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::eq.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">eq</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">eq_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::eq.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">eq</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">eq_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ge.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">ge</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ge_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ge.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">ge</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ge_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ge_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">ge_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ge__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ge_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">ge_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ge__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::greater_equal.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">greater_equal</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">greater_equal_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::greater_equal.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">greater_equal</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">greater_equal_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::greater_equal_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">greater_equal_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">greater_equal__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::greater_equal_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">greater_equal_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">greater_equal__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::le.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">le</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">le_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::le.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">le</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">le_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::le_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">le_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">le__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::le_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">le_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">le__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::less_equal.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">less_equal</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">less_equal_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::less_equal.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">less_equal</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">less_equal_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::less_equal_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">less_equal_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">less_equal__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::less_equal_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">less_equal_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">less_equal__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gt.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">gt</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gt_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gt.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">gt</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gt_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gt_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">gt_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gt__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gt_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">gt_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gt__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::greater.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">greater</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">greater_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::greater.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">greater</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">greater_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::greater_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">greater_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">greater__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::greater_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">greater_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">greater__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lt.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">lt</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lt_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lt.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">lt</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lt_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lt_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">lt_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lt__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lt_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">lt_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lt__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::less.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">less</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">less_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::less.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">less</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">less_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::less_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">less_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">less__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::less_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">less_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">less__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::take(Tensor self, Tensor index) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">take</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">take</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">index</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::take_along_dim(Tensor self, Tensor indices, int? dim=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">take_along_dim</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">indices</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dim</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">take_along_dim</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">indices</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_select(Tensor self, int dim, Tensor index) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">index_select</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_select</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::index_select.dimname(Tensor self, Dimname dim, Tensor index) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">index_select</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">index_select_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::masked_select(Tensor self, Tensor mask) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">masked_select</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">mask</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">masked_select</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">mask</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nonzero(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">nonzero</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nonzero</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::nonzero_static(Tensor self, *, SymInt size, int fill_value=-1) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">nonzero_static</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">fill_value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nonzero_static</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">fill_value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nonzero_static(Tensor self, *, SymInt size, int fill_value=-1) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">nonzero_static_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">fill_value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nonzero_static</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">fill_value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nonzero_numpy(Tensor self) -&gt; Tensor[]</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">nonzero_numpy</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nonzero_numpy</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::argwhere(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">argwhere</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">argwhere</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::gather(Tensor self, int dim, Tensor index, *, bool sparse_grad=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">gather</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">sparse_grad</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gather</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">sparse_grad</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::gather.dimname(Tensor self, Dimname dim, Tensor index, *, bool sparse_grad=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">gather</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">sparse_grad</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">gather_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">index</span><span class="p">,</span><span class="w"> </span><span class="n">sparse_grad</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addcmul(Tensor self, Tensor tensor1, Tensor tensor2, *, Scalar value=1) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">addcmul</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">tensor1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">tensor2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addcmul</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">tensor1</span><span class="p">,</span><span class="w"> </span><span class="n">tensor2</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addcmul_(Tensor(a!) self, Tensor tensor1, Tensor tensor2, *, Scalar value=1) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">addcmul_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">tensor1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">tensor2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addcmul_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">tensor1</span><span class="p">,</span><span class="w"> </span><span class="n">tensor2</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addcdiv(Tensor self, Tensor tensor1, Tensor tensor2, *, Scalar value=1) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">addcdiv</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">tensor1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">tensor2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addcdiv</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">tensor1</span><span class="p">,</span><span class="w"> </span><span class="n">tensor2</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::addcdiv_(Tensor(a!) self, Tensor tensor1, Tensor tensor2, *, Scalar value=1) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">addcdiv_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">tensor1</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">tensor2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">addcdiv_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">tensor1</span><span class="p">,</span><span class="w"> </span><span class="n">tensor2</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::triangular_solve(Tensor self, Tensor A, bool upper=True, bool transpose=False, bool unitriangular=False) -&gt; (Tensor solution, Tensor cloned_coefficient)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">triangular_solve</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">upper</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">transpose</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">unitriangular</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">triangular_solve</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="n">upper</span><span class="p">,</span><span class="w"> </span><span class="n">transpose</span><span class="p">,</span><span class="w"> </span><span class="n">unitriangular</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::svd(Tensor self, bool some=True, bool compute_uv=True) -&gt; (Tensor U, Tensor S, Tensor V)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">svd</span><span class="p">(</span><span class="kt">bool</span><span class="w"> </span><span class="n">some</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">compute_uv</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">svd</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">some</span><span class="p">,</span><span class="w"> </span><span class="n">compute_uv</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::swapaxes(Tensor(a) self, int axis0, int axis1) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">swapaxes</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">axis0</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">axis1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">swapaxes</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">axis0</span><span class="p">,</span><span class="w"> </span><span class="n">axis1</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::swapaxes_(Tensor(a!) self, int axis0, int axis1) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">swapaxes_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">axis0</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">axis1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">swapaxes_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">axis0</span><span class="p">,</span><span class="w"> </span><span class="n">axis1</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::swapdims(Tensor(a) self, int dim0, int dim1) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">swapdims</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim0</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">swapdims</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim0</span><span class="p">,</span><span class="w"> </span><span class="n">dim1</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::swapdims_(Tensor(a!) self, int dim0, int dim1) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">swapdims_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim0</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim1</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">swapdims_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim0</span><span class="p">,</span><span class="w"> </span><span class="n">dim1</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cholesky(Tensor self, bool upper=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">cholesky</span><span class="p">(</span><span class="kt">bool</span><span class="w"> </span><span class="n">upper</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cholesky</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">upper</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cholesky_solve(Tensor self, Tensor input2, bool upper=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">cholesky_solve</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">input2</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">upper</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cholesky_solve</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">input2</span><span class="p">,</span><span class="w"> </span><span class="n">upper</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::cholesky_inverse(Tensor self, bool upper=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">cholesky_inverse</span><span class="p">(</span><span class="kt">bool</span><span class="w"> </span><span class="n">upper</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">cholesky_inverse</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">upper</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::qr(Tensor self, bool some=True) -&gt; (Tensor Q, Tensor R)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">qr</span><span class="p">(</span><span class="kt">bool</span><span class="w"> </span><span class="n">some</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">qr</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">some</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::geqrf(Tensor self) -&gt; (Tensor a, Tensor tau)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">geqrf</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">geqrf</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::orgqr(Tensor self, Tensor input2) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">orgqr</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">input2</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">orgqr</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">input2</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ormqr(Tensor self, Tensor input2, Tensor input3, bool left=True, bool transpose=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">ormqr</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">input2</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">input3</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">left</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">transpose</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ormqr</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">input2</span><span class="p">,</span><span class="w"> </span><span class="n">input3</span><span class="p">,</span><span class="w"> </span><span class="n">left</span><span class="p">,</span><span class="w"> </span><span class="n">transpose</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lu_solve(Tensor self, Tensor LU_data, Tensor LU_pivots) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">lu_solve</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">LU_data</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">LU_pivots</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lu_solve</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">LU_data</span><span class="p">,</span><span class="w"> </span><span class="n">LU_pivots</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::multinomial(Tensor self, SymInt num_samples, bool replacement=False, *, Generator? generator=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">multinomial</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">num_samples</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">replacement</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">multinomial</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">num_samples</span><span class="p">,</span><span class="w"> </span><span class="n">replacement</span><span class="p">,</span><span class="w"> </span><span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::multinomial(Tensor self, SymInt num_samples, bool replacement=False, *, Generator? generator=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">multinomial_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">num_samples</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">replacement</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">multinomial</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">num_samples</span><span class="p">,</span><span class="w"> </span><span class="n">replacement</span><span class="p">,</span><span class="w"> </span><span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lgamma_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">lgamma_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lgamma_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::lgamma(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">lgamma</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lgamma</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::digamma(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">digamma</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">digamma</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::polygamma(int n, Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">polygamma</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">polygamma</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::polygamma_(Tensor(a!) self, int n) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">polygamma_</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">polygamma_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::erfinv(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">erfinv</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">erfinv</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::erfinv_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">erfinv_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">erfinv_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::i0(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">i0</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">i0</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::i0_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">i0_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">i0_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::sign(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sign</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sign</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::sign_(Tensor(a!) self) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sign_</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sign_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::signbit(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">signbit</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">signbit</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::dist(Tensor self, Tensor other, Scalar p=2) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">dist</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">p</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">dist</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::atan2_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">atan2_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">atan2_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::atan2(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">atan2</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">atan2</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arctan2(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">arctan2</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arctan2</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::arctan2_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">arctan2_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">arctan2_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lerp.Scalar(Tensor self, Tensor end, Scalar weight) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">lerp</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">end</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">weight</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lerp_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">end</span><span class="p">,</span><span class="w"> </span><span class="n">weight</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::lerp.Tensor(Tensor self, Tensor end, Tensor weight) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">lerp</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">end</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">weight</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">lerp_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">end</span><span class="p">,</span><span class="w"> </span><span class="n">weight</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::histc(Tensor self, int bins=100, Scalar min=0, Scalar max=0) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">histc</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">bins</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">min</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">max</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">histc</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">bins</span><span class="p">,</span><span class="w"> </span><span class="n">min</span><span class="p">,</span><span class="w"> </span><span class="n">max</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::histogram.bins_tensor(Tensor self, Tensor bins, *, Tensor? weight=None, bool density=False) -&gt; (Tensor hist, Tensor bin_edges)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">histogram</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">bins</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">weight</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">density</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">histogram_bins_tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">bins</span><span class="p">,</span><span class="w"> </span><span class="n">weight</span><span class="p">,</span><span class="w"> </span><span class="n">density</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::histogram.bin_ct(Tensor self, int bins=100, *, float[]? range=None, Tensor? weight=None, bool density=False) -&gt; (Tensor hist, Tensor bin_edges)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">histogram</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">bins</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">ArrayRef</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="n">range</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">weight</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">density</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">histogram_bin_ct</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">bins</span><span class="p">,</span><span class="w"> </span><span class="n">range</span><span class="p">,</span><span class="w"> </span><span class="n">weight</span><span class="p">,</span><span class="w"> </span><span class="n">density</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fmod.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">fmod</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fmod_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fmod_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">fmod_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fmod__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fmod.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">fmod</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fmod_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::fmod_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">fmod_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fmod__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hypot(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">hypot</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hypot</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::hypot_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">hypot_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">hypot_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::igamma(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">igamma</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">igamma</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::igamma_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">igamma_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">igamma_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::igammac(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">igammac</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">igammac</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::igammac_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">igammac_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">igammac_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nextafter(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">nextafter</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nextafter</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nextafter_(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">nextafter_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nextafter_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::remainder.Scalar(Tensor self, Scalar other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">remainder</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">remainder_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::remainder_.Scalar(Tensor(a!) self, Scalar other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">remainder_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">remainder__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::remainder.Tensor(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">remainder</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">remainder_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::remainder_.Tensor(Tensor(a!) self, Tensor other) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">remainder_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">remainder__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::min(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">min</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">min</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::fmin(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">fmin</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fmin</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">max</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::fmax(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">fmax</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">fmax</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::maximum(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">maximum</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">maximum</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::max.other(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">max</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">max_other</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::minimum(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">minimum</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">minimum</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::min.other(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">min</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">min_other</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::quantile(Tensor self, Tensor q, int? dim=None, bool keepdim=False, *, str interpolation=&#39;linear&#39;) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">quantile</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">q</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="w"> </span><span class="n">interpolation</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">quantile</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">q</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="n">interpolation</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::quantile.scalar(Tensor self, float q, int? dim=None, bool keepdim=False, *, str interpolation=&#39;linear&#39;) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">quantile</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">q</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="w"> </span><span class="n">interpolation</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">quantile_scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">q</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="n">interpolation</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nanquantile(Tensor self, Tensor q, int? dim=None, bool keepdim=False, *, str interpolation=&#39;linear&#39;) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">nanquantile</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">q</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="w"> </span><span class="n">interpolation</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nanquantile</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">q</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="n">interpolation</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::nanquantile.scalar(Tensor self, float q, int? dim=None, bool keepdim=False, *, str interpolation=&#39;linear&#39;) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">nanquantile</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">q</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">string_view</span><span class="w"> </span><span class="n">interpolation</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">nanquantile_scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">q</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">keepdim</span><span class="p">,</span><span class="w"> </span><span class="n">interpolation</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sort(Tensor self, int dim=-1, bool descending=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sort</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">descending</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sort</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">descending</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sort.stable(Tensor self, *, bool? stable, int dim=-1, bool descending=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sort</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">stable</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">descending</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sort_stable</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">stable</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">descending</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sort.dimname(Tensor self, Dimname dim, bool descending=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sort</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">descending</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sort_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">descending</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::sort.dimname_stable(Tensor self, *, bool? stable, Dimname dim, bool descending=False) -&gt; (Tensor values, Tensor indices)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">sort</span><span class="p">(</span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="w"> </span><span class="n">stable</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">descending</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">sort_dimname_stable</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">stable</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">descending</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::msort(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">msort</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">msort</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::argsort(Tensor self, int dim=-1, bool descending=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">argsort</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">descending</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">argsort</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">descending</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::argsort.stable(Tensor self, *, bool stable, int dim=-1, bool descending=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">argsort</span><span class="p">(</span><span class="kt">bool</span><span class="w"> </span><span class="n">stable</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">descending</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">argsort_stable</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">stable</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">descending</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::argsort.dimname(Tensor self, Dimname dim, bool descending=False) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">argsort</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Dimname</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">descending</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">argsort_dimname</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">descending</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::topk(Tensor self, SymInt k, int dim=-1, bool largest=True, bool sorted=True) -&gt; (Tensor values, Tensor indices)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">topk</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">largest</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">sorted</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">topk</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">largest</span><span class="p">,</span><span class="w"> </span><span class="n">sorted</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::topk(Tensor self, SymInt k, int dim=-1, bool largest=True, bool sorted=True) -&gt; (Tensor values, Tensor indices)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">topk_symint</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">SymInt</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">largest</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">sorted</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">topk</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">largest</span><span class="p">,</span><span class="w"> </span><span class="n">sorted</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::all(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">all</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">all</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::any(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">any</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">any</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::renorm(Tensor self, Scalar p, int dim, Scalar maxnorm) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">renorm</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">maxnorm</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">renorm</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">maxnorm</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::renorm_(Tensor(a!) self, Scalar p, int dim, Scalar maxnorm) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">renorm_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">maxnorm</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">renorm_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">maxnorm</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::unfold(Tensor(a) self, int dimension, int size, int step) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">unfold</span><span class="p">(</span><span class="kt">int64_t</span><span class="w"> </span><span class="n">dimension</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">step</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">unfold</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">dimension</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">step</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::equal(Tensor self, Tensor other) -&gt; bool</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">equal</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">equal</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::pow.Tensor_Tensor(Tensor self, Tensor exponent) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">pow</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">exponent</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">pow_Tensor_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">exponent</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::pow.Tensor_Scalar(Tensor self, Scalar exponent) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">pow</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">exponent</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">pow_Tensor_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">exponent</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::pow_.Scalar(Tensor(a!) self, Scalar exponent) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">pow_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">exponent</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">pow__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">exponent</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::pow_.Tensor(Tensor(a!) self, Tensor exponent) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">pow_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">exponent</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">pow__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">exponent</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::float_power.Tensor_Tensor(Tensor self, Tensor exponent) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">float_power</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">exponent</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">float_power_Tensor_Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">exponent</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::float_power.Tensor_Scalar(Tensor self, Scalar exponent) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">float_power</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">exponent</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">float_power_Tensor_Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">exponent</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::float_power_.Scalar(Tensor(a!) self, Scalar exponent) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">float_power_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Scalar</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">exponent</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">float_power__Scalar</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">exponent</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::float_power_.Tensor(Tensor(a!) self, Tensor exponent) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">float_power_</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">exponent</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">float_power__Tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">exponent</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::normal_(Tensor(a!) self, float mean=0, float std=1, *, Generator? generator=None) -&gt; Tensor(a!)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">normal_</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">mean</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="w"> </span><span class="n">std</span><span class="p">,</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Generator</span><span class="o">&gt;</span><span class="w"> </span><span class="n">generator</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">normal_</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">mean</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="p">,</span><span class="w"> </span><span class="n">generator</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::alias(Tensor(a) self) -&gt; Tensor(a)</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">alias</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">alias</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::isfinite(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">isfinite</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">isfinite</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::isinf(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">isinf</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">isinf</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::record_stream(Tensor(a!) self, Stream s) -&gt; ()</span>
<span class="kr">inline</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">record_stream</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Stream</span><span class="w"> </span><span class="n">s</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">record_stream</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">s</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::isposinf(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">isposinf</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">isposinf</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::isneginf(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">isneginf</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">isneginf</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::det(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">det</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">det</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::slogdet(Tensor self) -&gt; (Tensor sign, Tensor logabsdet)</span>
<span class="kr">inline</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">,</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">slogdet</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">slogdet</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::logdet(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">logdet</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">logdet</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::inverse(Tensor self) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">inverse</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">inverse</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// aten::inner(Tensor self, Tensor other) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">inner</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">other</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">inner</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">other</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::outer(Tensor self, Tensor vec2) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">outer</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">vec2</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">outer</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">vec2</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::ger(Tensor self, Tensor vec2) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">ger</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">vec2</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">ger</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">vec2</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::to_padded_tensor(Tensor self, float padding, SymInt[]? output_size=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">to_padded_tensor</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">padding</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">OptionalIntArrayRef</span><span class="w"> </span><span class="n">output_size</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">to_padded_tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">padding</span><span class="p">,</span><span class="w"> </span><span class="n">output_size</span><span class="p">.</span><span class="n">has_value</span><span class="p">()</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">make_optional</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">fromIntArrayRefSlow</span><span class="p">(</span><span class="o">*</span><span class="n">output_size</span><span class="p">))</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="o">::</span><span class="n">std</span><span class="o">::</span><span class="n">nullopt</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// aten::to_padded_tensor(Tensor self, float padding, SymInt[]? output_size=None) -&gt; Tensor</span>
<span class="kr">inline</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">to_padded_tensor_symint</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">padding</span><span class="p">,</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">OptionalSymIntArrayRef</span><span class="w"> </span><span class="n">output_size</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">_ops</span><span class="o">::</span><span class="n">to_padded_tensor</span><span class="o">::</span><span class="n">call</span><span class="p">(</span><span class="k">const_cast</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&amp;&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">),</span><span class="w"> </span><span class="n">padding</span><span class="p">,</span><span class="w"> </span><span class="n">output_size</span><span class="p">);</span>
<span class="p">}</span>
<span class="p">}</span><span class="w"> </span><span class="c1">// namespace at</span>


<span class="k">namespace</span><span class="w"> </span><span class="nn">c10</span><span class="w"> </span><span class="p">{</span>
<span class="k">template</span><span class="w"> </span><span class="o">&lt;&gt;</span>
<span class="k">struct</span><span class="w"> </span><span class="nc">MaybeOwnedTraits</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">using</span><span class="w"> </span><span class="n">owned_type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">;</span>
<span class="w">  </span><span class="k">using</span><span class="w"> </span><span class="n">borrow_type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">;</span>

<span class="w">  </span><span class="k">static</span><span class="w"> </span><span class="n">borrow_type</span><span class="w"> </span><span class="nf">createBorrow</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">owned_type</span><span class="o">&amp;</span><span class="w"> </span><span class="n">from</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// NOTE: this can be implemented without the special</span>
<span class="w">    </span><span class="c1">// unsafe_borrow_t Tensor constructor as</span>
<span class="w">    </span><span class="c1">//</span>
<span class="w">    </span><span class="c1">// return borrow_type(c10::intrusive_ptr&lt;at::TensorImpl, at::UndefinedTensorImpl&gt;::reclaim(from.unsafeGetTensorImpl()));</span>
<span class="w">    </span><span class="c1">//</span>
<span class="w">    </span><span class="c1">// but that hurts inlining due to the nullptr check in the</span>
<span class="w">    </span><span class="c1">// Tensor(c10::intrusive_ptr&lt;...&gt;) constructor. We already know</span>
<span class="w">    </span><span class="c1">// that from.impl_ isn&#39;t null because from is a valid Tensor, so</span>
<span class="w">    </span><span class="c1">// we needn&#39;t do the check again. (using __builtin_assume can</span>
<span class="w">    </span><span class="c1">// avoid this, but wouldn&#39;t be portable to MSVC.)</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">borrow_type</span><span class="p">(</span><span class="n">borrow_type</span><span class="o">::</span><span class="n">unsafe_borrow_t</span><span class="p">{},</span><span class="w"> </span><span class="n">from</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">static</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="nf">assignBorrow</span><span class="p">(</span><span class="n">borrow_type</span><span class="o">&amp;</span><span class="w"> </span><span class="n">lhs</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">borrow_type</span><span class="o">&amp;</span><span class="w"> </span><span class="n">rhs</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">lhs</span><span class="p">.</span><span class="n">unsafeReleaseTensorImpl</span><span class="p">();</span>
<span class="w">    </span><span class="c1">// See above note: this can be implemented with public API</span>
<span class="w">    </span><span class="c1">// similarly to createBorrow(), but that would hurt inlining.</span>
<span class="w">    </span><span class="n">lhs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">borrow_type</span><span class="p">(</span><span class="n">borrow_type</span><span class="o">::</span><span class="n">unsafe_borrow_t</span><span class="p">{},</span><span class="w"> </span><span class="n">rhs</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">static</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="nf">destroyBorrow</span><span class="p">(</span><span class="n">borrow_type</span><span class="o">&amp;</span><span class="w"> </span><span class="n">toDestroy</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">toDestroy</span><span class="p">.</span><span class="n">unsafeReleaseTensorImpl</span><span class="p">();</span><span class="w"> </span><span class="c1">// &quot;leak&quot; it, but it was already +0.</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">static</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">owned_type</span><span class="o">&amp;</span><span class="w"> </span><span class="nf">referenceFromBorrow</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">borrow_type</span><span class="o">&amp;</span><span class="w"> </span><span class="n">borrow</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">borrow</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">static</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">owned_type</span><span class="o">*</span><span class="w"> </span><span class="nf">pointerFromBorrow</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">borrow_type</span><span class="o">&amp;</span><span class="w"> </span><span class="n">borrow</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="o">&amp;</span><span class="n">borrow</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">static</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="nf">debugBorrowIsValid</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">borrow_type</span><span class="o">&amp;</span><span class="w"> </span><span class="cm">/*borrow*/</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nb">true</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">};</span>

<span class="k">template</span><span class="w"> </span><span class="o">&lt;&gt;</span>
<span class="k">struct</span><span class="w"> </span><span class="nc">ExclusivelyOwnedTraits</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">using</span><span class="w"> </span><span class="n">repr_type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">;</span>
<span class="w">  </span><span class="k">using</span><span class="w"> </span><span class="n">pointer_type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">*</span><span class="p">;</span>
<span class="w">  </span><span class="k">using</span><span class="w"> </span><span class="n">const_pointer_type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">*</span><span class="p">;</span>

<span class="w">  </span><span class="k">static</span><span class="w"> </span><span class="n">repr_type</span><span class="w"> </span><span class="nf">nullRepr</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">();</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">class</span><span class="p">...</span><span class="w"> </span><span class="n">Args</span><span class="o">&gt;</span>
<span class="w">  </span><span class="k">static</span><span class="w"> </span><span class="n">repr_type</span><span class="w"> </span><span class="n">createInPlace</span><span class="p">(</span><span class="n">Args</span><span class="o">&amp;&amp;</span><span class="p">...</span><span class="w"> </span><span class="n">args</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">forward</span><span class="o">&lt;</span><span class="n">Args</span><span class="o">&gt;</span><span class="p">(</span><span class="n">args</span><span class="p">)...);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">static</span><span class="w"> </span><span class="n">repr_type</span><span class="w"> </span><span class="n">moveToRepr</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">x</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">static</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">destroyOwned</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">ExclusivelyOwnedTraits</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">TensorBase</span><span class="o">&gt;::</span><span class="n">destroyOwned</span><span class="p">(</span><span class="n">x</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">static</span><span class="w"> </span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">take</span><span class="p">(</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&amp;</span><span class="w"> </span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">x</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">static</span><span class="w"> </span><span class="n">pointer_type</span><span class="w"> </span><span class="n">getImpl</span><span class="p">(</span><span class="n">repr_type</span><span class="o">&amp;</span><span class="w"> </span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="o">&amp;</span><span class="n">x</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">static</span><span class="w"> </span><span class="n">const_pointer_type</span><span class="w"> </span><span class="n">getImpl</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">repr_type</span><span class="o">&amp;</span><span class="w"> </span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="o">&amp;</span><span class="n">x</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">};</span>
<span class="p">}</span><span class="w"> </span><span class="c1">// namespace c10</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">at</span><span class="w"> </span><span class="p">{</span>

<span class="kr">inline</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">MaybeOwned</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">borrow_from_optional_tensor</span><span class="p">(</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">opt</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">opt</span><span class="p">.</span><span class="n">has_value</span><span class="p">()</span>
<span class="w">    </span><span class="o">?</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">MaybeOwned</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;::</span><span class="n">borrowed</span><span class="p">(</span><span class="o">*</span><span class="n">opt</span><span class="p">)</span>
<span class="w">    </span><span class="o">:</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">MaybeOwned</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;::</span><span class="n">owned</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">in_place</span><span class="p">);</span>
<span class="p">}</span>

<span class="kr">inline</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">MaybeOwned</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="w"> </span><span class="n">Tensor</span><span class="o">::</span><span class="n">expect_contiguous</span><span class="p">(</span><span class="n">MemoryFormat</span><span class="w"> </span><span class="n">memory_format</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">is_contiguous</span><span class="p">(</span><span class="n">memory_format</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">MaybeOwned</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;::</span><span class="n">borrowed</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">MaybeOwned</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;::</span><span class="n">owned</span><span class="p">(</span><span class="n">__dispatch_contiguous</span><span class="p">(</span><span class="n">memory_format</span><span class="p">));</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
<span class="p">}</span><span class="w"> </span><span class="c1">// namespace at</span>
</pre></div>
</div>
</div>


                </article>
              
  </article>
  
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn"
            onclick="openGitHubIssue()"
            data-bs-title="Create a GitHub Issue"
            data-bs-placement="bottom"
            data-bs-toggle="tooltip"
            data-gtm="feedback-btn-click">Send Feedback
    </button>
  </div>
</div>

<div class="prev-next-area">
    <a class="left-prev"
       href="file_build_aten_src_ATen_core_TensorBody.h.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">File TensorBody.h</p>
      </div>
    </a>
    <a class="right-next"
       href="file_aten_src_ATen_TensorOptions.h.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">File TensorOptions.h</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>

<div class="footer-info">
  <p class="copyright">
    
      
        © Copyright PyTorch Contributors.
      
      <br/>
    
  </p>

  <p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="file_build_aten_src_ATen_core_TensorBody.h.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">File TensorBody.h</p>
      </div>
    </a>
    <a class="right-next"
       href="file_aten_src_ATen_TensorOptions.h.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">File TensorOptions.h</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
    
       <div class="sidebar-secondary-item">
    <div class="tocsection sourcelink">
      <a href="../_sources/api/program_listing_file_build_aten_src_ATen_core_TensorBody.h.rst.txt">
        <i class="fa-solid fa-file-lines"></i> Show Source
      </a>
    </div>
</div>
    




<div class="sidebar-secondary-item">
  <div class="sidebar-heading">PyTorch Libraries</div>
  <ul style="list-style-type: none; padding: 0; padding-bottom: 80px;">
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/ao" style="color: var(--pst-color-text-muted)">torchao</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchrec" style="color: var(--pst-color-text-muted)">torchrec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchft" style="color: var(--pst-color-text-muted)">torchft</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchcodec" style="color: var(--pst-color-text-muted)">TorchCodec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/vision" style="color: var(--pst-color-text-muted)">torchvision</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/executorch" style="color: var(--pst-color-text-muted)">ExecuTorch</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/xla" style="color: var(--pst-color-text-muted)">PyTorch on XLA Devices</a></li>
  
  </ul>
</div>

</div>
</div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4">
        <h2>Docs</h2>
        <p>Access comprehensive developer documentation for PyTorch</p>
        <a class="with-right-arrow" href="https://docs.pytorch.org/docs/stable/index.html">View Docs</a>
      </div>

      <div class="col-md-4">
        <h2>Tutorials</h2>
        <p>Get in-depth tutorials for beginners and advanced developers</p>
        <a class="with-right-arrow" href="https://docs.pytorch.org/tutorials">View Tutorials</a>
      </div>

      <div class="col-md-4">
        <h2>Resources</h2>
        <p>Find development resources and get your questions answered</p>
        <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
      </div>
    </div>
  </div>
</div>

<footer class="site-footer">
  <div class="container footer-container">

    
    <div class="newsletter" id="newsletter">

      <p class="newsletter__title is-style-max-width-800"><strong>Stay in touch</strong> for updates, event info, and
        the latest news</p>


      <script charset="utf-8" type="text/javascript" src="//js.hsforms.net/forms/embed/v2.js"></script>
      <script>
        hbspt.forms.create({
          region: "na1",
          portalId: "8112310",
          formId: "2fb2231c-000b-4ec5-88a0-1ab242549c9e"
        });
      </script>


      <p class="newsletter__privacy">By submitting this form, I consent to receive marketing emails from the LF and its
        projects regarding their events, training, research, developments, and related announcements. I understand that
        I can unsubscribe at any time using the links in the footers of the emails I receive. <a
          href="https://www.linuxfoundation.org/privacy/">Privacy Policy</a>.</p>

    </div>
    

    <div class="lf-grid">
      <ul class="social-links">
        <li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-0.51 -0.26 26.45 26.45" aria-label="Facebook">
              <path fill="currentColor"
                d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z" />
            </svg>
          </a></li>
        <li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 300 300" aria-label="X">
              <path fill="currentColor"
                d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66" />
            </svg>
          </a></li>
        <li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0.21 0.27 34.45 25.07" aria-label="YouTube">
              <path fill="currentColor"
                d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z" />
            </svg>
          </a></li>
        <li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-10.23 -10.23 531.96 531.96" aria-label="LinkedIn">
              <rect width="512" height="512" rx="0" fill="currentColor" />
              <circle fill="#000" cx="142" cy="138" r="37" />
              <path stroke="#000" stroke-width="66" d="M244 194v198M142 194v198" />
              <path fill="#000"
                d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32" />
            </svg>
          </a></li>
        <li><a href="https://pytorch.slack.com" target="_blank" title="PyTorch Slack">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.16 -0.03 21.19 21.19" aria-label="Slack">
              <path fill="currentColor"
                d="M4.896 13.27a2.147 2.147 0 0 1-2.141 2.142A2.147 2.147 0 0 1 .613 13.27c0-1.178.963-2.141 2.142-2.141h2.141v2.141zm1.08 0c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.363a2.147 2.147 0 0 1-2.142 2.141 2.147 2.147 0 0 1-2.141-2.142V13.27zm2.141-8.6a2.147 2.147 0 0 1-2.141-2.14c0-1.18.962-2.142 2.141-2.142s2.142.963 2.142 2.141v2.142H8.117zm0 1.08c1.179 0 2.141.962 2.141 2.141a2.147 2.147 0 0 1-2.141 2.142H2.755A2.147 2.147 0 0 1 .613 7.89c0-1.179.963-2.141 2.142-2.141h5.362zm8.599 2.141c0-1.179.963-2.141 2.141-2.141 1.179 0 2.143.962 2.143 2.14a2.147 2.147 0 0 1-2.142 2.142h-2.141V7.89zm-1.08 0a2.147 2.147 0 0 1-2.141 2.142 2.147 2.147 0 0 1-2.141-2.142V2.53c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.362zm-2.141 8.6c1.179 0 2.142.962 2.142 2.14a2.147 2.147 0 0 1-2.142 2.142 2.147 2.147 0 0 1-2.141-2.141V16.49h2.141zm0-1.08a2.147 2.147 0 0 1-2.141-2.141c0-1.179.962-2.142 2.141-2.142h5.362c1.179 0 2.142.963 2.142 2.142a2.147 2.147 0 0 1-2.142 2.142h-5.362z">
              </path>
            </svg>
          </a></li>
        <li><a href="https://pytorch.org/wechat" title="PyTorch on WeChat">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.14 -0.17 38.02 33.02" aria-label="WeChat">
              <path fill="currentColor"
                d="M26.289 10.976a12.972 12.972 0 0 0-8.742 3.53 10.386 10.386 0 0 0-3.224 8.795c-1.326-.164-2.535-.345-3.75-.448a2.332 2.332 0 0 0-1.273.216c-1.18.666-2.311 1.418-3.652 2.255.246-1.112.405-2.087.687-3.024a1.15 1.15 0 0 0-.523-1.52C1.737 17.902.02 13.601 1.307 9.165c1.189-4.1 4.11-6.587 8.077-7.884A13.54 13.54 0 0 1 24.18 5.617a10.135 10.135 0 0 1 2.109 5.359zM10.668 9.594a1.564 1.564 0 0 0-2.095-1.472 1.52 1.52 0 0 0-.895 1.964 1.502 1.502 0 0 0 1.391.966 1.545 1.545 0 0 0 1.598-1.46v.002zm8.15-1.566a1.567 1.567 0 0 0-1.528 1.543 1.528 1.528 0 0 0 1.571 1.492 1.52 1.52 0 0 0 1.375-2.117 1.518 1.518 0 0 0-1.415-.919l-.003.001z">
              </path>
              <path fill="currentColor"
                d="M33.914 32.137c-1.075-.478-2.062-1.196-3.11-1.306-1.049-.11-2.145.494-3.24.605a10.821 10.821 0 0 1-8.781-2.864c-4.682-4.33-4.013-10.97 1.403-14.518 4.811-3.154 11.874-2.102 15.268 2.273a8.671 8.671 0 0 1-1.002 12.095c-1.046.929-1.422 1.693-.751 2.917.102.257.174.525.213.798zM21.68 20.292a1.264 1.264 0 1 0 .01-2.528 1.264 1.264 0 0 0-.01 2.528zm7.887-2.526a1.266 1.266 0 0 0-1.256 1.21 1.247 1.247 0 1 0 1.256-1.21z">
              </path>
            </svg>
          </a></li>
      </ul>
    </div>

    <div class="privacy-policy">
      <div class="copyright">
        
        <p>
          &copy; PyTorch. Copyright © The Linux Foundation®. All rights reserved. The Linux Foundation has registered
          trademarks and uses trademarks. For more information, including terms of use, privacy policy, and trademark
          usage, please see our <a href="https://www.linuxfoundation.org/legal/policies">Policies</a> page. <a
            href="https://www.linuxfoundation.org/trademark-usage">Trademark Usage</a>. <a
            href="http://www.linuxfoundation.org/privacy">Privacy Policy</a>.
        </p>
        
      </div>
    </div>


  </div>
</footer>

<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/img/pytorch-x.svg">
  </div>
</div>
  
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright PyTorch Contributors.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 5.3.0.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  <script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "Program Listing for File TensorBody.h",
       "headline": "Program Listing for File TensorBody.h",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
       "url": "/api/program_listing_file_build_aten_src_ATen_core_TensorBody.h.html",
       "articleBody": "Program Listing for File TensorBody.h# \u21b0 Return to documentation for file (build/aten/src/ATen/core/TensorBody.h) #pragma once #ifdef TORCH_ASSERT_NO_OPERATORS #error This change adds a dependency on native_functions.yaml, \\ meaning the file will need to be re-compiled every time an operator \\ is changed or added. Consider if your change would be better placed in \\ another file, or if a more specific header might achieve the same goal. \\ See NOTE: [Tensor vs. TensorBase] #endif #include \u003cc10/core/Device.h\u003e #include \u003cc10/core/Layout.h\u003e #include \u003cc10/core/MemoryFormat.h\u003e #include \u003cc10/core/QScheme.h\u003e #include \u003cc10/core/Stream.h\u003e #include \u003cc10/core/Scalar.h\u003e #include \u003cc10/core/ScalarType.h\u003e #include \u003cc10/core/ScalarTypeToTypeMeta.h\u003e #include \u003cc10/core/Storage.h\u003e #include \u003cc10/core/TensorImpl.h\u003e #include \u003cc10/core/UndefinedTensorImpl.h\u003e #include \u003cc10/core/WrapDimMinimal.h\u003e #include \u003cc10/util/Exception.h\u003e #include \u003cc10/util/ExclusivelyOwned.h\u003e #include \u003cc10/util/Deprecated.h\u003e #include \u003cc10/util/MaybeOwned.h\u003e #include \u003coptional\u003e #include \u003cc10/util/OptionalArrayRef.h\u003e #include \u003cc10/util/intrusive_ptr.h\u003e #include \u003cc10/macros/Export.h\u003e #include \u003cATen/core/CheckMemoryFormat.h\u003e #include \u003cATen/core/DeprecatedTypePropertiesRegistry.h\u003e #include \u003cATen/core/DeprecatedTypeProperties.h\u003e #include \u003cATen/core/NamedTensor.h\u003e #include \u003cATen/core/QuantizerBase.h\u003e #include \u003cc10/core/SymInt.h\u003e #include \u003cATen/core/TensorAccessor.h\u003e #include \u003cATen/core/TensorBase.h\u003e #include \u003cATen/MethodOperators.h\u003e namespace c10{ template\u003cclass T\u003e class List; template\u003cclass T\u003e class IListRef; } namespace at { struct Generator; struct Type; class DeprecatedTypeProperties; class Tensor; } // namespace at namespace at { namespace indexing { struct TensorIndex; } // namespace indexing } // namespace at namespace torch { namespace autograd { struct Node; }} // namespace torch::autograd namespace at { class OptionalTensorRef; class TensorRef; class Tensor; using TensorList = ArrayRef\u003cTensor\u003e; using ITensorList = c10::IListRef\u003cTensor\u003e; using Stream = c10::Stream; // Tensor is a \"generic\" object holding a pointer to the underlying TensorImpl object, which // has an embedded reference count. In this way, Tensor is similar to boost::intrusive_ptr. // // For example: // // void func(Tensor a) { // Tensor b = a; // ... // } // // In this example, when we say Tensor b = a, we are creating a new object that points to the // same underlying TensorImpl, and bumps its reference count. When b goes out of scope, the // destructor decrements the reference count by calling release() on the TensorImpl it points to. // The existing constructors, operator overloads, etc. take care to implement the correct semantics. // // Note that Tensor can also be NULL, i.e. it is not associated with any underlying TensorImpl, and // special care must be taken to handle this. class TORCH_API Tensor: public TensorBase { protected: // Create a Tensor with a +0 reference count. Special care must be // taken to avoid decrementing this reference count at destruction // time. Intended to support MaybeOwnedTraits\u003cTensor\u003e. explicit Tensor(unsafe_borrow_t, const TensorBase\u0026 rhs): TensorBase(unsafe_borrow_t{}, rhs) {} friend MaybeOwnedTraits\u003cTensor\u003e; friend OptionalTensorRef; friend TensorRef; public: Tensor() = default; // This constructor should not be used by end users and is an implementation // detail invoked by autogenerated code. explicit Tensor( c10::intrusive_ptr\u003cTensorImpl, UndefinedTensorImpl\u003e tensor_impl) : TensorBase(std::move(tensor_impl)) {} Tensor(const Tensor \u0026tensor) = default; Tensor(Tensor \u0026\u0026tensor) = default; // Implicitly move-constructible from TensorBase, but must be explicit to increase refcount explicit Tensor(const TensorBase \u0026base): TensorBase(base) {} /*implicit*/ Tensor(TensorBase \u0026\u0026base): TensorBase(std::move(base)) {} // Creates a new wrapper from TensorImpl. Intentionally a free method because // it should be used with care. Checks necessary invariants static Tensor wrap_tensor_impl( c10::intrusive_ptr\u003cTensorImpl, UndefinedTensorImpl\u003e tensor_impl) { return TensorBase::wrap_tensor_impl(std::move(tensor_impl)); } Tensor contiguous(MemoryFormat memory_format=MemoryFormat::Contiguous) const { return TensorBase::contiguous(memory_format); } Tensor conj() const { if (!this-\u003eis_complex()) { return *this; } switch (this-\u003elayout()) { case at::kSparse: case at::kSparseCsr: case at::kSparseCsc: case at::kSparseBsr: case at::kSparseBsc: return this-\u003econj_physical(); default: return this-\u003e_conj(); } } // Aliased by Dimname overloads, so need explicit using using TensorBase::size; using TensorBase::sym_size; using TensorBase::stride; c10::MaybeOwned\u003cTensor\u003e expect_contiguous(MemoryFormat memory_format=MemoryFormat::Contiguous) const \u0026; // Use .contiguous() instead. Trying to borrow from a prvalue Tensor // will only lead to trouble and dangling references. c10::MaybeOwned\u003cTensor\u003e expect_contiguous(MemoryFormat memory_format=MemoryFormat::Contiguous) \u0026\u0026 = delete; // The following overloads are very intruiging. Consider the following // program: // // x[1] = 3; // // We would expect that the first entry of x is written to 3. But how can we // actually achieve this? x[1] evaluates to a tensor... // // The answer is, using a ref-qualifier. x[1] is an rvalue, which cannot be // (profitably) assigned to in the traditional sense, so we overload // assignment to mean, \"Actually, copy 3 into the tensor data.\" This is done // with an rvalue-reference ref-qualified overload (the methods with \u0026\u0026 at the // end of their type.) // // There\u0027s one more fly in the ointment: We also want // // Tensor x = y; // // to work, and we want it NOT to copy. So we need a traditional operator= // overload. But we MUST specify a mutable lvalue ref-qualifier, to // disambiguate the traditional overload from the rvalue-reference // ref-qualified overload. Otherwise, it will be ambiguous, because // a non ref-qualified method is eligible for all situations. // Unfortunately, we have to write these constructors out manually // to work around an MSVC bug: // error C2580: \u0027at::Tensor \u0026at::Tensor::operator =(const at::Tensor \u0026) \u0026\u0027: // multiple versions of a defaulted special member functions are not allowed // Tensor\u0026 operator=(const Tensor\u0026) \u0026 = default; // Tensor\u0026 operator=(Tensor\u0026\u0026) \u0026 = default; // Also MSVC will wrongly issue the following warning with the aforementioned fix // warning C4522: \u0027at::Tensor\u0027: multiple assignment operators specified // Let\u0027s just skip the warning. // // TODO: temporarily disabled Tensor\u0026 operator=(const TensorBase\u0026 x) \u0026 noexcept { impl_ = x.getIntrusivePtr(); return *this; } Tensor\u0026 operator=(TensorBase\u0026\u0026 x) \u0026 noexcept { impl_ = x.unsafeReleaseIntrusivePtr(); return *this; } Tensor\u0026 operator=(const Tensor \u0026x) \u0026 noexcept { return operator=(static_cast\u003cconst TensorBase\u0026\u003e(x)); } Tensor\u0026 operator=(Tensor \u0026\u0026x) \u0026 noexcept { return operator=(static_cast\u003cTensorBase\u0026\u0026\u003e(x)); } Tensor\u0026 operator=(const Scalar \u0026v) \u0026\u0026 { return fill_(v); } Tensor\u0026 operator=(const Tensor \u0026rhs) \u0026\u0026 { return copy_(rhs); } Tensor\u0026 operator=(Tensor\u0026\u0026 rhs) \u0026\u0026 { return copy_(rhs); } C10_DEPRECATED_MESSAGE(\"Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device().\") DeprecatedTypeProperties \u0026 type() const { return globalDeprecatedTypePropertiesRegistry().getDeprecatedTypeProperties( dispatchKeyToBackend(legacyExtractDispatchKey(key_set())), scalar_type()); } Tensor toType(ScalarType t) const { return to(options().dtype(t), /*non_blocking*/ false, /*copy*/ false); } // TODO: Deprecate me Tensor toBackend(Backend b) const { return to(options().device(backendToDeviceType(b)).layout(layout_from_backend(b)), /*non_blocking*/ false, /*copy*/ false); } C10_DEPRECATED_MESSAGE(\"Tensor.is_variable() is deprecated; everything is a variable now. (If you want to assert that variable has been appropriately handled already, use at::impl::variable_excluded_from_dispatch())\") bool is_variable() const noexcept { return !at::impl::variable_excluded_from_dispatch(); } template\u003ctypename T\u003e C10_DEPRECATED_MESSAGE(\"Tensor.data\u003cT\u003e() is deprecated. Please use Tensor.data_ptr\u003cT\u003e() instead.\") T * data() const { return data_ptr\u003cT\u003e(); } template \u003ctypename T\u003e T item() const; template\u003ctypename T, size_t N, template \u003ctypename U\u003e class PtrTraits = DefaultPtrTraits, typename index_t = int64_t\u003e C10_DEPRECATED_MESSAGE(\"packed_accessor is deprecated, use packed_accessor32 or packed_accessor64 instead\") GenericPackedTensorAccessor\u003cT,N,PtrTraits,index_t\u003e packed_accessor() const \u0026 { return generic_packed_accessor\u003cT,N,PtrTraits,index_t\u003e(); } template\u003ctypename T, size_t N, template \u003ctypename U\u003e class PtrTraits = DefaultPtrTraits, typename index_t = int64_t\u003e C10_DEPRECATED_MESSAGE(\"packed_accessor is deprecated, use packed_accessor32 or packed_accessor64 instead\") GenericPackedTensorAccessor\u003cT,N,PtrTraits,index_t\u003e packed_accessor() \u0026\u0026 = delete; Tensor operator~() const { return bitwise_not(); } Tensor operator-() const { return neg(); } Tensor\u0026 operator+=(const Tensor \u0026 other) { return add_(other); } Tensor\u0026 operator+=(const Scalar \u0026 other) { return add_(other); } Tensor\u0026 operator-=(const Tensor \u0026 other) { return sub_(other); } Tensor\u0026 operator-=(const Scalar \u0026 other) { return sub_(other); } Tensor\u0026 operator*=(const Tensor \u0026 other) { return mul_(other); } Tensor\u0026 operator*=(const Scalar \u0026 other) { return mul_(other); } Tensor\u0026 operator/=(const Tensor \u0026 other) { return div_(other); } Tensor\u0026 operator/=(const Scalar \u0026 other) { return div_(other); } Tensor\u0026 operator\u0026=(const Tensor \u0026 other) { return bitwise_and_(other); } Tensor\u0026 operator|=(const Tensor \u0026 other) { return bitwise_or_(other); } Tensor\u0026 operator^=(const Tensor \u0026 other) { return bitwise_xor_(other); } Tensor operator[](const Scalar \u0026 index) const { if (!index.isIntegral(false)) { TORCH_CHECK_INDEX(false, \"Can only index tensors with integral scalars\"); } return this-\u003eoperator[](index.toLong()); } Tensor operator[](const Tensor \u0026 index) const { // These properties are checked in the Scalar constructor, but we already // check them here to provide more useful diagnostics for the user. if (!index.defined()) { TORCH_CHECK_INDEX(false, \"Can only index with tensors that are defined\"); } if (index.dim() != 0) { TORCH_CHECK_INDEX(false, \"Can only index with tensors that are scalars (zero-dim)\"); } // The Scalar(Tensor) constructor is explicit, so we need to call it. return this-\u003eoperator[](index.item()); } Tensor operator[](int64_t index) const { return select(0, index); } Tensor index(ArrayRef\u003cat::indexing::TensorIndex\u003e indices) const; Tensor index(std::initializer_list\u003cat::indexing::TensorIndex\u003e indices) const; Tensor \u0026 index_put_(ArrayRef\u003cat::indexing::TensorIndex\u003e indices, Tensor const \u0026 rhs); Tensor \u0026 index_put_(ArrayRef\u003cat::indexing::TensorIndex\u003e indices, const Scalar\u0026 v); Tensor \u0026 index_put_(std::initializer_list\u003cat::indexing::TensorIndex\u003e indices, Tensor const \u0026 rhs); Tensor \u0026 index_put_(std::initializer_list\u003cat::indexing::TensorIndex\u003e indices, const Scalar\u0026 v); Tensor cpu() const { return to(options().device(c10::DeviceType::CPU), /*non_blocking*/ false, /*copy*/ false); } // TODO: The Python version also accepts arguments Tensor cuda() const { return to(options().device(c10::DeviceType::CUDA), /*non_blocking*/ false, /*copy*/ false); } Tensor hip() const { return to(options().device(c10::DeviceType::HIP), /*non_blocking*/ false, /*copy*/ false); } Tensor ve() const { return to(options().device(c10::DeviceType::VE), /*non_blocking*/ false, /*copy*/ false); } Tensor vulkan() const { return to(options().device(c10::DeviceType::Vulkan), /*non_blocking*/ false, /*copy*/ false); } Tensor metal() const { return to(options().device(c10::DeviceType::Metal), /*non_blocking*/ false, /*copy*/ false); } Tensor meta() const { return to(options().device(c10::DeviceType::Meta), /*non_blocking*/ false, /*copy*/ false); } // ~~~~~ Autograd API ~~~~~ void backward(const Tensor \u0026 gradient={}, std::optional\u003cbool\u003e retain_graph=std::nullopt, bool create_graph=false, std::optional\u003cTensorList\u003e inputs=std::nullopt) const { // NB: Adding this wrapper to _backward here because we\u0027d like our // \u0027backwards\u0027 api to accept the \u0027inputs\u0027 argument optionally. Since code gen // currently does not support optional of TensorList our approach is to replace // backward in native_functions.yaml with _backward and call it here instead. if (inputs.has_value()) { TORCH_CHECK(inputs.value().size() \u003e 0, \"\u0027inputs\u0027 argument to backward cannot be empty\") this-\u003e_backward(inputs.value(), gradient, retain_graph, create_graph); } else { this-\u003e_backward({}, gradient, retain_graph, create_graph); } } const Tensor\u0026 set_requires_grad(bool requires_grad) const { TensorBase::set_requires_grad(requires_grad); return *this; } Tensor\u0026 mutable_grad() const { return impl_-\u003emutable_grad(); } const Tensor\u0026 grad() const { const Tensor\u0026 maybe_grad = impl_-\u003egrad(); if (!is_leaf() \u0026\u0026 !retains_grad() \u0026\u0026 !maybe_grad.defined()) { TORCH_WARN( \"The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad \" \"attribute won\u0027t be populated during autograd.backward(). If you indeed want the .grad \" \"field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. \" \"If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor \" \"instead. See github.com/pytorch/pytorch/pull/30531 for more information.\"); } return maybe_grad; } // The Forward AD API functions below are low level and are not to be used by end // users who should use the API provided in torch/csrc/autograd.h const Tensor\u0026 _fw_grad(uint64_t level) const { return impl_-\u003e_fw_grad(level, *this); } void _set_fw_grad(const TensorBase\u0026 new_grad, uint64_t level, bool is_inplace_op) const { impl_-\u003e_set_fw_grad(new_grad, *this, level, is_inplace_op); } // STOP. Thinking of adding a method here, which only makes use // of other ATen methods? Define it in native_functions.yaml. //example //Tensor * add(Tensor \u0026 b); void __dispatch__backward(at::TensorList inputs, const ::std::optional\u003cat::Tensor\u003e \u0026 gradient={}, ::std::optional\u003cbool\u003e retain_graph=::std::nullopt, bool create_graph=false) const; void __dispatch_set_data(const at::Tensor \u0026 new_data) const; at::Tensor __dispatch_data() const; bool __dispatch_is_leaf() const; int64_t __dispatch_output_nr() const; int64_t __dispatch__version() const; at::Tensor \u0026 __dispatch_requires_grad_(bool requires_grad=true) const; void __dispatch_retain_grad() const; bool __dispatch_retains_grad() const; at::Tensor _fw_primal(int64_t level) const; at::Tensor \u0026 rename_(::std::optional\u003cat::DimnameList\u003e names) const; at::Tensor rename(::std::optional\u003cat::DimnameList\u003e names) const; at::Tensor align_to(at::DimnameList names) const; at::Tensor align_to(at::DimnameList order, int64_t ellipsis_idx) const; at::Tensor align_as(const at::Tensor \u0026 other) const; at::Tensor refine_names(at::DimnameList names) const; at::Tensor abs() const; at::Tensor \u0026 abs_() const; at::Tensor absolute() const; at::Tensor \u0026 absolute_() const; at::Tensor angle() const; at::Tensor sgn() const; at::Tensor \u0026 sgn_() const; at::Tensor chalf(::std::optional\u003cat::MemoryFormat\u003e memory_format=::std::nullopt) const; at::Tensor _conj() const; at::Tensor __dispatch_conj() const; at::Tensor _conj_physical() const; at::Tensor conj_physical() const; at::Tensor \u0026 conj_physical_() const; at::Tensor resolve_conj() const; at::Tensor resolve_neg() const; at::Tensor _neg_view() const; at::Tensor acos() const; at::Tensor \u0026 acos_() const; at::Tensor arccos() const; at::Tensor \u0026 arccos_() const; at::Tensor add(const at::Tensor \u0026 other, const at::Scalar \u0026 alpha=1) const; at::Tensor \u0026 add_(const at::Tensor \u0026 other, const at::Scalar \u0026 alpha=1) const; at::Tensor add(const at::Scalar \u0026 other, const at::Scalar \u0026 alpha=1) const; at::Tensor \u0026 add_(const at::Scalar \u0026 other, const at::Scalar \u0026 alpha=1) const; at::Tensor addmv(const at::Tensor \u0026 mat, const at::Tensor \u0026 vec, const at::Scalar \u0026 beta=1, const at::Scalar \u0026 alpha=1) const; at::Tensor \u0026 addmv_(const at::Tensor \u0026 mat, const at::Tensor \u0026 vec, const at::Scalar \u0026 beta=1, const at::Scalar \u0026 alpha=1) const; at::Tensor addr(const at::Tensor \u0026 vec1, const at::Tensor \u0026 vec2, const at::Scalar \u0026 beta=1, const at::Scalar \u0026 alpha=1) const; at::Tensor \u0026 addr_(const at::Tensor \u0026 vec1, const at::Tensor \u0026 vec2, const at::Scalar \u0026 beta=1, const at::Scalar \u0026 alpha=1) const; at::Tensor _is_all_true() const; at::Tensor _is_any_true() const; at::Tensor all(int64_t dim, bool keepdim=false) const; at::Tensor all(at::OptionalIntArrayRef dim, bool keepdim=false) const; at::Tensor all(at::Dimname dim, bool keepdim=false) const; bool allclose(const at::Tensor \u0026 other, double rtol=1e-05, double atol=1e-08, bool equal_nan=false) const; at::Tensor any(int64_t dim, bool keepdim=false) const; at::Tensor any(at::OptionalIntArrayRef dim, bool keepdim=false) const; at::Tensor any(at::Dimname dim, bool keepdim=false) const; at::Tensor argmax(::std::optional\u003cint64_t\u003e dim=::std::nullopt, bool keepdim=false) const; at::Tensor argmin(::std::optional\u003cint64_t\u003e dim=::std::nullopt, bool keepdim=false) const; at::Tensor acosh() const; at::Tensor \u0026 acosh_() const; at::Tensor arccosh() const; at::Tensor \u0026 arccosh_() const; at::Tensor asinh() const; at::Tensor \u0026 asinh_() const; at::Tensor arcsinh() const; at::Tensor \u0026 arcsinh_() const; at::Tensor atanh() const; at::Tensor \u0026 atanh_() const; at::Tensor arctanh() const; at::Tensor \u0026 arctanh_() const; at::Tensor as_strided(at::IntArrayRef size, at::IntArrayRef stride, ::std::optional\u003cint64_t\u003e storage_offset=::std::nullopt) const; at::Tensor as_strided_symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride, ::std::optional\u003cc10::SymInt\u003e storage_offset=::std::nullopt) const; const at::Tensor \u0026 as_strided_(at::IntArrayRef size, at::IntArrayRef stride, ::std::optional\u003cint64_t\u003e storage_offset=::std::nullopt) const; const at::Tensor \u0026 as_strided__symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride, ::std::optional\u003cc10::SymInt\u003e storage_offset=::std::nullopt) const; at::Tensor asin() const; at::Tensor \u0026 asin_() const; at::Tensor arcsin() const; at::Tensor \u0026 arcsin_() const; at::Tensor atan() const; at::Tensor \u0026 atan_() const; at::Tensor arctan() const; at::Tensor \u0026 arctan_() const; at::Tensor baddbmm(const at::Tensor \u0026 batch1, const at::Tensor \u0026 batch2, const at::Scalar \u0026 beta=1, const at::Scalar \u0026 alpha=1) const; at::Tensor \u0026 baddbmm_(const at::Tensor \u0026 batch1, const at::Tensor \u0026 batch2, const at::Scalar \u0026 beta=1, const at::Scalar \u0026 alpha=1) const; at::Tensor bernoulli(::std::optional\u003cat::Generator\u003e generator=::std::nullopt) const; at::Tensor \u0026 bernoulli_(const at::Tensor \u0026 p, ::std::optional\u003cat::Generator\u003e generator=::std::nullopt) const; at::Tensor \u0026 bernoulli_(double p=0.5, ::std::optional\u003cat::Generator\u003e generator=::std::nullopt) const; at::Tensor bernoulli(double p, ::std::optional\u003cat::Generator\u003e generator=::std::nullopt) const; at::Tensor bincount(const ::std::optional\u003cat::Tensor\u003e \u0026 weights={}, int64_t minlength=0) const; at::Tensor bincount_symint(const ::std::optional\u003cat::Tensor\u003e \u0026 weights={}, c10::SymInt minlength=0) const; at::Tensor bitwise_not() const; at::Tensor \u0026 bitwise_not_() const; at::Tensor copysign(const at::Tensor \u0026 other) const; at::Tensor \u0026 copysign_(const at::Tensor \u0026 other) const; at::Tensor copysign(const at::Scalar \u0026 other) const; at::Tensor \u0026 copysign_(const at::Scalar \u0026 other) const; at::Tensor _lazy_clone() const; at::Tensor logical_not() const; at::Tensor \u0026 logical_not_() const; at::Tensor logical_xor(const at::Tensor \u0026 other) const; at::Tensor \u0026 logical_xor_(const at::Tensor \u0026 other) const; at::Tensor logical_and(const at::Tensor \u0026 other) const; at::Tensor \u0026 logical_and_(const at::Tensor \u0026 other) const; at::Tensor logical_or(const at::Tensor \u0026 other) const; at::Tensor \u0026 logical_or_(const at::Tensor \u0026 other) const; at::Tensor bmm(const at::Tensor \u0026 mat2) const; at::Tensor broadcast_to(at::IntArrayRef size) const; at::Tensor broadcast_to_symint(c10::SymIntArrayRef size) const; at::Tensor ceil() const; at::Tensor \u0026 ceil_() const; ::std::vector\u003cat::Tensor\u003e unsafe_chunk(int64_t chunks, int64_t dim=0) const; ::std::vector\u003cat::Tensor\u003e chunk(int64_t chunks, int64_t dim=0) const; ::std::vector\u003cat::Tensor\u003e tensor_split(int64_t sections, int64_t dim=0) const; ::std::vector\u003cat::Tensor\u003e tensor_split_symint(c10::SymInt sections, int64_t dim=0) const; ::std::vector\u003cat::Tensor\u003e tensor_split(at::IntArrayRef indices, int64_t dim=0) const; ::std::vector\u003cat::Tensor\u003e tensor_split_symint(c10::SymIntArrayRef indices, int64_t dim=0) const; ::std::vector\u003cat::Tensor\u003e tensor_split(const at::Tensor \u0026 tensor_indices_or_sections, int64_t dim=0) const; at::Tensor clamp(const ::std::optional\u003cat::Scalar\u003e \u0026 min, const ::std::optional\u003cat::Scalar\u003e \u0026 max=::std::nullopt) const; at::Tensor clamp(const ::std::optional\u003cat::Tensor\u003e \u0026 min={}, const ::std::optional\u003cat::Tensor\u003e \u0026 max={}) const; at::Tensor \u0026 clamp_(const ::std::optional\u003cat::Scalar\u003e \u0026 min, const ::std::optional\u003cat::Scalar\u003e \u0026 max=::std::nullopt) const; at::Tensor \u0026 clamp_(const ::std::optional\u003cat::Tensor\u003e \u0026 min={}, const ::std::optional\u003cat::Tensor\u003e \u0026 max={}) const; at::Tensor clamp_max(const at::Scalar \u0026 max) const; at::Tensor clamp_max(const at::Tensor \u0026 max) const; at::Tensor \u0026 clamp_max_(const at::Scalar \u0026 max) const; at::Tensor \u0026 clamp_max_(const at::Tensor \u0026 max) const; at::Tensor clamp_min(const at::Scalar \u0026 min) const; at::Tensor clamp_min(const at::Tensor \u0026 min) const; at::Tensor \u0026 clamp_min_(const at::Scalar \u0026 min) const; at::Tensor \u0026 clamp_min_(const at::Tensor \u0026 min) const; at::Tensor clip(const ::std::optional\u003cat::Scalar\u003e \u0026 min, const ::std::optional\u003cat::Scalar\u003e \u0026 max=::std::nullopt) const; at::Tensor clip(const ::std::optional\u003cat::Tensor\u003e \u0026 min={}, const ::std::optional\u003cat::Tensor\u003e \u0026 max={}) const; at::Tensor \u0026 clip_(const ::std::optional\u003cat::Scalar\u003e \u0026 min, const ::std::optional\u003cat::Scalar\u003e \u0026 max=::std::nullopt) const; at::Tensor \u0026 clip_(const ::std::optional\u003cat::Tensor\u003e \u0026 min={}, const ::std::optional\u003cat::Tensor\u003e \u0026 max={}) const; at::Tensor __dispatch_contiguous(at::MemoryFormat memory_format=c10::MemoryFormat::Contiguous) const; at::Tensor \u0026 copy_(const at::Tensor \u0026 src, bool non_blocking=false) const; at::Tensor cos() const; at::Tensor \u0026 cos_() const; at::Tensor cosh() const; at::Tensor \u0026 cosh_() const; at::Tensor count_nonzero(at::IntArrayRef dim) const; at::Tensor count_nonzero(::std::optional\u003cint64_t\u003e dim=::std::nullopt) const; at::Tensor cov(int64_t correction=1, const ::std::optional\u003cat::Tensor\u003e \u0026 fweights={}, const ::std::optional\u003cat::Tensor\u003e \u0026 aweights={}) const; at::Tensor corrcoef() const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e cummax(int64_t dim) const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e cummax(at::Dimname dim) const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e cummin(int64_t dim) const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e cummin(at::Dimname dim) const; at::Tensor cumprod(int64_t dim, ::std::optional\u003cat::ScalarType\u003e dtype=::std::nullopt) const; at::Tensor \u0026 cumprod_(int64_t dim, ::std::optional\u003cat::ScalarType\u003e dtype=::std::nullopt) const; at::Tensor cumprod(at::Dimname dim, ::std::optional\u003cat::ScalarType\u003e dtype=::std::nullopt) const; at::Tensor \u0026 cumprod_(at::Dimname dim, ::std::optional\u003cat::ScalarType\u003e dtype=::std::nullopt) const; at::Tensor cumsum(int64_t dim, ::std::optional\u003cat::ScalarType\u003e dtype=::std::nullopt) const; at::Tensor \u0026 cumsum_(int64_t dim, ::std::optional\u003cat::ScalarType\u003e dtype=::std::nullopt) const; at::Tensor cumsum(at::Dimname dim, ::std::optional\u003cat::ScalarType\u003e dtype=::std::nullopt) const; at::Tensor \u0026 cumsum_(at::Dimname dim, ::std::optional\u003cat::ScalarType\u003e dtype=::std::nullopt) const; at::Tensor diag_embed(int64_t offset=0, int64_t dim1=-2, int64_t dim2=-1) const; at::Tensor diagflat(int64_t offset=0) const; at::Tensor diagonal(int64_t offset=0, int64_t dim1=0, int64_t dim2=1) const; at::Tensor diagonal(at::Dimname outdim, at::Dimname dim1, at::Dimname dim2, int64_t offset=0) const; at::Tensor \u0026 fill_diagonal_(const at::Scalar \u0026 fill_value, bool wrap=false) const; at::Tensor diff(int64_t n=1, int64_t dim=-1, const ::std::optional\u003cat::Tensor\u003e \u0026 prepend={}, const ::std::optional\u003cat::Tensor\u003e \u0026 append={}) const; at::Tensor div(const at::Tensor \u0026 other) const; at::Tensor \u0026 div_(const at::Tensor \u0026 other) const; at::Tensor div(const at::Tensor \u0026 other, ::std::optional\u003cc10::string_view\u003e rounding_mode) const; at::Tensor \u0026 div_(const at::Tensor \u0026 other, ::std::optional\u003cc10::string_view\u003e rounding_mode) const; at::Tensor div(const at::Scalar \u0026 other) const; at::Tensor \u0026 div_(const at::Scalar \u0026 other) const; at::Tensor div(const at::Scalar \u0026 other, ::std::optional\u003cc10::string_view\u003e rounding_mode) const; at::Tensor \u0026 div_(const at::Scalar \u0026 other, ::std::optional\u003cc10::string_view\u003e rounding_mode) const; at::Tensor divide(const at::Tensor \u0026 other) const; at::Tensor \u0026 divide_(const at::Tensor \u0026 other) const; at::Tensor divide(const at::Scalar \u0026 other) const; at::Tensor \u0026 divide_(const at::Scalar \u0026 other) const; at::Tensor divide(const at::Tensor \u0026 other, ::std::optional\u003cc10::string_view\u003e rounding_mode) const; at::Tensor \u0026 divide_(const at::Tensor \u0026 other, ::std::optional\u003cc10::string_view\u003e rounding_mode) const; at::Tensor divide(const at::Scalar \u0026 other, ::std::optional\u003cc10::string_view\u003e rounding_mode) const; at::Tensor \u0026 divide_(const at::Scalar \u0026 other, ::std::optional\u003cc10::string_view\u003e rounding_mode) const; at::Tensor true_divide(const at::Tensor \u0026 other) const; at::Tensor \u0026 true_divide_(const at::Tensor \u0026 other) const; at::Tensor true_divide(const at::Scalar \u0026 other) const; at::Tensor \u0026 true_divide_(const at::Scalar \u0026 other) const; at::Tensor dot(const at::Tensor \u0026 tensor) const; at::Tensor vdot(const at::Tensor \u0026 other) const; at::Tensor new_empty(at::IntArrayRef size, at::TensorOptions options={}) const; at::Tensor new_empty(at::IntArrayRef size, ::std::optional\u003cat::ScalarType\u003e dtype, ::std::optional\u003cat::Layout\u003e layout, ::std::optional\u003cat::Device\u003e device, ::std::optional\u003cbool\u003e pin_memory) const; at::Tensor new_empty_symint(c10::SymIntArrayRef size, at::TensorOptions options={}) const; at::Tensor new_empty_symint(c10::SymIntArrayRef size, ::std::optional\u003cat::ScalarType\u003e dtype, ::std::optional\u003cat::Layout\u003e layout, ::std::optional\u003cat::Device\u003e device, ::std::optional\u003cbool\u003e pin_memory) const; at::Tensor new_empty_strided(at::IntArrayRef size, at::IntArrayRef stride, at::TensorOptions options={}) const; at::Tensor new_empty_strided(at::IntArrayRef size, at::IntArrayRef stride, ::std::optional\u003cat::ScalarType\u003e dtype, ::std::optional\u003cat::Layout\u003e layout, ::std::optional\u003cat::Device\u003e device, ::std::optional\u003cbool\u003e pin_memory) const; at::Tensor new_empty_strided_symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride, at::TensorOptions options={}) const; at::Tensor new_empty_strided_symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride, ::std::optional\u003cat::ScalarType\u003e dtype, ::std::optional\u003cat::Layout\u003e layout, ::std::optional\u003cat::Device\u003e device, ::std::optional\u003cbool\u003e pin_memory) const; at::Tensor new_full(at::IntArrayRef size, const at::Scalar \u0026 fill_value, at::TensorOptions options={}) const; at::Tensor new_full(at::IntArrayRef size, const at::Scalar \u0026 fill_value, ::std::optional\u003cat::ScalarType\u003e dtype, ::std::optional\u003cat::Layout\u003e layout, ::std::optional\u003cat::Device\u003e device, ::std::optional\u003cbool\u003e pin_memory) const; at::Tensor new_full_symint(c10::SymIntArrayRef size, const at::Scalar \u0026 fill_value, at::TensorOptions options={}) const; at::Tensor new_full_symint(c10::SymIntArrayRef size, const at::Scalar \u0026 fill_value, ::std::optional\u003cat::ScalarType\u003e dtype, ::std::optional\u003cat::Layout\u003e layout, ::std::optional\u003cat::Device\u003e device, ::std::optional\u003cbool\u003e pin_memory) const; at::Tensor new_zeros(at::IntArrayRef size, at::TensorOptions options={}) const; at::Tensor new_zeros(at::IntArrayRef size, ::std::optional\u003cat::ScalarType\u003e dtype, ::std::optional\u003cat::Layout\u003e layout, ::std::optional\u003cat::Device\u003e device, ::std::optional\u003cbool\u003e pin_memory) const; at::Tensor new_zeros_symint(c10::SymIntArrayRef size, at::TensorOptions options={}) const; at::Tensor new_zeros_symint(c10::SymIntArrayRef size, ::std::optional\u003cat::ScalarType\u003e dtype, ::std::optional\u003cat::Layout\u003e layout, ::std::optional\u003cat::Device\u003e device, ::std::optional\u003cbool\u003e pin_memory) const; at::Tensor new_ones(at::IntArrayRef size, at::TensorOptions options={}) const; at::Tensor new_ones(at::IntArrayRef size, ::std::optional\u003cat::ScalarType\u003e dtype, ::std::optional\u003cat::Layout\u003e layout, ::std::optional\u003cat::Device\u003e device, ::std::optional\u003cbool\u003e pin_memory) const; at::Tensor new_ones_symint(c10::SymIntArrayRef size, at::TensorOptions options={}) const; at::Tensor new_ones_symint(c10::SymIntArrayRef size, ::std::optional\u003cat::ScalarType\u003e dtype, ::std::optional\u003cat::Layout\u003e layout, ::std::optional\u003cat::Device\u003e device, ::std::optional\u003cbool\u003e pin_memory) const; const at::Tensor \u0026 resize_(at::IntArrayRef size, ::std::optional\u003cat::MemoryFormat\u003e memory_format=::std::nullopt) const; const at::Tensor \u0026 resize__symint(c10::SymIntArrayRef size, ::std::optional\u003cat::MemoryFormat\u003e memory_format=::std::nullopt) const; at::Tensor erf() const; at::Tensor \u0026 erf_() const; at::Tensor erfc() const; at::Tensor \u0026 erfc_() const; at::Tensor exp() const; at::Tensor \u0026 exp_() const; at::Tensor exp2() const; at::Tensor \u0026 exp2_() const; at::Tensor expm1() const; at::Tensor \u0026 expm1_() const; at::Tensor expand(at::IntArrayRef size, bool implicit=false) const; at::Tensor expand_symint(c10::SymIntArrayRef size, bool implicit=false) const; at::Tensor expand_as(const at::Tensor \u0026 other) const; at::Tensor flatten(int64_t start_dim=0, int64_t end_dim=-1) const; at::Tensor flatten(int64_t start_dim, int64_t end_dim, at::Dimname out_dim) const; at::Tensor flatten(at::Dimname start_dim, at::Dimname end_dim, at::Dimname out_dim) const; at::Tensor flatten(at::DimnameList dims, at::Dimname out_dim) const; at::Tensor unflatten(int64_t dim, at::IntArrayRef sizes) const; at::Tensor unflatten_symint(int64_t dim, c10::SymIntArrayRef sizes) const; at::Tensor unflatten(at::Dimname dim, at::IntArrayRef sizes, at::DimnameList names) const; at::Tensor unflatten_symint(at::Dimname dim, c10::SymIntArrayRef sizes, at::DimnameList names) const; at::Tensor \u0026 fill_(const at::Scalar \u0026 value) const; at::Tensor \u0026 fill_(const at::Tensor \u0026 value) const; at::Tensor floor() const; at::Tensor \u0026 floor_() const; at::Tensor floor_divide(const at::Tensor \u0026 other) const; at::Tensor \u0026 floor_divide_(const at::Tensor \u0026 other) const; at::Tensor floor_divide(const at::Scalar \u0026 other) const; at::Tensor \u0026 floor_divide_(const at::Scalar \u0026 other) const; at::Tensor frac() const; at::Tensor \u0026 frac_() const; at::Tensor gcd(const at::Tensor \u0026 other) const; at::Tensor \u0026 gcd_(const at::Tensor \u0026 other) const; at::Tensor lcm(const at::Tensor \u0026 other) const; at::Tensor \u0026 lcm_(const at::Tensor \u0026 other) const; at::Tensor index(const c10::List\u003c::std::optional\u003cat::Tensor\u003e\u003e \u0026 indices) const; at::Tensor \u0026 index_copy_(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 source) const; at::Tensor index_copy(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 source) const; at::Tensor \u0026 index_copy_(at::Dimname dim, const at::Tensor \u0026 index, const at::Tensor \u0026 source) const; at::Tensor index_copy(at::Dimname dim, const at::Tensor \u0026 index, const at::Tensor \u0026 source) const; at::Tensor \u0026 index_put_(const c10::List\u003c::std::optional\u003cat::Tensor\u003e\u003e \u0026 indices, const at::Tensor \u0026 values, bool accumulate=false) const; at::Tensor index_put(const c10::List\u003c::std::optional\u003cat::Tensor\u003e\u003e \u0026 indices, const at::Tensor \u0026 values, bool accumulate=false) const; at::Tensor isclose(const at::Tensor \u0026 other, double rtol=1e-05, double atol=1e-08, bool equal_nan=false) const; at::Tensor isnan() const; bool is_distributed() const; bool __dispatch_is_floating_point() const; bool __dispatch_is_complex() const; bool __dispatch_is_conj() const; bool __dispatch__is_zerotensor() const; bool __dispatch_is_neg() const; at::Tensor isreal() const; bool is_nonzero() const; bool is_same_size(const at::Tensor \u0026 other) const; bool __dispatch_is_signed() const; bool __dispatch_is_inference() const; at::Tensor kron(const at::Tensor \u0026 other) const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e kthvalue(int64_t k, int64_t dim=-1, bool keepdim=false) const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e kthvalue_symint(c10::SymInt k, int64_t dim=-1, bool keepdim=false) const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e kthvalue(int64_t k, at::Dimname dim, bool keepdim=false) const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e kthvalue_symint(c10::SymInt k, at::Dimname dim, bool keepdim=false) const; at::Tensor nan_to_num(::std::optional\u003cdouble\u003e nan=::std::nullopt, ::std::optional\u003cdouble\u003e posinf=::std::nullopt, ::std::optional\u003cdouble\u003e neginf=::std::nullopt) const; at::Tensor \u0026 nan_to_num_(::std::optional\u003cdouble\u003e nan=::std::nullopt, ::std::optional\u003cdouble\u003e posinf=::std::nullopt, ::std::optional\u003cdouble\u003e neginf=::std::nullopt) const; at::Tensor ldexp(const at::Tensor \u0026 other) const; at::Tensor \u0026 ldexp_(const at::Tensor \u0026 other) const; at::Tensor log() const; at::Tensor \u0026 log_() const; at::Tensor log10() const; at::Tensor \u0026 log10_() const; at::Tensor log1p() const; at::Tensor \u0026 log1p_() const; at::Tensor log2() const; at::Tensor \u0026 log2_() const; at::Tensor logaddexp(const at::Tensor \u0026 other) const; at::Tensor logaddexp2(const at::Tensor \u0026 other) const; at::Tensor xlogy(const at::Tensor \u0026 other) const; at::Tensor xlogy(const at::Scalar \u0026 other) const; at::Tensor \u0026 xlogy_(const at::Tensor \u0026 other) const; at::Tensor \u0026 xlogy_(const at::Scalar \u0026 other) const; at::Tensor log_softmax(int64_t dim, ::std::optional\u003cat::ScalarType\u003e dtype=::std::nullopt) const; at::Tensor log_softmax(at::Dimname dim, ::std::optional\u003cat::ScalarType\u003e dtype=::std::nullopt) const; at::Tensor logcumsumexp(int64_t dim) const; at::Tensor logcumsumexp(at::Dimname dim) const; at::Tensor logsumexp(at::IntArrayRef dim, bool keepdim=false) const; at::Tensor logsumexp(at::DimnameList dim, bool keepdim=false) const; at::Tensor matmul(const at::Tensor \u0026 other) const; at::Tensor matrix_power(int64_t n) const; at::Tensor matrix_exp() const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e aminmax(::std::optional\u003cint64_t\u003e dim=::std::nullopt, bool keepdim=false) const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e max(int64_t dim, bool keepdim=false) const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e max(at::Dimname dim, bool keepdim=false) const; at::Tensor amax(at::IntArrayRef dim={}, bool keepdim=false) const; at::Tensor mean(::std::optional\u003cat::ScalarType\u003e dtype=::std::nullopt) const; at::Tensor mean(at::OptionalIntArrayRef dim, bool keepdim=false, ::std::optional\u003cat::ScalarType\u003e dtype=::std::nullopt) const; at::Tensor mean(at::DimnameList dim, bool keepdim=false, ::std::optional\u003cat::ScalarType\u003e dtype=::std::nullopt) const; at::Tensor nanmean(at::OptionalIntArrayRef dim=::std::nullopt, bool keepdim=false, ::std::optional\u003cat::ScalarType\u003e dtype=::std::nullopt) const; at::Tensor median() const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e median(int64_t dim, bool keepdim=false) const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e median(at::Dimname dim, bool keepdim=false) const; at::Tensor nanmedian() const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e nanmedian(int64_t dim, bool keepdim=false) const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e nanmedian(at::Dimname dim, bool keepdim=false) const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e min(int64_t dim, bool keepdim=false) const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e min(at::Dimname dim, bool keepdim=false) const; at::Tensor amin(at::IntArrayRef dim={}, bool keepdim=false) const; at::Tensor mm(const at::Tensor \u0026 mat2) const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e mode(int64_t dim=-1, bool keepdim=false) const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e mode(at::Dimname dim, bool keepdim=false) const; at::Tensor mul(const at::Tensor \u0026 other) const; at::Tensor \u0026 mul_(const at::Tensor \u0026 other) const; at::Tensor mul(const at::Scalar \u0026 other) const; at::Tensor \u0026 mul_(const at::Scalar \u0026 other) const; at::Tensor multiply(const at::Tensor \u0026 other) const; at::Tensor \u0026 multiply_(const at::Tensor \u0026 other) const; at::Tensor multiply(const at::Scalar \u0026 other) const; at::Tensor \u0026 multiply_(const at::Scalar \u0026 other) const; at::Tensor mv(const at::Tensor \u0026 vec) const; at::Tensor mvlgamma(int64_t p) const; at::Tensor \u0026 mvlgamma_(int64_t p) const; at::Tensor narrow_copy(int64_t dim, int64_t start, int64_t length) const; at::Tensor narrow_copy_symint(int64_t dim, c10::SymInt start, c10::SymInt length) const; at::Tensor narrow(int64_t dim, int64_t start, int64_t length) const; at::Tensor narrow_symint(int64_t dim, c10::SymInt start, c10::SymInt length) const; at::Tensor narrow(int64_t dim, const at::Tensor \u0026 start, int64_t length) const; at::Tensor narrow_symint(int64_t dim, const at::Tensor \u0026 start, c10::SymInt length) const; at::Tensor permute(at::IntArrayRef dims) const; at::Tensor movedim(at::IntArrayRef source, at::IntArrayRef destination) const; at::Tensor movedim(int64_t source, int64_t destination) const; at::Tensor moveaxis(at::IntArrayRef source, at::IntArrayRef destination) const; at::Tensor moveaxis(int64_t source, int64_t destination) const; at::Tensor numpy_T() const; at::Tensor matrix_H() const; at::Tensor mT() const; at::Tensor mH() const; at::Tensor adjoint() const; bool is_pinned(::std::optional\u003cat::Device\u003e device=::std::nullopt) const; at::Tensor pin_memory(::std::optional\u003cat::Device\u003e device=::std::nullopt) const; at::Tensor pinverse(double rcond=1e-15) const; at::Tensor rad2deg() const; at::Tensor \u0026 rad2deg_() const; at::Tensor deg2rad() const; at::Tensor \u0026 deg2rad_() const; at::Tensor ravel() const; at::Tensor reciprocal() const; at::Tensor \u0026 reciprocal_() const; at::Tensor neg() const; at::Tensor \u0026 neg_() const; at::Tensor negative() const; at::Tensor \u0026 negative_() const; at::Tensor repeat(at::IntArrayRef repeats) const; at::Tensor repeat_symint(c10::SymIntArrayRef repeats) const; at::Tensor repeat_interleave(const at::Tensor \u0026 repeats, ::std::optional\u003cint64_t\u003e dim=::std::nullopt, ::std::optional\u003cint64_t\u003e output_size=::std::nullopt) const; at::Tensor repeat_interleave_symint(const at::Tensor \u0026 repeats, ::std::optional\u003cint64_t\u003e dim=::std::nullopt, ::std::optional\u003cc10::SymInt\u003e output_size=::std::nullopt) const; at::Tensor repeat_interleave(int64_t repeats, ::std::optional\u003cint64_t\u003e dim=::std::nullopt, ::std::optional\u003cint64_t\u003e output_size=::std::nullopt) const; at::Tensor repeat_interleave_symint(c10::SymInt repeats, ::std::optional\u003cint64_t\u003e dim=::std::nullopt, ::std::optional\u003cc10::SymInt\u003e output_size=::std::nullopt) const; at::Tensor reshape(at::IntArrayRef shape) const; at::Tensor reshape_symint(c10::SymIntArrayRef shape) const; at::Tensor _reshape_alias(at::IntArrayRef size, at::IntArrayRef stride) const; at::Tensor _reshape_alias_symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride) const; at::Tensor reshape_as(const at::Tensor \u0026 other) const; at::Tensor round() const; at::Tensor \u0026 round_() const; at::Tensor round(int64_t decimals) const; at::Tensor \u0026 round_(int64_t decimals) const; at::Tensor relu() const; at::Tensor \u0026 relu_() const; at::Tensor prelu(const at::Tensor \u0026 weight) const; at::Tensor hardshrink(const at::Scalar \u0026 lambd=0.5) const; at::Tensor hardshrink_backward(const at::Tensor \u0026 grad_out, const at::Scalar \u0026 lambd) const; at::Tensor rsqrt() const; at::Tensor \u0026 rsqrt_() const; at::Tensor select(at::Dimname dim, int64_t index) const; at::Tensor select(int64_t dim, int64_t index) const; at::Tensor select_symint(int64_t dim, c10::SymInt index) const; at::Tensor sigmoid() const; at::Tensor \u0026 sigmoid_() const; at::Tensor logit(::std::optional\u003cdouble\u003e eps=::std::nullopt) const; at::Tensor \u0026 logit_(::std::optional\u003cdouble\u003e eps=::std::nullopt) const; at::Tensor sin() const; at::Tensor \u0026 sin_() const; at::Tensor sinc() const; at::Tensor \u0026 sinc_() const; at::Tensor sinh() const; at::Tensor \u0026 sinh_() const; at::Tensor detach() const; at::Tensor \u0026 detach_() const; int64_t size(at::Dimname dim) const; at::Tensor slice(int64_t dim=0, ::std::optional\u003cint64_t\u003e start=::std::nullopt, ::std::optional\u003cint64_t\u003e end=::std::nullopt, int64_t step=1) const; at::Tensor slice_symint(int64_t dim=0, ::std::optional\u003cc10::SymInt\u003e start=::std::nullopt, ::std::optional\u003cc10::SymInt\u003e end=::std::nullopt, c10::SymInt step=1) const; at::Tensor slice_inverse(const at::Tensor \u0026 src, int64_t dim=0, ::std::optional\u003cint64_t\u003e start=::std::nullopt, ::std::optional\u003cint64_t\u003e end=::std::nullopt, int64_t step=1) const; at::Tensor slice_inverse_symint(const at::Tensor \u0026 src, int64_t dim=0, ::std::optional\u003cc10::SymInt\u003e start=::std::nullopt, ::std::optional\u003cc10::SymInt\u003e end=::std::nullopt, c10::SymInt step=1) const; at::Tensor slice_scatter(const at::Tensor \u0026 src, int64_t dim=0, ::std::optional\u003cint64_t\u003e start=::std::nullopt, ::std::optional\u003cint64_t\u003e end=::std::nullopt, int64_t step=1) const; at::Tensor slice_scatter_symint(const at::Tensor \u0026 src, int64_t dim=0, ::std::optional\u003cc10::SymInt\u003e start=::std::nullopt, ::std::optional\u003cc10::SymInt\u003e end=::std::nullopt, c10::SymInt step=1) const; at::Tensor select_scatter(const at::Tensor \u0026 src, int64_t dim, int64_t index) const; at::Tensor select_scatter_symint(const at::Tensor \u0026 src, int64_t dim, c10::SymInt index) const; at::Tensor diagonal_scatter(const at::Tensor \u0026 src, int64_t offset=0, int64_t dim1=0, int64_t dim2=1) const; at::Tensor as_strided_scatter(const at::Tensor \u0026 src, at::IntArrayRef size, at::IntArrayRef stride, ::std::optional\u003cint64_t\u003e storage_offset=::std::nullopt) const; at::Tensor as_strided_scatter_symint(const at::Tensor \u0026 src, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, ::std::optional\u003cc10::SymInt\u003e storage_offset=::std::nullopt) const; at::Tensor smm(const at::Tensor \u0026 mat2) const; at::Tensor softmax(int64_t dim, ::std::optional\u003cat::ScalarType\u003e dtype=::std::nullopt) const; at::Tensor softmax(at::Dimname dim, ::std::optional\u003cat::ScalarType\u003e dtype=::std::nullopt) const; ::std::vector\u003cat::Tensor\u003e unsafe_split(int64_t split_size, int64_t dim=0) const; ::std::vector\u003cat::Tensor\u003e unsafe_split_symint(c10::SymInt split_size, int64_t dim=0) const; ::std::vector\u003cat::Tensor\u003e split(int64_t split_size, int64_t dim=0) const; ::std::vector\u003cat::Tensor\u003e split_symint(c10::SymInt split_size, int64_t dim=0) const; ::std::vector\u003cat::Tensor\u003e split(at::IntArrayRef split_size, int64_t dim=0) const; ::std::vector\u003cat::Tensor\u003e split_symint(c10::SymIntArrayRef split_size, int64_t dim=0) const; ::std::vector\u003cat::Tensor\u003e unsafe_split_with_sizes(at::IntArrayRef split_sizes, int64_t dim=0) const; ::std::vector\u003cat::Tensor\u003e unsafe_split_with_sizes_symint(c10::SymIntArrayRef split_sizes, int64_t dim=0) const; ::std::vector\u003cat::Tensor\u003e split_with_sizes(at::IntArrayRef split_sizes, int64_t dim=0) const; ::std::vector\u003cat::Tensor\u003e split_with_sizes_symint(c10::SymIntArrayRef split_sizes, int64_t dim=0) const; ::std::vector\u003cat::Tensor\u003e hsplit(int64_t sections) const; ::std::vector\u003cat::Tensor\u003e hsplit(at::IntArrayRef indices) const; ::std::vector\u003cat::Tensor\u003e vsplit(int64_t sections) const; ::std::vector\u003cat::Tensor\u003e vsplit(at::IntArrayRef indices) const; ::std::vector\u003cat::Tensor\u003e dsplit(int64_t sections) const; ::std::vector\u003cat::Tensor\u003e dsplit(at::IntArrayRef indices) const; at::Tensor squeeze() const; at::Tensor squeeze(int64_t dim) const; at::Tensor squeeze(at::Dimname dim) const; at::Tensor squeeze(at::IntArrayRef dim) const; at::Tensor \u0026 squeeze_() const; at::Tensor \u0026 squeeze_(int64_t dim) const; at::Tensor \u0026 squeeze_(at::IntArrayRef dim) const; at::Tensor \u0026 squeeze_(at::Dimname dim) const; at::Tensor sspaddmm(const at::Tensor \u0026 mat1, const at::Tensor \u0026 mat2, const at::Scalar \u0026 beta=1, const at::Scalar \u0026 alpha=1) const; at::Tensor stft(int64_t n_fft, ::std::optional\u003cint64_t\u003e hop_length, ::std::optional\u003cint64_t\u003e win_length, const ::std::optional\u003cat::Tensor\u003e \u0026 window, bool normalized, ::std::optional\u003cbool\u003e onesided=::std::nullopt, ::std::optional\u003cbool\u003e return_complex=::std::nullopt, ::std::optional\u003cbool\u003e align_to_window=::std::nullopt) const; at::Tensor stft(int64_t n_fft, ::std::optional\u003cint64_t\u003e hop_length=::std::nullopt, ::std::optional\u003cint64_t\u003e win_length=::std::nullopt, const ::std::optional\u003cat::Tensor\u003e \u0026 window={}, bool center=true, c10::string_view pad_mode=\"reflect\", bool normalized=false, ::std::optional\u003cbool\u003e onesided=::std::nullopt, ::std::optional\u003cbool\u003e return_complex=::std::nullopt, ::std::optional\u003cbool\u003e align_to_window=::std::nullopt) const; at::Tensor istft(int64_t n_fft, ::std::optional\u003cint64_t\u003e hop_length=::std::nullopt, ::std::optional\u003cint64_t\u003e win_length=::std::nullopt, const ::std::optional\u003cat::Tensor\u003e \u0026 window={}, bool center=true, bool normalized=false, ::std::optional\u003cbool\u003e onesided=::std::nullopt, ::std::optional\u003cint64_t\u003e length=::std::nullopt, bool return_complex=false) const; int64_t stride(at::Dimname dim) const; at::Tensor sum(::std::optional\u003cat::ScalarType\u003e dtype=::std::nullopt) const; at::Tensor sum(at::OptionalIntArrayRef dim, bool keepdim=false, ::std::optional\u003cat::ScalarType\u003e dtype=::std::nullopt) const; at::Tensor sum(at::DimnameList dim, bool keepdim=false, ::std::optional\u003cat::ScalarType\u003e dtype=::std::nullopt) const; at::Tensor nansum(at::OptionalIntArrayRef dim=::std::nullopt, bool keepdim=false, ::std::optional\u003cat::ScalarType\u003e dtype=::std::nullopt) const; at::Tensor hash_tensor(at::IntArrayRef dim={}, bool keepdim=false, int64_t mode=0) const; at::Tensor sum_to_size(at::IntArrayRef size) const; at::Tensor sum_to_size_symint(c10::SymIntArrayRef size) const; at::Tensor sqrt() const; at::Tensor \u0026 sqrt_() const; at::Tensor square() const; at::Tensor \u0026 square_() const; at::Tensor std(bool unbiased) const; at::Tensor std(at::OptionalIntArrayRef dim, bool unbiased, bool keepdim=false) const; at::Tensor std(at::OptionalIntArrayRef dim=::std::nullopt, const ::std::optional\u003cat::Scalar\u003e \u0026 correction=::std::nullopt, bool keepdim=false) const; at::Tensor std(at::DimnameList dim, bool unbiased, bool keepdim=false) const; at::Tensor std(at::DimnameList dim, const ::std::optional\u003cat::Scalar\u003e \u0026 correction=::std::nullopt, bool keepdim=false) const; at::Tensor prod(::std::optional\u003cat::ScalarType\u003e dtype=::std::nullopt) const; at::Tensor prod(int64_t dim, bool keepdim=false, ::std::optional\u003cat::ScalarType\u003e dtype=::std::nullopt) const; at::Tensor prod(at::Dimname dim, bool keepdim=false, ::std::optional\u003cat::ScalarType\u003e dtype=::std::nullopt) const; at::Tensor t() const; at::Tensor \u0026 t_() const; at::Tensor tan() const; at::Tensor \u0026 tan_() const; at::Tensor tanh() const; at::Tensor \u0026 tanh_() const; at::Tensor tile(at::IntArrayRef dims) const; at::Tensor tile_symint(c10::SymIntArrayRef dims) const; at::Tensor transpose(int64_t dim0, int64_t dim1) const; at::Tensor transpose(at::Dimname dim0, at::Dimname dim1) const; at::Tensor \u0026 transpose_(int64_t dim0, int64_t dim1) const; at::Tensor flip(at::IntArrayRef dims) const; at::Tensor fliplr() const; at::Tensor flipud() const; at::Tensor roll(at::IntArrayRef shifts, at::IntArrayRef dims={}) const; at::Tensor roll_symint(c10::SymIntArrayRef shifts, at::IntArrayRef dims={}) const; at::Tensor rot90(int64_t k=1, at::IntArrayRef dims={0,1}) const; at::Tensor _nested_tensor_size() const; at::Tensor _nested_tensor_strides() const; at::Tensor _nested_tensor_storage_offsets() const; at::Tensor trunc() const; at::Tensor \u0026 trunc_() const; at::Tensor fix() const; at::Tensor \u0026 fix_() const; at::Tensor type_as(const at::Tensor \u0026 other) const; at::Tensor unsqueeze(int64_t dim) const; at::Tensor \u0026 unsqueeze_(int64_t dim) const; at::Tensor var(bool unbiased) const; at::Tensor var(at::OptionalIntArrayRef dim, bool unbiased, bool keepdim=false) const; at::Tensor var(at::OptionalIntArrayRef dim=::std::nullopt, const ::std::optional\u003cat::Scalar\u003e \u0026 correction=::std::nullopt, bool keepdim=false) const; at::Tensor var(at::DimnameList dim, bool unbiased, bool keepdim=false) const; at::Tensor var(at::DimnameList dim, const ::std::optional\u003cat::Scalar\u003e \u0026 correction=::std::nullopt, bool keepdim=false) const; at::Tensor view_as(const at::Tensor \u0026 other) const; at::Tensor where(const at::Tensor \u0026 condition, const at::Tensor \u0026 other) const; at::Tensor where(const at::Tensor \u0026 condition, const at::Scalar \u0026 other) const; at::Tensor norm(const ::std::optional\u003cat::Scalar\u003e \u0026 p, at::ScalarType dtype) const; at::Tensor norm(const at::Scalar \u0026 p=2) const; at::Tensor norm(const ::std::optional\u003cat::Scalar\u003e \u0026 p, at::IntArrayRef dim, bool keepdim, at::ScalarType dtype) const; at::Tensor norm(const ::std::optional\u003cat::Scalar\u003e \u0026 p, at::IntArrayRef dim, bool keepdim=false) const; at::Tensor norm(const ::std::optional\u003cat::Scalar\u003e \u0026 p, at::DimnameList dim, bool keepdim, at::ScalarType dtype) const; at::Tensor norm(const ::std::optional\u003cat::Scalar\u003e \u0026 p, at::DimnameList dim, bool keepdim=false) const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e frexp() const; at::Tensor clone(::std::optional\u003cat::MemoryFormat\u003e memory_format=::std::nullopt) const; at::Tensor positive() const; const at::Tensor \u0026 resize_as_(const at::Tensor \u0026 the_template, ::std::optional\u003cat::MemoryFormat\u003e memory_format=::std::nullopt) const; const at::Tensor \u0026 resize_as_sparse_(const at::Tensor \u0026 the_template) const; at::Tensor \u0026 zero_() const; at::Tensor sub(const at::Tensor \u0026 other, const at::Scalar \u0026 alpha=1) const; at::Tensor \u0026 sub_(const at::Tensor \u0026 other, const at::Scalar \u0026 alpha=1) const; at::Tensor sub(const at::Scalar \u0026 other, const at::Scalar \u0026 alpha=1) const; at::Tensor \u0026 sub_(const at::Scalar \u0026 other, const at::Scalar \u0026 alpha=1) const; at::Tensor subtract(const at::Tensor \u0026 other, const at::Scalar \u0026 alpha=1) const; at::Tensor \u0026 subtract_(const at::Tensor \u0026 other, const at::Scalar \u0026 alpha=1) const; at::Tensor subtract(const at::Scalar \u0026 other, const at::Scalar \u0026 alpha=1) const; at::Tensor \u0026 subtract_(const at::Scalar \u0026 other, const at::Scalar \u0026 alpha=1) const; at::Tensor heaviside(const at::Tensor \u0026 values) const; at::Tensor \u0026 heaviside_(const at::Tensor \u0026 values) const; at::Tensor addmm(const at::Tensor \u0026 mat1, const at::Tensor \u0026 mat2, const at::Scalar \u0026 beta=1, const at::Scalar \u0026 alpha=1) const; at::Tensor \u0026 addmm_(const at::Tensor \u0026 mat1, const at::Tensor \u0026 mat2, const at::Scalar \u0026 beta=1, const at::Scalar \u0026 alpha=1) const; at::Tensor _addmm_activation(const at::Tensor \u0026 mat1, const at::Tensor \u0026 mat2, const at::Scalar \u0026 beta=1, const at::Scalar \u0026 alpha=1, bool use_gelu=false) const; const at::Tensor \u0026 sparse_resize_(at::IntArrayRef size, int64_t sparse_dim, int64_t dense_dim) const; const at::Tensor \u0026 sparse_resize_and_clear_(at::IntArrayRef size, int64_t sparse_dim, int64_t dense_dim) const; at::Tensor sparse_mask(const at::Tensor \u0026 mask) const; at::Tensor _sparse_mask_projection(const at::Tensor \u0026 mask, bool accumulate_matches=false) const; at::Tensor to_dense(::std::optional\u003cat::ScalarType\u003e dtype=::std::nullopt, ::std::optional\u003cbool\u003e masked_grad=::std::nullopt) const; at::Tensor _to_dense(::std::optional\u003cat::ScalarType\u003e dtype=::std::nullopt, ::std::optional\u003cbool\u003e masked_grad=::std::nullopt) const; int64_t sparse_dim() const; int64_t _dimI() const; int64_t dense_dim() const; int64_t _dimV() const; int64_t _nnz() const; at::Tensor coalesce() const; bool is_coalesced() const; at::Tensor _indices() const; at::Tensor _values() const; at::Tensor \u0026 _coalesced_(bool coalesced) const; at::Tensor indices() const; at::Tensor values() const; at::Tensor crow_indices() const; at::Tensor col_indices() const; at::Tensor ccol_indices() const; at::Tensor row_indices() const; ::std::vector\u003cat::Tensor\u003e unbind(int64_t dim=0) const; ::std::vector\u003cat::Tensor\u003e unbind(at::Dimname dim) const; at::Tensor to_sparse(int64_t sparse_dim) const; at::Tensor _to_sparse(int64_t sparse_dim) const; at::Tensor to_sparse(::std::optional\u003cat::Layout\u003e layout=::std::nullopt, at::OptionalIntArrayRef blocksize=::std::nullopt, ::std::optional\u003cint64_t\u003e dense_dim=::std::nullopt) const; at::Tensor _to_sparse(::std::optional\u003cat::Layout\u003e layout=::std::nullopt, at::OptionalIntArrayRef blocksize=::std::nullopt, ::std::optional\u003cint64_t\u003e dense_dim=::std::nullopt) const; at::Tensor to_sparse_csr(::std::optional\u003cint64_t\u003e dense_dim=::std::nullopt) const; at::Tensor _to_sparse_csr(::std::optional\u003cint64_t\u003e dense_dim=::std::nullopt) const; at::Tensor to_sparse_csc(::std::optional\u003cint64_t\u003e dense_dim=::std::nullopt) const; at::Tensor _to_sparse_csc(::std::optional\u003cint64_t\u003e dense_dim=::std::nullopt) const; at::Tensor to_sparse_bsr(at::IntArrayRef blocksize, ::std::optional\u003cint64_t\u003e dense_dim=::std::nullopt) const; at::Tensor _to_sparse_bsr(at::IntArrayRef blocksize, ::std::optional\u003cint64_t\u003e dense_dim=::std::nullopt) const; at::Tensor to_sparse_bsc(at::IntArrayRef blocksize, ::std::optional\u003cint64_t\u003e dense_dim=::std::nullopt) const; at::Tensor _to_sparse_bsc(at::IntArrayRef blocksize, ::std::optional\u003cint64_t\u003e dense_dim=::std::nullopt) const; at::Tensor to_mkldnn(::std::optional\u003cat::ScalarType\u003e dtype=::std::nullopt) const; at::Tensor dequantize() const; double q_scale() const; int64_t q_zero_point() const; at::Tensor q_per_channel_scales() const; at::Tensor q_per_channel_zero_points() const; int64_t q_per_channel_axis() const; at::Tensor int_repr() const; at::QScheme qscheme() const; at::Tensor _autocast_to_reduced_precision(bool cuda_enabled, bool cpu_enabled, at::ScalarType cuda_dtype, at::ScalarType cpu_dtype) const; at::Tensor _autocast_to_full_precision(bool cuda_enabled, bool cpu_enabled) const; at::Tensor to(at::TensorOptions options={}, bool non_blocking=false, bool copy=false, ::std::optional\u003cat::MemoryFormat\u003e memory_format=::std::nullopt) const; at::Tensor to(::std::optional\u003cat::ScalarType\u003e dtype, ::std::optional\u003cat::Layout\u003e layout, ::std::optional\u003cat::Device\u003e device, ::std::optional\u003cbool\u003e pin_memory, bool non_blocking, bool copy, ::std::optional\u003cat::MemoryFormat\u003e memory_format) const; at::Tensor to(at::Device device, at::ScalarType dtype, bool non_blocking=false, bool copy=false, ::std::optional\u003cat::MemoryFormat\u003e memory_format=::std::nullopt) const; at::Tensor to(at::ScalarType dtype, bool non_blocking=false, bool copy=false, ::std::optional\u003cat::MemoryFormat\u003e memory_format=::std::nullopt) const; at::Tensor to(const at::Tensor \u0026 other, bool non_blocking=false, bool copy=false, ::std::optional\u003cat::MemoryFormat\u003e memory_format=::std::nullopt) const; at::Scalar item() const; at::Tensor \u0026 set_(at::Storage source) const; at::Tensor \u0026 set_(at::Storage source, int64_t storage_offset, at::IntArrayRef size, at::IntArrayRef stride={}) const; at::Tensor \u0026 set__symint(at::Storage source, c10::SymInt storage_offset, c10::SymIntArrayRef size, c10::SymIntArrayRef stride={}) const; at::Tensor \u0026 set_(const at::Tensor \u0026 source, int64_t storage_offset, at::IntArrayRef size, at::IntArrayRef stride={}) const; at::Tensor \u0026 set__symint(const at::Tensor \u0026 source, c10::SymInt storage_offset, c10::SymIntArrayRef size, c10::SymIntArrayRef stride={}) const; at::Tensor \u0026 set_(const at::Tensor \u0026 source) const; at::Tensor \u0026 set_() const; bool is_set_to(const at::Tensor \u0026 tensor) const; at::Tensor \u0026 masked_fill_(const at::Tensor \u0026 mask, const at::Scalar \u0026 value) const; at::Tensor masked_fill(const at::Tensor \u0026 mask, const at::Scalar \u0026 value) const; at::Tensor \u0026 masked_fill_(const at::Tensor \u0026 mask, const at::Tensor \u0026 value) const; at::Tensor masked_fill(const at::Tensor \u0026 mask, const at::Tensor \u0026 value) const; at::Tensor \u0026 masked_scatter_(const at::Tensor \u0026 mask, const at::Tensor \u0026 source) const; at::Tensor masked_scatter(const at::Tensor \u0026 mask, const at::Tensor \u0026 source) const; at::Tensor view(at::IntArrayRef size) const; at::Tensor view_symint(c10::SymIntArrayRef size) const; at::Tensor view(at::ScalarType dtype) const; at::Tensor \u0026 put_(const at::Tensor \u0026 index, const at::Tensor \u0026 source, bool accumulate=false) const; at::Tensor put(const at::Tensor \u0026 index, const at::Tensor \u0026 source, bool accumulate=false) const; at::Tensor \u0026 index_add_(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 source, const at::Scalar \u0026 alpha=1) const; at::Tensor index_add(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 source, const at::Scalar \u0026 alpha=1) const; at::Tensor index_add(at::Dimname dim, const at::Tensor \u0026 index, const at::Tensor \u0026 source, const at::Scalar \u0026 alpha=1) const; at::Tensor \u0026 index_reduce_(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 source, c10::string_view reduce, bool include_self=true) const; at::Tensor index_reduce(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 source, c10::string_view reduce, bool include_self=true) const; at::Tensor \u0026 index_fill_(int64_t dim, const at::Tensor \u0026 index, const at::Scalar \u0026 value) const; at::Tensor index_fill(int64_t dim, const at::Tensor \u0026 index, const at::Scalar \u0026 value) const; at::Tensor \u0026 index_fill_(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 value) const; at::Tensor index_fill(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 value) const; at::Tensor \u0026 index_fill_(at::Dimname dim, const at::Tensor \u0026 index, const at::Scalar \u0026 value) const; at::Tensor \u0026 index_fill_(at::Dimname dim, const at::Tensor \u0026 index, const at::Tensor \u0026 value) const; at::Tensor index_fill(at::Dimname dim, const at::Tensor \u0026 index, const at::Scalar \u0026 value) const; at::Tensor index_fill(at::Dimname dim, const at::Tensor \u0026 index, const at::Tensor \u0026 value) const; at::Tensor scatter(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 src) const; at::Tensor \u0026 scatter_(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 src) const; at::Tensor scatter(int64_t dim, const at::Tensor \u0026 index, const at::Scalar \u0026 value) const; at::Tensor \u0026 scatter_(int64_t dim, const at::Tensor \u0026 index, const at::Scalar \u0026 value) const; at::Tensor scatter(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 src, c10::string_view reduce) const; at::Tensor \u0026 scatter_(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 src, c10::string_view reduce) const; at::Tensor scatter(int64_t dim, const at::Tensor \u0026 index, const at::Scalar \u0026 value, c10::string_view reduce) const; at::Tensor \u0026 scatter_(int64_t dim, const at::Tensor \u0026 index, const at::Scalar \u0026 value, c10::string_view reduce) const; at::Tensor scatter(at::Dimname dim, const at::Tensor \u0026 index, const at::Tensor \u0026 src) const; at::Tensor scatter(at::Dimname dim, const at::Tensor \u0026 index, const at::Scalar \u0026 value) const; at::Tensor scatter_add(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 src) const; at::Tensor \u0026 scatter_add_(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 src) const; at::Tensor scatter_add(at::Dimname dim, const at::Tensor \u0026 index, const at::Tensor \u0026 src) const; at::Tensor scatter_reduce(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 src, c10::string_view reduce, bool include_self=true) const; at::Tensor \u0026 scatter_reduce_(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 src, c10::string_view reduce, bool include_self=true) const; at::Tensor \u0026 eq_(const at::Scalar \u0026 other) const; at::Tensor \u0026 eq_(const at::Tensor \u0026 other) const; at::Tensor bitwise_and(const at::Scalar \u0026 other) const; at::Tensor bitwise_and(const at::Tensor \u0026 other) const; at::Tensor \u0026 bitwise_and_(const at::Scalar \u0026 other) const; at::Tensor \u0026 bitwise_and_(const at::Tensor \u0026 other) const; at::Tensor __and__(const at::Scalar \u0026 other) const; at::Tensor __and__(const at::Tensor \u0026 other) const; at::Tensor \u0026 __iand__(const at::Scalar \u0026 other) const; at::Tensor \u0026 __iand__(const at::Tensor \u0026 other) const; at::Tensor bitwise_or(const at::Scalar \u0026 other) const; at::Tensor bitwise_or(const at::Tensor \u0026 other) const; at::Tensor \u0026 bitwise_or_(const at::Scalar \u0026 other) const; at::Tensor \u0026 bitwise_or_(const at::Tensor \u0026 other) const; at::Tensor __or__(const at::Scalar \u0026 other) const; at::Tensor __or__(const at::Tensor \u0026 other) const; at::Tensor \u0026 __ior__(const at::Scalar \u0026 other) const; at::Tensor \u0026 __ior__(const at::Tensor \u0026 other) const; at::Tensor bitwise_xor(const at::Scalar \u0026 other) const; at::Tensor bitwise_xor(const at::Tensor \u0026 other) const; at::Tensor \u0026 bitwise_xor_(const at::Scalar \u0026 other) const; at::Tensor \u0026 bitwise_xor_(const at::Tensor \u0026 other) const; at::Tensor __xor__(const at::Scalar \u0026 other) const; at::Tensor __xor__(const at::Tensor \u0026 other) const; at::Tensor \u0026 __ixor__(const at::Scalar \u0026 other) const; at::Tensor \u0026 __ixor__(const at::Tensor \u0026 other) const; at::Tensor __lshift__(const at::Scalar \u0026 other) const; at::Tensor __lshift__(const at::Tensor \u0026 other) const; at::Tensor \u0026 __ilshift__(const at::Scalar \u0026 other) const; at::Tensor \u0026 __ilshift__(const at::Tensor \u0026 other) const; at::Tensor bitwise_left_shift(const at::Tensor \u0026 other) const; at::Tensor \u0026 bitwise_left_shift_(const at::Tensor \u0026 other) const; at::Tensor bitwise_left_shift(const at::Scalar \u0026 other) const; at::Tensor \u0026 bitwise_left_shift_(const at::Scalar \u0026 other) const; at::Tensor __rshift__(const at::Scalar \u0026 other) const; at::Tensor __rshift__(const at::Tensor \u0026 other) const; at::Tensor \u0026 __irshift__(const at::Scalar \u0026 other) const; at::Tensor \u0026 __irshift__(const at::Tensor \u0026 other) const; at::Tensor bitwise_right_shift(const at::Tensor \u0026 other) const; at::Tensor \u0026 bitwise_right_shift_(const at::Tensor \u0026 other) const; at::Tensor bitwise_right_shift(const at::Scalar \u0026 other) const; at::Tensor \u0026 bitwise_right_shift_(const at::Scalar \u0026 other) const; at::Tensor \u0026 tril_(int64_t diagonal=0) const; at::Tensor \u0026 triu_(int64_t diagonal=0) const; at::Tensor \u0026 digamma_() const; at::Tensor \u0026 lerp_(const at::Tensor \u0026 end, const at::Scalar \u0026 weight) const; at::Tensor \u0026 lerp_(const at::Tensor \u0026 end, const at::Tensor \u0026 weight) const; at::Tensor \u0026 addbmm_(const at::Tensor \u0026 batch1, const at::Tensor \u0026 batch2, const at::Scalar \u0026 beta=1, const at::Scalar \u0026 alpha=1) const; at::Tensor addbmm(const at::Tensor \u0026 batch1, const at::Tensor \u0026 batch2, const at::Scalar \u0026 beta=1, const at::Scalar \u0026 alpha=1) const; at::Tensor \u0026 random_(int64_t from, ::std::optional\u003cint64_t\u003e to, ::std::optional\u003cat::Generator\u003e generator=::std::nullopt) const; at::Tensor \u0026 random_(int64_t to, ::std::optional\u003cat::Generator\u003e generator=::std::nullopt) const; at::Tensor \u0026 random_(::std::optional\u003cat::Generator\u003e generator=::std::nullopt) const; at::Tensor \u0026 uniform_(double from=0, double to=1, ::std::optional\u003cat::Generator\u003e generator=::std::nullopt) const; at::Tensor \u0026 cauchy_(double median=0, double sigma=1, ::std::optional\u003cat::Generator\u003e generator=::std::nullopt) const; at::Tensor \u0026 log_normal_(double mean=1, double std=2, ::std::optional\u003cat::Generator\u003e generator=::std::nullopt) const; at::Tensor \u0026 exponential_(double lambd=1, ::std::optional\u003cat::Generator\u003e generator=::std::nullopt) const; at::Tensor \u0026 geometric_(double p, ::std::optional\u003cat::Generator\u003e generator=::std::nullopt) const; at::Tensor diag(int64_t diagonal=0) const; at::Tensor cross(const at::Tensor \u0026 other, ::std::optional\u003cint64_t\u003e dim=::std::nullopt) const; at::Tensor triu(int64_t diagonal=0) const; at::Tensor tril(int64_t diagonal=0) const; at::Tensor trace() const; at::Tensor ne(const at::Scalar \u0026 other) const; at::Tensor ne(const at::Tensor \u0026 other) const; at::Tensor \u0026 ne_(const at::Scalar \u0026 other) const; at::Tensor \u0026 ne_(const at::Tensor \u0026 other) const; at::Tensor not_equal(const at::Scalar \u0026 other) const; at::Tensor not_equal(const at::Tensor \u0026 other) const; at::Tensor \u0026 not_equal_(const at::Scalar \u0026 other) const; at::Tensor \u0026 not_equal_(const at::Tensor \u0026 other) const; at::Tensor eq(const at::Scalar \u0026 other) const; at::Tensor eq(const at::Tensor \u0026 other) const; at::Tensor ge(const at::Scalar \u0026 other) const; at::Tensor ge(const at::Tensor \u0026 other) const; at::Tensor \u0026 ge_(const at::Scalar \u0026 other) const; at::Tensor \u0026 ge_(const at::Tensor \u0026 other) const; at::Tensor greater_equal(const at::Scalar \u0026 other) const; at::Tensor greater_equal(const at::Tensor \u0026 other) const; at::Tensor \u0026 greater_equal_(const at::Scalar \u0026 other) const; at::Tensor \u0026 greater_equal_(const at::Tensor \u0026 other) const; at::Tensor le(const at::Scalar \u0026 other) const; at::Tensor le(const at::Tensor \u0026 other) const; at::Tensor \u0026 le_(const at::Scalar \u0026 other) const; at::Tensor \u0026 le_(const at::Tensor \u0026 other) const; at::Tensor less_equal(const at::Scalar \u0026 other) const; at::Tensor less_equal(const at::Tensor \u0026 other) const; at::Tensor \u0026 less_equal_(const at::Scalar \u0026 other) const; at::Tensor \u0026 less_equal_(const at::Tensor \u0026 other) const; at::Tensor gt(const at::Scalar \u0026 other) const; at::Tensor gt(const at::Tensor \u0026 other) const; at::Tensor \u0026 gt_(const at::Scalar \u0026 other) const; at::Tensor \u0026 gt_(const at::Tensor \u0026 other) const; at::Tensor greater(const at::Scalar \u0026 other) const; at::Tensor greater(const at::Tensor \u0026 other) const; at::Tensor \u0026 greater_(const at::Scalar \u0026 other) const; at::Tensor \u0026 greater_(const at::Tensor \u0026 other) const; at::Tensor lt(const at::Scalar \u0026 other) const; at::Tensor lt(const at::Tensor \u0026 other) const; at::Tensor \u0026 lt_(const at::Scalar \u0026 other) const; at::Tensor \u0026 lt_(const at::Tensor \u0026 other) const; at::Tensor less(const at::Scalar \u0026 other) const; at::Tensor less(const at::Tensor \u0026 other) const; at::Tensor \u0026 less_(const at::Scalar \u0026 other) const; at::Tensor \u0026 less_(const at::Tensor \u0026 other) const; at::Tensor take(const at::Tensor \u0026 index) const; at::Tensor take_along_dim(const at::Tensor \u0026 indices, ::std::optional\u003cint64_t\u003e dim=::std::nullopt) const; at::Tensor index_select(int64_t dim, const at::Tensor \u0026 index) const; at::Tensor index_select(at::Dimname dim, const at::Tensor \u0026 index) const; at::Tensor masked_select(const at::Tensor \u0026 mask) const; at::Tensor nonzero() const; at::Tensor nonzero_static(int64_t size, int64_t fill_value=-1) const; at::Tensor nonzero_static_symint(c10::SymInt size, int64_t fill_value=-1) const; ::std::vector\u003cat::Tensor\u003e nonzero_numpy() const; at::Tensor argwhere() const; at::Tensor gather(int64_t dim, const at::Tensor \u0026 index, bool sparse_grad=false) const; at::Tensor gather(at::Dimname dim, const at::Tensor \u0026 index, bool sparse_grad=false) const; at::Tensor addcmul(const at::Tensor \u0026 tensor1, const at::Tensor \u0026 tensor2, const at::Scalar \u0026 value=1) const; at::Tensor \u0026 addcmul_(const at::Tensor \u0026 tensor1, const at::Tensor \u0026 tensor2, const at::Scalar \u0026 value=1) const; at::Tensor addcdiv(const at::Tensor \u0026 tensor1, const at::Tensor \u0026 tensor2, const at::Scalar \u0026 value=1) const; at::Tensor \u0026 addcdiv_(const at::Tensor \u0026 tensor1, const at::Tensor \u0026 tensor2, const at::Scalar \u0026 value=1) const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e triangular_solve(const at::Tensor \u0026 A, bool upper=true, bool transpose=false, bool unitriangular=false) const; ::std::tuple\u003cat::Tensor,at::Tensor,at::Tensor\u003e svd(bool some=true, bool compute_uv=true) const; at::Tensor swapaxes(int64_t axis0, int64_t axis1) const; at::Tensor \u0026 swapaxes_(int64_t axis0, int64_t axis1) const; at::Tensor swapdims(int64_t dim0, int64_t dim1) const; at::Tensor \u0026 swapdims_(int64_t dim0, int64_t dim1) const; at::Tensor cholesky(bool upper=false) const; at::Tensor cholesky_solve(const at::Tensor \u0026 input2, bool upper=false) const; at::Tensor cholesky_inverse(bool upper=false) const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e qr(bool some=true) const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e geqrf() const; at::Tensor orgqr(const at::Tensor \u0026 input2) const; at::Tensor ormqr(const at::Tensor \u0026 input2, const at::Tensor \u0026 input3, bool left=true, bool transpose=false) const; at::Tensor lu_solve(const at::Tensor \u0026 LU_data, const at::Tensor \u0026 LU_pivots) const; at::Tensor multinomial(int64_t num_samples, bool replacement=false, ::std::optional\u003cat::Generator\u003e generator=::std::nullopt) const; at::Tensor multinomial_symint(c10::SymInt num_samples, bool replacement=false, ::std::optional\u003cat::Generator\u003e generator=::std::nullopt) const; at::Tensor \u0026 lgamma_() const; at::Tensor lgamma() const; at::Tensor digamma() const; at::Tensor polygamma(int64_t n) const; at::Tensor \u0026 polygamma_(int64_t n) const; at::Tensor erfinv() const; at::Tensor \u0026 erfinv_() const; at::Tensor i0() const; at::Tensor \u0026 i0_() const; at::Tensor sign() const; at::Tensor \u0026 sign_() const; at::Tensor signbit() const; at::Tensor dist(const at::Tensor \u0026 other, const at::Scalar \u0026 p=2) const; at::Tensor \u0026 atan2_(const at::Tensor \u0026 other) const; at::Tensor atan2(const at::Tensor \u0026 other) const; at::Tensor arctan2(const at::Tensor \u0026 other) const; at::Tensor \u0026 arctan2_(const at::Tensor \u0026 other) const; at::Tensor lerp(const at::Tensor \u0026 end, const at::Scalar \u0026 weight) const; at::Tensor lerp(const at::Tensor \u0026 end, const at::Tensor \u0026 weight) const; at::Tensor histc(int64_t bins=100, const at::Scalar \u0026 min=0, const at::Scalar \u0026 max=0) const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e histogram(const at::Tensor \u0026 bins, const ::std::optional\u003cat::Tensor\u003e \u0026 weight={}, bool density=false) const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e histogram(int64_t bins=100, ::std::optional\u003cat::ArrayRef\u003cdouble\u003e\u003e range=::std::nullopt, const ::std::optional\u003cat::Tensor\u003e \u0026 weight={}, bool density=false) const; at::Tensor fmod(const at::Scalar \u0026 other) const; at::Tensor \u0026 fmod_(const at::Scalar \u0026 other) const; at::Tensor fmod(const at::Tensor \u0026 other) const; at::Tensor \u0026 fmod_(const at::Tensor \u0026 other) const; at::Tensor hypot(const at::Tensor \u0026 other) const; at::Tensor \u0026 hypot_(const at::Tensor \u0026 other) const; at::Tensor igamma(const at::Tensor \u0026 other) const; at::Tensor \u0026 igamma_(const at::Tensor \u0026 other) const; at::Tensor igammac(const at::Tensor \u0026 other) const; at::Tensor \u0026 igammac_(const at::Tensor \u0026 other) const; at::Tensor nextafter(const at::Tensor \u0026 other) const; at::Tensor \u0026 nextafter_(const at::Tensor \u0026 other) const; at::Tensor remainder(const at::Scalar \u0026 other) const; at::Tensor \u0026 remainder_(const at::Scalar \u0026 other) const; at::Tensor remainder(const at::Tensor \u0026 other) const; at::Tensor \u0026 remainder_(const at::Tensor \u0026 other) const; at::Tensor min() const; at::Tensor fmin(const at::Tensor \u0026 other) const; at::Tensor max() const; at::Tensor fmax(const at::Tensor \u0026 other) const; at::Tensor maximum(const at::Tensor \u0026 other) const; at::Tensor max(const at::Tensor \u0026 other) const; at::Tensor minimum(const at::Tensor \u0026 other) const; at::Tensor min(const at::Tensor \u0026 other) const; at::Tensor quantile(const at::Tensor \u0026 q, ::std::optional\u003cint64_t\u003e dim=::std::nullopt, bool keepdim=false, c10::string_view interpolation=\"linear\") const; at::Tensor quantile(double q, ::std::optional\u003cint64_t\u003e dim=::std::nullopt, bool keepdim=false, c10::string_view interpolation=\"linear\") const; at::Tensor nanquantile(const at::Tensor \u0026 q, ::std::optional\u003cint64_t\u003e dim=::std::nullopt, bool keepdim=false, c10::string_view interpolation=\"linear\") const; at::Tensor nanquantile(double q, ::std::optional\u003cint64_t\u003e dim=::std::nullopt, bool keepdim=false, c10::string_view interpolation=\"linear\") const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e sort(int64_t dim=-1, bool descending=false) const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e sort(::std::optional\u003cbool\u003e stable, int64_t dim=-1, bool descending=false) const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e sort(at::Dimname dim, bool descending=false) const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e sort(::std::optional\u003cbool\u003e stable, at::Dimname dim, bool descending=false) const; at::Tensor msort() const; at::Tensor argsort(int64_t dim=-1, bool descending=false) const; at::Tensor argsort(bool stable, int64_t dim=-1, bool descending=false) const; at::Tensor argsort(at::Dimname dim, bool descending=false) const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e topk(int64_t k, int64_t dim=-1, bool largest=true, bool sorted=true) const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e topk_symint(c10::SymInt k, int64_t dim=-1, bool largest=true, bool sorted=true) const; at::Tensor all() const; at::Tensor any() const; at::Tensor renorm(const at::Scalar \u0026 p, int64_t dim, const at::Scalar \u0026 maxnorm) const; at::Tensor \u0026 renorm_(const at::Scalar \u0026 p, int64_t dim, const at::Scalar \u0026 maxnorm) const; at::Tensor unfold(int64_t dimension, int64_t size, int64_t step) const; bool equal(const at::Tensor \u0026 other) const; at::Tensor pow(const at::Tensor \u0026 exponent) const; at::Tensor pow(const at::Scalar \u0026 exponent) const; at::Tensor \u0026 pow_(const at::Scalar \u0026 exponent) const; at::Tensor \u0026 pow_(const at::Tensor \u0026 exponent) const; at::Tensor float_power(const at::Tensor \u0026 exponent) const; at::Tensor float_power(const at::Scalar \u0026 exponent) const; at::Tensor \u0026 float_power_(const at::Scalar \u0026 exponent) const; at::Tensor \u0026 float_power_(const at::Tensor \u0026 exponent) const; at::Tensor \u0026 normal_(double mean=0, double std=1, ::std::optional\u003cat::Generator\u003e generator=::std::nullopt) const; at::Tensor alias() const; at::Tensor isfinite() const; at::Tensor isinf() const; void record_stream(at::Stream s) const; at::Tensor isposinf() const; at::Tensor isneginf() const; at::Tensor det() const; ::std::tuple\u003cat::Tensor,at::Tensor\u003e slogdet() const; at::Tensor logdet() const; at::Tensor inverse() const; at::Tensor inner(const at::Tensor \u0026 other) const; at::Tensor outer(const at::Tensor \u0026 vec2) const; at::Tensor ger(const at::Tensor \u0026 vec2) const; at::Tensor to_padded_tensor(double padding, at::OptionalIntArrayRef output_size=::std::nullopt) const; at::Tensor to_padded_tensor_symint(double padding, at::OptionalSymIntArrayRef output_size=::std::nullopt) const; // Special C++ only overloads for std()-like functions (See gh-40287) // These are needed because int -\u003e bool conversion takes precedence over int -\u003e IntArrayRef // So, for example std(0) would select the std(unbiased=False) overload Tensor var(int dim) const { return var(IntArrayRef{dim}); } Tensor std(int dim) const { return std(IntArrayRef{dim}); } // We changed .dtype() to return a TypeMeta in #12766. Ideally, we want the // at::kDouble and its friends to be TypeMeta\u0027s, but that hasn\u0027t happened yet. // Before that change, we make this method to maintain BC for C++ usage like // `x.to(y.dtype)`. // TODO: remove following two after at::kDouble and its friends are TypeMeta\u0027s. inline Tensor to(caffe2::TypeMeta type_meta, bool non_blocking=false, bool copy=false) const { return this-\u003eto(/*scalar_type=*/typeMetaToScalarType(type_meta), non_blocking, copy); } inline Tensor to(Device device, caffe2::TypeMeta type_meta, bool non_blocking=false, bool copy=false) const { return this-\u003eto(device, /*scalar_type=*/typeMetaToScalarType(type_meta), non_blocking, copy); } template \u003ctypename F, typename... Args\u003e decltype(auto) m(F func, Args\u0026\u0026... params) const { return func(*this, std::forward\u003cArgs\u003e(params)...); } at::Tensor tensor_data() const { return TensorBase::tensor_data(); } at::Tensor variable_data() const { return TensorBase::variable_data(); } // Hooks //~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ template \u003ctypename T\u003e using hook_return_void_t = std::enable_if_t\u003cstd::is_void\u003ctypename std::invoke_result_t\u003cT\u0026, Tensor\u003e\u003e::value, unsigned\u003e; template \u003ctypename T\u003e using hook_return_var_t = std::enable_if_t\u003cstd::is_same_v\u003ctypename std::invoke_result_t\u003cT\u0026, Tensor\u003e, Tensor\u003e, unsigned\u003e; template \u003ctypename T\u003e hook_return_void_t\u003cT\u003e register_hook(T\u0026\u0026 hook) const; template \u003ctypename T\u003e hook_return_var_t\u003cT\u003e register_hook(T\u0026\u0026 hook) const; // Variable methods //~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Tensor data() const { return TensorBase::data(); } void _backward(TensorList inputs, const std::optional\u003cTensor\u003e\u0026 gradient, std::optional\u003cbool\u003e keep_graph, bool create_graph) const; const Tensor\u0026 requires_grad_(bool _requires_grad=true) const { TensorBase::requires_grad_(_requires_grad); return *this; } }; namespace detail { // Helper creator for Tensor class which doesn\u0027t requires the users to pass // in an intrusive_ptr instead it just converts the argument passed to // requested intrusive_ptr type. template \u003ctypename T, typename... Args\u003e Tensor make_tensor(Args\u0026\u0026... args) { return Tensor(c10::make_intrusive\u003cT\u003e(std::forward\u003cArgs\u003e(args)...)); } } // namespace detail } // namespace at namespace at { // aten::_backward(Tensor self, Tensor[] inputs, Tensor? gradient=None, bool? retain_graph=None, bool create_graph=False) -\u003e () inline void Tensor::__dispatch__backward(at::TensorList inputs, const ::std::optional\u003cat::Tensor\u003e \u0026 gradient, ::std::optional\u003cbool\u003e retain_graph, bool create_graph) const { return at::_ops::_backward::call(const_cast\u003cTensor\u0026\u003e(*this), inputs, gradient, retain_graph, create_graph); } // aten::set_data(Tensor(a!) self, Tensor new_data) -\u003e () inline void Tensor::__dispatch_set_data(const at::Tensor \u0026 new_data) const { return at::_ops::set_data::call(const_cast\u003cTensor\u0026\u003e(*this), new_data); } // aten::data(Tensor self) -\u003e Tensor inline at::Tensor Tensor::__dispatch_data() const { return at::_ops::data::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::is_leaf(Tensor self) -\u003e bool inline bool Tensor::__dispatch_is_leaf() const { return at::_ops::is_leaf::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::output_nr(Tensor self) -\u003e int inline int64_t Tensor::__dispatch_output_nr() const { return at::_ops::output_nr::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::_version(Tensor self) -\u003e int inline int64_t Tensor::__dispatch__version() const { return at::_ops::_version::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::requires_grad_(Tensor(a!) self, bool requires_grad=True) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::__dispatch_requires_grad_(bool requires_grad) const { return at::_ops::requires_grad_::call(const_cast\u003cTensor\u0026\u003e(*this), requires_grad); } // aten::retain_grad(Tensor(a!) self) -\u003e () inline void Tensor::__dispatch_retain_grad() const { return at::_ops::retain_grad::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::retains_grad(Tensor self) -\u003e bool inline bool Tensor::__dispatch_retains_grad() const { return at::_ops::retains_grad::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::_fw_primal(Tensor(a) self, int level) -\u003e Tensor(a) inline at::Tensor Tensor::_fw_primal(int64_t level) const { return at::_ops::_fw_primal::call(const_cast\u003cTensor\u0026\u003e(*this), level); } // aten::rename_(Tensor(a!) self, Dimname[]? names) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::rename_(::std::optional\u003cat::DimnameList\u003e names) const { return at::_ops::rename_::call(const_cast\u003cTensor\u0026\u003e(*this), names); } // aten::rename(Tensor(a) self, Dimname[]? names) -\u003e Tensor(a) inline at::Tensor Tensor::rename(::std::optional\u003cat::DimnameList\u003e names) const { return at::_ops::rename::call(const_cast\u003cTensor\u0026\u003e(*this), names); } // aten::align_to(Tensor(a) self, Dimname[] names) -\u003e Tensor(a) inline at::Tensor Tensor::align_to(at::DimnameList names) const { return at::_ops::align_to::call(const_cast\u003cTensor\u0026\u003e(*this), names); } // aten::align_to.ellipsis_idx(Tensor(a) self, Dimname[] order, int ellipsis_idx) -\u003e Tensor(a) inline at::Tensor Tensor::align_to(at::DimnameList order, int64_t ellipsis_idx) const { return at::_ops::align_to_ellipsis_idx::call(const_cast\u003cTensor\u0026\u003e(*this), order, ellipsis_idx); } // aten::align_as(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::align_as(const at::Tensor \u0026 other) const { return at::_ops::align_as::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::refine_names(Tensor(a) self, Dimname[] names) -\u003e Tensor(a) inline at::Tensor Tensor::refine_names(at::DimnameList names) const { return at::_ops::refine_names::call(const_cast\u003cTensor\u0026\u003e(*this), names); } // aten::abs(Tensor self) -\u003e Tensor inline at::Tensor Tensor::abs() const { return at::_ops::abs::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::abs_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::abs_() const { return at::_ops::abs_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::absolute(Tensor self) -\u003e Tensor inline at::Tensor Tensor::absolute() const { return at::_ops::absolute::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::absolute_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::absolute_() const { return at::_ops::absolute_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::angle(Tensor self) -\u003e Tensor inline at::Tensor Tensor::angle() const { return at::_ops::angle::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::sgn(Tensor self) -\u003e Tensor inline at::Tensor Tensor::sgn() const { return at::_ops::sgn::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::sgn_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::sgn_() const { return at::_ops::sgn_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::chalf(Tensor self, *, MemoryFormat? memory_format=None) -\u003e Tensor inline at::Tensor Tensor::chalf(::std::optional\u003cat::MemoryFormat\u003e memory_format) const { return at::_ops::chalf::call(const_cast\u003cTensor\u0026\u003e(*this), memory_format); } // aten::_conj(Tensor(a) self) -\u003e Tensor(a) inline at::Tensor Tensor::_conj() const { return at::_ops::_conj::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::conj(Tensor(a) self) -\u003e Tensor(a) inline at::Tensor Tensor::__dispatch_conj() const { return at::_ops::conj::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::_conj_physical(Tensor self) -\u003e Tensor inline at::Tensor Tensor::_conj_physical() const { return at::_ops::_conj_physical::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::conj_physical(Tensor self) -\u003e Tensor inline at::Tensor Tensor::conj_physical() const { return at::_ops::conj_physical::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::conj_physical_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::conj_physical_() const { return at::_ops::conj_physical_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::resolve_conj(Tensor(a) self) -\u003e Tensor(a) inline at::Tensor Tensor::resolve_conj() const { return at::_ops::resolve_conj::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::resolve_neg(Tensor(a) self) -\u003e Tensor(a) inline at::Tensor Tensor::resolve_neg() const { return at::_ops::resolve_neg::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::_neg_view(Tensor(a) self) -\u003e Tensor(a) inline at::Tensor Tensor::_neg_view() const { return at::_ops::_neg_view::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::acos(Tensor self) -\u003e Tensor inline at::Tensor Tensor::acos() const { return at::_ops::acos::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::acos_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::acos_() const { return at::_ops::acos_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::arccos(Tensor self) -\u003e Tensor inline at::Tensor Tensor::arccos() const { return at::_ops::arccos::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::arccos_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::arccos_() const { return at::_ops::arccos_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -\u003e Tensor inline at::Tensor Tensor::add(const at::Tensor \u0026 other, const at::Scalar \u0026 alpha) const { return at::_ops::add_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other, alpha); } // aten::add_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::add_(const at::Tensor \u0026 other, const at::Scalar \u0026 alpha) const { return at::_ops::add__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other, alpha); } // aten::add.Scalar(Tensor self, Scalar other, Scalar alpha=1) -\u003e Tensor inline at::Tensor Tensor::add(const at::Scalar \u0026 other, const at::Scalar \u0026 alpha) const { return at::_ops::add_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other, alpha); } // aten::add_.Scalar(Tensor(a!) self, Scalar other, Scalar alpha=1) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::add_(const at::Scalar \u0026 other, const at::Scalar \u0026 alpha) const { return at::_ops::add__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other, alpha); } // aten::addmv(Tensor self, Tensor mat, Tensor vec, *, Scalar beta=1, Scalar alpha=1) -\u003e Tensor inline at::Tensor Tensor::addmv(const at::Tensor \u0026 mat, const at::Tensor \u0026 vec, const at::Scalar \u0026 beta, const at::Scalar \u0026 alpha) const { return at::_ops::addmv::call(const_cast\u003cTensor\u0026\u003e(*this), mat, vec, beta, alpha); } // aten::addmv_(Tensor(a!) self, Tensor mat, Tensor vec, *, Scalar beta=1, Scalar alpha=1) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::addmv_(const at::Tensor \u0026 mat, const at::Tensor \u0026 vec, const at::Scalar \u0026 beta, const at::Scalar \u0026 alpha) const { return at::_ops::addmv_::call(const_cast\u003cTensor\u0026\u003e(*this), mat, vec, beta, alpha); } // aten::addr(Tensor self, Tensor vec1, Tensor vec2, *, Scalar beta=1, Scalar alpha=1) -\u003e Tensor inline at::Tensor Tensor::addr(const at::Tensor \u0026 vec1, const at::Tensor \u0026 vec2, const at::Scalar \u0026 beta, const at::Scalar \u0026 alpha) const { return at::_ops::addr::call(const_cast\u003cTensor\u0026\u003e(*this), vec1, vec2, beta, alpha); } // aten::addr_(Tensor(a!) self, Tensor vec1, Tensor vec2, *, Scalar beta=1, Scalar alpha=1) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::addr_(const at::Tensor \u0026 vec1, const at::Tensor \u0026 vec2, const at::Scalar \u0026 beta, const at::Scalar \u0026 alpha) const { return at::_ops::addr_::call(const_cast\u003cTensor\u0026\u003e(*this), vec1, vec2, beta, alpha); } // aten::_is_all_true(Tensor self) -\u003e Tensor inline at::Tensor Tensor::_is_all_true() const { return at::_ops::_is_all_true::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::_is_any_true(Tensor self) -\u003e Tensor inline at::Tensor Tensor::_is_any_true() const { return at::_ops::_is_any_true::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::all.dim(Tensor self, int dim, bool keepdim=False) -\u003e Tensor inline at::Tensor Tensor::all(int64_t dim, bool keepdim) const { return at::_ops::all_dim::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim); } // aten::all.dims(Tensor self, int[]? dim=None, bool keepdim=False) -\u003e Tensor inline at::Tensor Tensor::all(at::OptionalIntArrayRef dim, bool keepdim) const { return at::_ops::all_dims::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim); } // aten::all.dimname(Tensor self, Dimname dim, bool keepdim=False) -\u003e Tensor inline at::Tensor Tensor::all(at::Dimname dim, bool keepdim) const { return at::_ops::all_dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim); } // aten::allclose(Tensor self, Tensor other, float rtol=1e-05, float atol=1e-08, bool equal_nan=False) -\u003e bool inline bool Tensor::allclose(const at::Tensor \u0026 other, double rtol, double atol, bool equal_nan) const { return at::_ops::allclose::call(const_cast\u003cTensor\u0026\u003e(*this), other, rtol, atol, equal_nan); } // aten::any.dim(Tensor self, int dim, bool keepdim=False) -\u003e Tensor inline at::Tensor Tensor::any(int64_t dim, bool keepdim) const { return at::_ops::any_dim::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim); } // aten::any.dims(Tensor self, int[]? dim=None, bool keepdim=False) -\u003e Tensor inline at::Tensor Tensor::any(at::OptionalIntArrayRef dim, bool keepdim) const { return at::_ops::any_dims::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim); } // aten::any.dimname(Tensor self, Dimname dim, bool keepdim=False) -\u003e Tensor inline at::Tensor Tensor::any(at::Dimname dim, bool keepdim) const { return at::_ops::any_dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim); } // aten::argmax(Tensor self, int? dim=None, bool keepdim=False) -\u003e Tensor inline at::Tensor Tensor::argmax(::std::optional\u003cint64_t\u003e dim, bool keepdim) const { return at::_ops::argmax::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim); } // aten::argmin(Tensor self, int? dim=None, bool keepdim=False) -\u003e Tensor inline at::Tensor Tensor::argmin(::std::optional\u003cint64_t\u003e dim, bool keepdim) const { return at::_ops::argmin::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim); } // aten::acosh(Tensor self) -\u003e Tensor inline at::Tensor Tensor::acosh() const { return at::_ops::acosh::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::acosh_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::acosh_() const { return at::_ops::acosh_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::arccosh(Tensor self) -\u003e Tensor inline at::Tensor Tensor::arccosh() const { return at::_ops::arccosh::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::arccosh_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::arccosh_() const { return at::_ops::arccosh_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::asinh(Tensor self) -\u003e Tensor inline at::Tensor Tensor::asinh() const { return at::_ops::asinh::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::asinh_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::asinh_() const { return at::_ops::asinh_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::arcsinh(Tensor self) -\u003e Tensor inline at::Tensor Tensor::arcsinh() const { return at::_ops::arcsinh::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::arcsinh_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::arcsinh_() const { return at::_ops::arcsinh_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::atanh(Tensor self) -\u003e Tensor inline at::Tensor Tensor::atanh() const { return at::_ops::atanh::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::atanh_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::atanh_() const { return at::_ops::atanh_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::arctanh(Tensor self) -\u003e Tensor inline at::Tensor Tensor::arctanh() const { return at::_ops::arctanh::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::arctanh_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::arctanh_() const { return at::_ops::arctanh_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -\u003e Tensor(a) inline at::Tensor Tensor::as_strided(at::IntArrayRef size, at::IntArrayRef stride, ::std::optional\u003cint64_t\u003e storage_offset) const { return at::_ops::as_strided::call(const_cast\u003cTensor\u0026\u003e(*this), c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride), storage_offset.has_value() ? ::std::make_optional(c10::SymInt(*storage_offset)) : ::std::nullopt); } // aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -\u003e Tensor(a) inline at::Tensor Tensor::as_strided_symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride, ::std::optional\u003cc10::SymInt\u003e storage_offset) const { return at::_ops::as_strided::call(const_cast\u003cTensor\u0026\u003e(*this), size, stride, storage_offset); } // aten::as_strided_(Tensor(a!) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -\u003e Tensor(a!) inline const at::Tensor \u0026 Tensor::as_strided_(at::IntArrayRef size, at::IntArrayRef stride, ::std::optional\u003cint64_t\u003e storage_offset) const { return at::_ops::as_strided_::call(const_cast\u003cTensor\u0026\u003e(*this), c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride), storage_offset.has_value() ? ::std::make_optional(c10::SymInt(*storage_offset)) : ::std::nullopt); } // aten::as_strided_(Tensor(a!) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -\u003e Tensor(a!) inline const at::Tensor \u0026 Tensor::as_strided__symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride, ::std::optional\u003cc10::SymInt\u003e storage_offset) const { return at::_ops::as_strided_::call(const_cast\u003cTensor\u0026\u003e(*this), size, stride, storage_offset); } // aten::asin(Tensor self) -\u003e Tensor inline at::Tensor Tensor::asin() const { return at::_ops::asin::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::asin_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::asin_() const { return at::_ops::asin_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::arcsin(Tensor self) -\u003e Tensor inline at::Tensor Tensor::arcsin() const { return at::_ops::arcsin::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::arcsin_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::arcsin_() const { return at::_ops::arcsin_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::atan(Tensor self) -\u003e Tensor inline at::Tensor Tensor::atan() const { return at::_ops::atan::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::atan_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::atan_() const { return at::_ops::atan_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::arctan(Tensor self) -\u003e Tensor inline at::Tensor Tensor::arctan() const { return at::_ops::arctan::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::arctan_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::arctan_() const { return at::_ops::arctan_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -\u003e Tensor inline at::Tensor Tensor::baddbmm(const at::Tensor \u0026 batch1, const at::Tensor \u0026 batch2, const at::Scalar \u0026 beta, const at::Scalar \u0026 alpha) const { return at::_ops::baddbmm::call(const_cast\u003cTensor\u0026\u003e(*this), batch1, batch2, beta, alpha); } // aten::baddbmm_(Tensor(a!) self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::baddbmm_(const at::Tensor \u0026 batch1, const at::Tensor \u0026 batch2, const at::Scalar \u0026 beta, const at::Scalar \u0026 alpha) const { return at::_ops::baddbmm_::call(const_cast\u003cTensor\u0026\u003e(*this), batch1, batch2, beta, alpha); } // aten::bernoulli(Tensor self, *, Generator? generator=None) -\u003e Tensor inline at::Tensor Tensor::bernoulli(::std::optional\u003cat::Generator\u003e generator) const { return at::_ops::bernoulli::call(const_cast\u003cTensor\u0026\u003e(*this), generator); } // aten::bernoulli_.Tensor(Tensor(a!) self, Tensor p, *, Generator? generator=None) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::bernoulli_(const at::Tensor \u0026 p, ::std::optional\u003cat::Generator\u003e generator) const { return at::_ops::bernoulli__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), p, generator); } // aten::bernoulli_.float(Tensor(a!) self, float p=0.5, *, Generator? generator=None) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::bernoulli_(double p, ::std::optional\u003cat::Generator\u003e generator) const { return at::_ops::bernoulli__float::call(const_cast\u003cTensor\u0026\u003e(*this), p, generator); } // aten::bernoulli.p(Tensor self, float p, *, Generator? generator=None) -\u003e Tensor inline at::Tensor Tensor::bernoulli(double p, ::std::optional\u003cat::Generator\u003e generator) const { return at::_ops::bernoulli_p::call(const_cast\u003cTensor\u0026\u003e(*this), p, generator); } // aten::bincount(Tensor self, Tensor? weights=None, SymInt minlength=0) -\u003e Tensor inline at::Tensor Tensor::bincount(const ::std::optional\u003cat::Tensor\u003e \u0026 weights, int64_t minlength) const { return at::_ops::bincount::call(const_cast\u003cTensor\u0026\u003e(*this), weights, minlength); } // aten::bincount(Tensor self, Tensor? weights=None, SymInt minlength=0) -\u003e Tensor inline at::Tensor Tensor::bincount_symint(const ::std::optional\u003cat::Tensor\u003e \u0026 weights, c10::SymInt minlength) const { return at::_ops::bincount::call(const_cast\u003cTensor\u0026\u003e(*this), weights, minlength); } // aten::bitwise_not(Tensor self) -\u003e Tensor inline at::Tensor Tensor::bitwise_not() const { return at::_ops::bitwise_not::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::bitwise_not_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::bitwise_not_() const { return at::_ops::bitwise_not_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::copysign.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::copysign(const at::Tensor \u0026 other) const { return at::_ops::copysign_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::copysign_.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::copysign_(const at::Tensor \u0026 other) const { return at::_ops::copysign__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::copysign.Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::copysign(const at::Scalar \u0026 other) const { return at::_ops::copysign_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::copysign_.Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::copysign_(const at::Scalar \u0026 other) const { return at::_ops::copysign__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::_lazy_clone(Tensor self) -\u003e Tensor inline at::Tensor Tensor::_lazy_clone() const { return at::_ops::_lazy_clone::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::logical_not(Tensor self) -\u003e Tensor inline at::Tensor Tensor::logical_not() const { return at::_ops::logical_not::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::logical_not_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::logical_not_() const { return at::_ops::logical_not_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::logical_xor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::logical_xor(const at::Tensor \u0026 other) const { return at::_ops::logical_xor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::logical_xor_(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::logical_xor_(const at::Tensor \u0026 other) const { return at::_ops::logical_xor_::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::logical_and(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::logical_and(const at::Tensor \u0026 other) const { return at::_ops::logical_and::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::logical_and_(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::logical_and_(const at::Tensor \u0026 other) const { return at::_ops::logical_and_::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::logical_or(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::logical_or(const at::Tensor \u0026 other) const { return at::_ops::logical_or::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::logical_or_(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::logical_or_(const at::Tensor \u0026 other) const { return at::_ops::logical_or_::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::bmm(Tensor self, Tensor mat2) -\u003e Tensor inline at::Tensor Tensor::bmm(const at::Tensor \u0026 mat2) const { return at::_ops::bmm::call(const_cast\u003cTensor\u0026\u003e(*this), mat2); } // aten::broadcast_to(Tensor(a) self, SymInt[] size) -\u003e Tensor(a) inline at::Tensor Tensor::broadcast_to(at::IntArrayRef size) const { return at::_ops::broadcast_to::call(const_cast\u003cTensor\u0026\u003e(*this), c10::fromIntArrayRefSlow(size)); } // aten::broadcast_to(Tensor(a) self, SymInt[] size) -\u003e Tensor(a) inline at::Tensor Tensor::broadcast_to_symint(c10::SymIntArrayRef size) const { return at::_ops::broadcast_to::call(const_cast\u003cTensor\u0026\u003e(*this), size); } // aten::ceil(Tensor self) -\u003e Tensor inline at::Tensor Tensor::ceil() const { return at::_ops::ceil::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::ceil_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::ceil_() const { return at::_ops::ceil_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::unsafe_chunk(Tensor self, int chunks, int dim=0) -\u003e Tensor[] inline ::std::vector\u003cat::Tensor\u003e Tensor::unsafe_chunk(int64_t chunks, int64_t dim) const { return at::_ops::unsafe_chunk::call(const_cast\u003cTensor\u0026\u003e(*this), chunks, dim); } // aten::chunk(Tensor(a -\u003e *) self, int chunks, int dim=0) -\u003e Tensor(a)[] inline ::std::vector\u003cat::Tensor\u003e Tensor::chunk(int64_t chunks, int64_t dim) const { return at::_ops::chunk::call(const_cast\u003cTensor\u0026\u003e(*this), chunks, dim); } // aten::tensor_split.sections(Tensor(a -\u003e *) self, SymInt sections, int dim=0) -\u003e Tensor(a)[] inline ::std::vector\u003cat::Tensor\u003e Tensor::tensor_split(int64_t sections, int64_t dim) const { return at::_ops::tensor_split_sections::call(const_cast\u003cTensor\u0026\u003e(*this), sections, dim); } // aten::tensor_split.sections(Tensor(a -\u003e *) self, SymInt sections, int dim=0) -\u003e Tensor(a)[] inline ::std::vector\u003cat::Tensor\u003e Tensor::tensor_split_symint(c10::SymInt sections, int64_t dim) const { return at::_ops::tensor_split_sections::call(const_cast\u003cTensor\u0026\u003e(*this), sections, dim); } // aten::tensor_split.indices(Tensor(a -\u003e *) self, SymInt[] indices, int dim=0) -\u003e Tensor(a)[] inline ::std::vector\u003cat::Tensor\u003e Tensor::tensor_split(at::IntArrayRef indices, int64_t dim) const { return at::_ops::tensor_split_indices::call(const_cast\u003cTensor\u0026\u003e(*this), c10::fromIntArrayRefSlow(indices), dim); } // aten::tensor_split.indices(Tensor(a -\u003e *) self, SymInt[] indices, int dim=0) -\u003e Tensor(a)[] inline ::std::vector\u003cat::Tensor\u003e Tensor::tensor_split_symint(c10::SymIntArrayRef indices, int64_t dim) const { return at::_ops::tensor_split_indices::call(const_cast\u003cTensor\u0026\u003e(*this), indices, dim); } // aten::tensor_split.tensor_indices_or_sections(Tensor(a -\u003e *) self, Tensor tensor_indices_or_sections, int dim=0) -\u003e Tensor(a)[] inline ::std::vector\u003cat::Tensor\u003e Tensor::tensor_split(const at::Tensor \u0026 tensor_indices_or_sections, int64_t dim) const { return at::_ops::tensor_split_tensor_indices_or_sections::call(const_cast\u003cTensor\u0026\u003e(*this), tensor_indices_or_sections, dim); } // aten::clamp(Tensor self, Scalar? min=None, Scalar? max=None) -\u003e Tensor inline at::Tensor Tensor::clamp(const ::std::optional\u003cat::Scalar\u003e \u0026 min, const ::std::optional\u003cat::Scalar\u003e \u0026 max) const { return at::_ops::clamp::call(const_cast\u003cTensor\u0026\u003e(*this), min, max); } // aten::clamp.Tensor(Tensor self, Tensor? min=None, Tensor? max=None) -\u003e Tensor inline at::Tensor Tensor::clamp(const ::std::optional\u003cat::Tensor\u003e \u0026 min, const ::std::optional\u003cat::Tensor\u003e \u0026 max) const { return at::_ops::clamp_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), min, max); } // aten::clamp_(Tensor(a!) self, Scalar? min=None, Scalar? max=None) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::clamp_(const ::std::optional\u003cat::Scalar\u003e \u0026 min, const ::std::optional\u003cat::Scalar\u003e \u0026 max) const { return at::_ops::clamp_::call(const_cast\u003cTensor\u0026\u003e(*this), min, max); } // aten::clamp_.Tensor(Tensor(a!) self, Tensor? min=None, Tensor? max=None) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::clamp_(const ::std::optional\u003cat::Tensor\u003e \u0026 min, const ::std::optional\u003cat::Tensor\u003e \u0026 max) const { return at::_ops::clamp__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), min, max); } // aten::clamp_max(Tensor self, Scalar max) -\u003e Tensor inline at::Tensor Tensor::clamp_max(const at::Scalar \u0026 max) const { return at::_ops::clamp_max::call(const_cast\u003cTensor\u0026\u003e(*this), max); } // aten::clamp_max.Tensor(Tensor self, Tensor max) -\u003e Tensor inline at::Tensor Tensor::clamp_max(const at::Tensor \u0026 max) const { return at::_ops::clamp_max_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), max); } // aten::clamp_max_(Tensor(a!) self, Scalar max) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::clamp_max_(const at::Scalar \u0026 max) const { return at::_ops::clamp_max_::call(const_cast\u003cTensor\u0026\u003e(*this), max); } // aten::clamp_max_.Tensor(Tensor(a!) self, Tensor max) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::clamp_max_(const at::Tensor \u0026 max) const { return at::_ops::clamp_max__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), max); } // aten::clamp_min(Tensor self, Scalar min) -\u003e Tensor inline at::Tensor Tensor::clamp_min(const at::Scalar \u0026 min) const { return at::_ops::clamp_min::call(const_cast\u003cTensor\u0026\u003e(*this), min); } // aten::clamp_min.Tensor(Tensor self, Tensor min) -\u003e Tensor inline at::Tensor Tensor::clamp_min(const at::Tensor \u0026 min) const { return at::_ops::clamp_min_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), min); } // aten::clamp_min_(Tensor(a!) self, Scalar min) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::clamp_min_(const at::Scalar \u0026 min) const { return at::_ops::clamp_min_::call(const_cast\u003cTensor\u0026\u003e(*this), min); } // aten::clamp_min_.Tensor(Tensor(a!) self, Tensor min) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::clamp_min_(const at::Tensor \u0026 min) const { return at::_ops::clamp_min__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), min); } // aten::clip(Tensor self, Scalar? min=None, Scalar? max=None) -\u003e Tensor inline at::Tensor Tensor::clip(const ::std::optional\u003cat::Scalar\u003e \u0026 min, const ::std::optional\u003cat::Scalar\u003e \u0026 max) const { return at::_ops::clip::call(const_cast\u003cTensor\u0026\u003e(*this), min, max); } // aten::clip.Tensor(Tensor self, Tensor? min=None, Tensor? max=None) -\u003e Tensor inline at::Tensor Tensor::clip(const ::std::optional\u003cat::Tensor\u003e \u0026 min, const ::std::optional\u003cat::Tensor\u003e \u0026 max) const { return at::_ops::clip_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), min, max); } // aten::clip_(Tensor(a!) self, Scalar? min=None, Scalar? max=None) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::clip_(const ::std::optional\u003cat::Scalar\u003e \u0026 min, const ::std::optional\u003cat::Scalar\u003e \u0026 max) const { return at::_ops::clip_::call(const_cast\u003cTensor\u0026\u003e(*this), min, max); } // aten::clip_.Tensor(Tensor(a!) self, Tensor? min=None, Tensor? max=None) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::clip_(const ::std::optional\u003cat::Tensor\u003e \u0026 min, const ::std::optional\u003cat::Tensor\u003e \u0026 max) const { return at::_ops::clip__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), min, max); } // aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=contiguous_format) -\u003e Tensor(a) inline at::Tensor Tensor::__dispatch_contiguous(at::MemoryFormat memory_format) const { return at::_ops::contiguous::call(const_cast\u003cTensor\u0026\u003e(*this), memory_format); } // aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::copy_(const at::Tensor \u0026 src, bool non_blocking) const { return at::_ops::copy_::call(const_cast\u003cTensor\u0026\u003e(*this), src, non_blocking); } // aten::cos(Tensor self) -\u003e Tensor inline at::Tensor Tensor::cos() const { return at::_ops::cos::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::cos_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::cos_() const { return at::_ops::cos_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::cosh(Tensor self) -\u003e Tensor inline at::Tensor Tensor::cosh() const { return at::_ops::cosh::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::cosh_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::cosh_() const { return at::_ops::cosh_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::count_nonzero.dim_IntList(Tensor self, int[] dim) -\u003e Tensor inline at::Tensor Tensor::count_nonzero(at::IntArrayRef dim) const { return at::_ops::count_nonzero_dim_IntList::call(const_cast\u003cTensor\u0026\u003e(*this), dim); } // aten::count_nonzero(Tensor self, int? dim=None) -\u003e Tensor inline at::Tensor Tensor::count_nonzero(::std::optional\u003cint64_t\u003e dim) const { return at::_ops::count_nonzero::call(const_cast\u003cTensor\u0026\u003e(*this), dim); } // aten::cov(Tensor self, *, int correction=1, Tensor? fweights=None, Tensor? aweights=None) -\u003e Tensor inline at::Tensor Tensor::cov(int64_t correction, const ::std::optional\u003cat::Tensor\u003e \u0026 fweights, const ::std::optional\u003cat::Tensor\u003e \u0026 aweights) const { return at::_ops::cov::call(const_cast\u003cTensor\u0026\u003e(*this), correction, fweights, aweights); } // aten::corrcoef(Tensor self) -\u003e Tensor inline at::Tensor Tensor::corrcoef() const { return at::_ops::corrcoef::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::cummax(Tensor self, int dim) -\u003e (Tensor values, Tensor indices) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::cummax(int64_t dim) const { return at::_ops::cummax::call(const_cast\u003cTensor\u0026\u003e(*this), dim); } // aten::cummax.dimname(Tensor self, Dimname dim) -\u003e (Tensor values, Tensor indices) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::cummax(at::Dimname dim) const { return at::_ops::cummax_dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim); } // aten::cummin(Tensor self, int dim) -\u003e (Tensor values, Tensor indices) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::cummin(int64_t dim) const { return at::_ops::cummin::call(const_cast\u003cTensor\u0026\u003e(*this), dim); } // aten::cummin.dimname(Tensor self, Dimname dim) -\u003e (Tensor values, Tensor indices) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::cummin(at::Dimname dim) const { return at::_ops::cummin_dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim); } // aten::cumprod(Tensor self, int dim, *, ScalarType? dtype=None) -\u003e Tensor inline at::Tensor Tensor::cumprod(int64_t dim, ::std::optional\u003cat::ScalarType\u003e dtype) const { return at::_ops::cumprod::call(const_cast\u003cTensor\u0026\u003e(*this), dim, dtype); } // aten::cumprod_(Tensor(a!) self, int dim, *, ScalarType? dtype=None) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::cumprod_(int64_t dim, ::std::optional\u003cat::ScalarType\u003e dtype) const { return at::_ops::cumprod_::call(const_cast\u003cTensor\u0026\u003e(*this), dim, dtype); } // aten::cumprod.dimname(Tensor self, Dimname dim, *, ScalarType? dtype=None) -\u003e Tensor inline at::Tensor Tensor::cumprod(at::Dimname dim, ::std::optional\u003cat::ScalarType\u003e dtype) const { return at::_ops::cumprod_dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim, dtype); } // aten::cumprod_.dimname(Tensor(a!) self, Dimname dim, *, ScalarType? dtype=None) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::cumprod_(at::Dimname dim, ::std::optional\u003cat::ScalarType\u003e dtype) const { return at::_ops::cumprod__dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim, dtype); } // aten::cumsum(Tensor self, int dim, *, ScalarType? dtype=None) -\u003e Tensor inline at::Tensor Tensor::cumsum(int64_t dim, ::std::optional\u003cat::ScalarType\u003e dtype) const { return at::_ops::cumsum::call(const_cast\u003cTensor\u0026\u003e(*this), dim, dtype); } // aten::cumsum_(Tensor(a!) self, int dim, *, ScalarType? dtype=None) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::cumsum_(int64_t dim, ::std::optional\u003cat::ScalarType\u003e dtype) const { return at::_ops::cumsum_::call(const_cast\u003cTensor\u0026\u003e(*this), dim, dtype); } // aten::cumsum.dimname(Tensor self, Dimname dim, *, ScalarType? dtype=None) -\u003e Tensor inline at::Tensor Tensor::cumsum(at::Dimname dim, ::std::optional\u003cat::ScalarType\u003e dtype) const { return at::_ops::cumsum_dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim, dtype); } // aten::cumsum_.dimname(Tensor(a!) self, Dimname dim, *, ScalarType? dtype=None) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::cumsum_(at::Dimname dim, ::std::optional\u003cat::ScalarType\u003e dtype) const { return at::_ops::cumsum__dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim, dtype); } // aten::diag_embed(Tensor self, int offset=0, int dim1=-2, int dim2=-1) -\u003e Tensor inline at::Tensor Tensor::diag_embed(int64_t offset, int64_t dim1, int64_t dim2) const { return at::_ops::diag_embed::call(const_cast\u003cTensor\u0026\u003e(*this), offset, dim1, dim2); } // aten::diagflat(Tensor self, int offset=0) -\u003e Tensor inline at::Tensor Tensor::diagflat(int64_t offset) const { return at::_ops::diagflat::call(const_cast\u003cTensor\u0026\u003e(*this), offset); } // aten::diagonal(Tensor(a) self, int offset=0, int dim1=0, int dim2=1) -\u003e Tensor(a) inline at::Tensor Tensor::diagonal(int64_t offset, int64_t dim1, int64_t dim2) const { return at::_ops::diagonal::call(const_cast\u003cTensor\u0026\u003e(*this), offset, dim1, dim2); } // aten::diagonal.Dimname(Tensor(a) self, *, Dimname outdim, Dimname dim1, Dimname dim2, int offset=0) -\u003e Tensor(a) inline at::Tensor Tensor::diagonal(at::Dimname outdim, at::Dimname dim1, at::Dimname dim2, int64_t offset) const { return at::_ops::diagonal_Dimname::call(const_cast\u003cTensor\u0026\u003e(*this), outdim, dim1, dim2, offset); } // aten::fill_diagonal_(Tensor(a!) self, Scalar fill_value, bool wrap=False) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::fill_diagonal_(const at::Scalar \u0026 fill_value, bool wrap) const { return at::_ops::fill_diagonal_::call(const_cast\u003cTensor\u0026\u003e(*this), fill_value, wrap); } // aten::diff(Tensor self, int n=1, int dim=-1, Tensor? prepend=None, Tensor? append=None) -\u003e Tensor inline at::Tensor Tensor::diff(int64_t n, int64_t dim, const ::std::optional\u003cat::Tensor\u003e \u0026 prepend, const ::std::optional\u003cat::Tensor\u003e \u0026 append) const { return at::_ops::diff::call(const_cast\u003cTensor\u0026\u003e(*this), n, dim, prepend, append); } // aten::div.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::div(const at::Tensor \u0026 other) const { return at::_ops::div_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::div_.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::div_(const at::Tensor \u0026 other) const { return at::_ops::div__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::div.Tensor_mode(Tensor self, Tensor other, *, str? rounding_mode) -\u003e Tensor inline at::Tensor Tensor::div(const at::Tensor \u0026 other, ::std::optional\u003cc10::string_view\u003e rounding_mode) const { return at::_ops::div_Tensor_mode::call(const_cast\u003cTensor\u0026\u003e(*this), other, rounding_mode); } // aten::div_.Tensor_mode(Tensor(a!) self, Tensor other, *, str? rounding_mode) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::div_(const at::Tensor \u0026 other, ::std::optional\u003cc10::string_view\u003e rounding_mode) const { return at::_ops::div__Tensor_mode::call(const_cast\u003cTensor\u0026\u003e(*this), other, rounding_mode); } // aten::div.Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::div(const at::Scalar \u0026 other) const { return at::_ops::div_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::div_.Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::div_(const at::Scalar \u0026 other) const { return at::_ops::div__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::div.Scalar_mode(Tensor self, Scalar other, *, str? rounding_mode) -\u003e Tensor inline at::Tensor Tensor::div(const at::Scalar \u0026 other, ::std::optional\u003cc10::string_view\u003e rounding_mode) const { return at::_ops::div_Scalar_mode::call(const_cast\u003cTensor\u0026\u003e(*this), other, rounding_mode); } // aten::div_.Scalar_mode(Tensor(a!) self, Scalar other, *, str? rounding_mode) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::div_(const at::Scalar \u0026 other, ::std::optional\u003cc10::string_view\u003e rounding_mode) const { return at::_ops::div__Scalar_mode::call(const_cast\u003cTensor\u0026\u003e(*this), other, rounding_mode); } // aten::divide.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::divide(const at::Tensor \u0026 other) const { return at::_ops::divide_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::divide_.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::divide_(const at::Tensor \u0026 other) const { return at::_ops::divide__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::divide.Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::divide(const at::Scalar \u0026 other) const { return at::_ops::divide_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::divide_.Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::divide_(const at::Scalar \u0026 other) const { return at::_ops::divide__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::divide.Tensor_mode(Tensor self, Tensor other, *, str? rounding_mode) -\u003e Tensor inline at::Tensor Tensor::divide(const at::Tensor \u0026 other, ::std::optional\u003cc10::string_view\u003e rounding_mode) const { return at::_ops::divide_Tensor_mode::call(const_cast\u003cTensor\u0026\u003e(*this), other, rounding_mode); } // aten::divide_.Tensor_mode(Tensor(a!) self, Tensor other, *, str? rounding_mode) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::divide_(const at::Tensor \u0026 other, ::std::optional\u003cc10::string_view\u003e rounding_mode) const { return at::_ops::divide__Tensor_mode::call(const_cast\u003cTensor\u0026\u003e(*this), other, rounding_mode); } // aten::divide.Scalar_mode(Tensor self, Scalar other, *, str? rounding_mode) -\u003e Tensor inline at::Tensor Tensor::divide(const at::Scalar \u0026 other, ::std::optional\u003cc10::string_view\u003e rounding_mode) const { return at::_ops::divide_Scalar_mode::call(const_cast\u003cTensor\u0026\u003e(*this), other, rounding_mode); } // aten::divide_.Scalar_mode(Tensor(a!) self, Scalar other, *, str? rounding_mode) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::divide_(const at::Scalar \u0026 other, ::std::optional\u003cc10::string_view\u003e rounding_mode) const { return at::_ops::divide__Scalar_mode::call(const_cast\u003cTensor\u0026\u003e(*this), other, rounding_mode); } // aten::true_divide.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::true_divide(const at::Tensor \u0026 other) const { return at::_ops::true_divide_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::true_divide_.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::true_divide_(const at::Tensor \u0026 other) const { return at::_ops::true_divide__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::true_divide.Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::true_divide(const at::Scalar \u0026 other) const { return at::_ops::true_divide_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::true_divide_.Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::true_divide_(const at::Scalar \u0026 other) const { return at::_ops::true_divide__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::dot(Tensor self, Tensor tensor) -\u003e Tensor inline at::Tensor Tensor::dot(const at::Tensor \u0026 tensor) const { return at::_ops::dot::call(const_cast\u003cTensor\u0026\u003e(*this), tensor); } // aten::vdot(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::vdot(const at::Tensor \u0026 other) const { return at::_ops::vdot::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::new_empty(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -\u003e Tensor inline at::Tensor Tensor::new_empty(at::IntArrayRef size, at::TensorOptions options) const { return at::_ops::new_empty::call(const_cast\u003cTensor\u0026\u003e(*this), c10::fromIntArrayRefSlow(size), c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt()); } // aten::new_empty(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -\u003e Tensor inline at::Tensor Tensor::new_empty(at::IntArrayRef size, ::std::optional\u003cat::ScalarType\u003e dtype, ::std::optional\u003cat::Layout\u003e layout, ::std::optional\u003cat::Device\u003e device, ::std::optional\u003cbool\u003e pin_memory) const { return at::_ops::new_empty::call(const_cast\u003cTensor\u0026\u003e(*this), c10::fromIntArrayRefSlow(size), dtype, layout, device, pin_memory); } // aten::new_empty(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -\u003e Tensor inline at::Tensor Tensor::new_empty_symint(c10::SymIntArrayRef size, at::TensorOptions options) const { return at::_ops::new_empty::call(const_cast\u003cTensor\u0026\u003e(*this), size, c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt()); } // aten::new_empty(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -\u003e Tensor inline at::Tensor Tensor::new_empty_symint(c10::SymIntArrayRef size, ::std::optional\u003cat::ScalarType\u003e dtype, ::std::optional\u003cat::Layout\u003e layout, ::std::optional\u003cat::Device\u003e device, ::std::optional\u003cbool\u003e pin_memory) const { return at::_ops::new_empty::call(const_cast\u003cTensor\u0026\u003e(*this), size, dtype, layout, device, pin_memory); } // aten::new_empty_strided(Tensor self, SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -\u003e Tensor inline at::Tensor Tensor::new_empty_strided(at::IntArrayRef size, at::IntArrayRef stride, at::TensorOptions options) const { return at::_ops::new_empty_strided::call(const_cast\u003cTensor\u0026\u003e(*this), c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride), c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt()); } // aten::new_empty_strided(Tensor self, SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -\u003e Tensor inline at::Tensor Tensor::new_empty_strided(at::IntArrayRef size, at::IntArrayRef stride, ::std::optional\u003cat::ScalarType\u003e dtype, ::std::optional\u003cat::Layout\u003e layout, ::std::optional\u003cat::Device\u003e device, ::std::optional\u003cbool\u003e pin_memory) const { return at::_ops::new_empty_strided::call(const_cast\u003cTensor\u0026\u003e(*this), c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride), dtype, layout, device, pin_memory); } // aten::new_empty_strided(Tensor self, SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -\u003e Tensor inline at::Tensor Tensor::new_empty_strided_symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride, at::TensorOptions options) const { return at::_ops::new_empty_strided::call(const_cast\u003cTensor\u0026\u003e(*this), size, stride, c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt()); } // aten::new_empty_strided(Tensor self, SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -\u003e Tensor inline at::Tensor Tensor::new_empty_strided_symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride, ::std::optional\u003cat::ScalarType\u003e dtype, ::std::optional\u003cat::Layout\u003e layout, ::std::optional\u003cat::Device\u003e device, ::std::optional\u003cbool\u003e pin_memory) const { return at::_ops::new_empty_strided::call(const_cast\u003cTensor\u0026\u003e(*this), size, stride, dtype, layout, device, pin_memory); } // aten::new_full(Tensor self, SymInt[] size, Scalar fill_value, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -\u003e Tensor inline at::Tensor Tensor::new_full(at::IntArrayRef size, const at::Scalar \u0026 fill_value, at::TensorOptions options) const { return at::_ops::new_full::call(const_cast\u003cTensor\u0026\u003e(*this), c10::fromIntArrayRefSlow(size), fill_value, c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt()); } // aten::new_full(Tensor self, SymInt[] size, Scalar fill_value, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -\u003e Tensor inline at::Tensor Tensor::new_full(at::IntArrayRef size, const at::Scalar \u0026 fill_value, ::std::optional\u003cat::ScalarType\u003e dtype, ::std::optional\u003cat::Layout\u003e layout, ::std::optional\u003cat::Device\u003e device, ::std::optional\u003cbool\u003e pin_memory) const { return at::_ops::new_full::call(const_cast\u003cTensor\u0026\u003e(*this), c10::fromIntArrayRefSlow(size), fill_value, dtype, layout, device, pin_memory); } // aten::new_full(Tensor self, SymInt[] size, Scalar fill_value, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -\u003e Tensor inline at::Tensor Tensor::new_full_symint(c10::SymIntArrayRef size, const at::Scalar \u0026 fill_value, at::TensorOptions options) const { return at::_ops::new_full::call(const_cast\u003cTensor\u0026\u003e(*this), size, fill_value, c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt()); } // aten::new_full(Tensor self, SymInt[] size, Scalar fill_value, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -\u003e Tensor inline at::Tensor Tensor::new_full_symint(c10::SymIntArrayRef size, const at::Scalar \u0026 fill_value, ::std::optional\u003cat::ScalarType\u003e dtype, ::std::optional\u003cat::Layout\u003e layout, ::std::optional\u003cat::Device\u003e device, ::std::optional\u003cbool\u003e pin_memory) const { return at::_ops::new_full::call(const_cast\u003cTensor\u0026\u003e(*this), size, fill_value, dtype, layout, device, pin_memory); } // aten::new_zeros(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -\u003e Tensor inline at::Tensor Tensor::new_zeros(at::IntArrayRef size, at::TensorOptions options) const { return at::_ops::new_zeros::call(const_cast\u003cTensor\u0026\u003e(*this), c10::fromIntArrayRefSlow(size), c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt()); } // aten::new_zeros(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -\u003e Tensor inline at::Tensor Tensor::new_zeros(at::IntArrayRef size, ::std::optional\u003cat::ScalarType\u003e dtype, ::std::optional\u003cat::Layout\u003e layout, ::std::optional\u003cat::Device\u003e device, ::std::optional\u003cbool\u003e pin_memory) const { return at::_ops::new_zeros::call(const_cast\u003cTensor\u0026\u003e(*this), c10::fromIntArrayRefSlow(size), dtype, layout, device, pin_memory); } // aten::new_zeros(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -\u003e Tensor inline at::Tensor Tensor::new_zeros_symint(c10::SymIntArrayRef size, at::TensorOptions options) const { return at::_ops::new_zeros::call(const_cast\u003cTensor\u0026\u003e(*this), size, c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt()); } // aten::new_zeros(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -\u003e Tensor inline at::Tensor Tensor::new_zeros_symint(c10::SymIntArrayRef size, ::std::optional\u003cat::ScalarType\u003e dtype, ::std::optional\u003cat::Layout\u003e layout, ::std::optional\u003cat::Device\u003e device, ::std::optional\u003cbool\u003e pin_memory) const { return at::_ops::new_zeros::call(const_cast\u003cTensor\u0026\u003e(*this), size, dtype, layout, device, pin_memory); } // aten::new_ones(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -\u003e Tensor inline at::Tensor Tensor::new_ones(at::IntArrayRef size, at::TensorOptions options) const { return at::_ops::new_ones::call(const_cast\u003cTensor\u0026\u003e(*this), c10::fromIntArrayRefSlow(size), c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt()); } // aten::new_ones(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -\u003e Tensor inline at::Tensor Tensor::new_ones(at::IntArrayRef size, ::std::optional\u003cat::ScalarType\u003e dtype, ::std::optional\u003cat::Layout\u003e layout, ::std::optional\u003cat::Device\u003e device, ::std::optional\u003cbool\u003e pin_memory) const { return at::_ops::new_ones::call(const_cast\u003cTensor\u0026\u003e(*this), c10::fromIntArrayRefSlow(size), dtype, layout, device, pin_memory); } // aten::new_ones(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -\u003e Tensor inline at::Tensor Tensor::new_ones_symint(c10::SymIntArrayRef size, at::TensorOptions options) const { return at::_ops::new_ones::call(const_cast\u003cTensor\u0026\u003e(*this), size, c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt()); } // aten::new_ones(Tensor self, SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -\u003e Tensor inline at::Tensor Tensor::new_ones_symint(c10::SymIntArrayRef size, ::std::optional\u003cat::ScalarType\u003e dtype, ::std::optional\u003cat::Layout\u003e layout, ::std::optional\u003cat::Device\u003e device, ::std::optional\u003cbool\u003e pin_memory) const { return at::_ops::new_ones::call(const_cast\u003cTensor\u0026\u003e(*this), size, dtype, layout, device, pin_memory); } // aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -\u003e Tensor(a!) inline const at::Tensor \u0026 Tensor::resize_(at::IntArrayRef size, ::std::optional\u003cat::MemoryFormat\u003e memory_format) const { return at::_ops::resize_::call(const_cast\u003cTensor\u0026\u003e(*this), c10::fromIntArrayRefSlow(size), memory_format); } // aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -\u003e Tensor(a!) inline const at::Tensor \u0026 Tensor::resize__symint(c10::SymIntArrayRef size, ::std::optional\u003cat::MemoryFormat\u003e memory_format) const { return at::_ops::resize_::call(const_cast\u003cTensor\u0026\u003e(*this), size, memory_format); } // aten::erf(Tensor self) -\u003e Tensor inline at::Tensor Tensor::erf() const { return at::_ops::erf::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::erf_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::erf_() const { return at::_ops::erf_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::erfc(Tensor self) -\u003e Tensor inline at::Tensor Tensor::erfc() const { return at::_ops::erfc::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::erfc_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::erfc_() const { return at::_ops::erfc_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::exp(Tensor self) -\u003e Tensor inline at::Tensor Tensor::exp() const { return at::_ops::exp::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::exp_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::exp_() const { return at::_ops::exp_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::exp2(Tensor self) -\u003e Tensor inline at::Tensor Tensor::exp2() const { return at::_ops::exp2::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::exp2_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::exp2_() const { return at::_ops::exp2_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::expm1(Tensor self) -\u003e Tensor inline at::Tensor Tensor::expm1() const { return at::_ops::expm1::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::expm1_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::expm1_() const { return at::_ops::expm1_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -\u003e Tensor(a) inline at::Tensor Tensor::expand(at::IntArrayRef size, bool implicit) const { return at::_ops::expand::call(const_cast\u003cTensor\u0026\u003e(*this), c10::fromIntArrayRefSlow(size), implicit); } // aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -\u003e Tensor(a) inline at::Tensor Tensor::expand_symint(c10::SymIntArrayRef size, bool implicit) const { return at::_ops::expand::call(const_cast\u003cTensor\u0026\u003e(*this), size, implicit); } // aten::expand_as(Tensor(a) self, Tensor other) -\u003e Tensor(a) inline at::Tensor Tensor::expand_as(const at::Tensor \u0026 other) const { return at::_ops::expand_as::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::flatten.using_ints(Tensor(a) self, int start_dim=0, int end_dim=-1) -\u003e Tensor(a) inline at::Tensor Tensor::flatten(int64_t start_dim, int64_t end_dim) const { return at::_ops::flatten_using_ints::call(const_cast\u003cTensor\u0026\u003e(*this), start_dim, end_dim); } // aten::flatten.named_out_dim(Tensor(a) self, int start_dim, int end_dim, Dimname out_dim) -\u003e Tensor(a) inline at::Tensor Tensor::flatten(int64_t start_dim, int64_t end_dim, at::Dimname out_dim) const { return at::_ops::flatten_named_out_dim::call(const_cast\u003cTensor\u0026\u003e(*this), start_dim, end_dim, out_dim); } // aten::flatten.using_names(Tensor(a) self, Dimname start_dim, Dimname end_dim, Dimname out_dim) -\u003e Tensor(a) inline at::Tensor Tensor::flatten(at::Dimname start_dim, at::Dimname end_dim, at::Dimname out_dim) const { return at::_ops::flatten_using_names::call(const_cast\u003cTensor\u0026\u003e(*this), start_dim, end_dim, out_dim); } // aten::flatten.DimnameList(Tensor(a) self, Dimname[] dims, Dimname out_dim) -\u003e Tensor(a) inline at::Tensor Tensor::flatten(at::DimnameList dims, at::Dimname out_dim) const { return at::_ops::flatten_DimnameList::call(const_cast\u003cTensor\u0026\u003e(*this), dims, out_dim); } // aten::unflatten.int(Tensor(a) self, int dim, SymInt[] sizes) -\u003e Tensor(a) inline at::Tensor Tensor::unflatten(int64_t dim, at::IntArrayRef sizes) const { return at::_ops::unflatten_int::call(const_cast\u003cTensor\u0026\u003e(*this), dim, c10::fromIntArrayRefSlow(sizes)); } // aten::unflatten.int(Tensor(a) self, int dim, SymInt[] sizes) -\u003e Tensor(a) inline at::Tensor Tensor::unflatten_symint(int64_t dim, c10::SymIntArrayRef sizes) const { return at::_ops::unflatten_int::call(const_cast\u003cTensor\u0026\u003e(*this), dim, sizes); } // aten::unflatten.Dimname(Tensor(a) self, Dimname dim, SymInt[] sizes, Dimname[] names) -\u003e Tensor(a) inline at::Tensor Tensor::unflatten(at::Dimname dim, at::IntArrayRef sizes, at::DimnameList names) const { return at::_ops::unflatten_Dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim, c10::fromIntArrayRefSlow(sizes), names); } // aten::unflatten.Dimname(Tensor(a) self, Dimname dim, SymInt[] sizes, Dimname[] names) -\u003e Tensor(a) inline at::Tensor Tensor::unflatten_symint(at::Dimname dim, c10::SymIntArrayRef sizes, at::DimnameList names) const { return at::_ops::unflatten_Dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim, sizes, names); } // aten::fill_.Scalar(Tensor(a!) self, Scalar value) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::fill_(const at::Scalar \u0026 value) const { return at::_ops::fill__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), value); } // aten::fill_.Tensor(Tensor(a!) self, Tensor value) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::fill_(const at::Tensor \u0026 value) const { return at::_ops::fill__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), value); } // aten::floor(Tensor self) -\u003e Tensor inline at::Tensor Tensor::floor() const { return at::_ops::floor::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::floor_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::floor_() const { return at::_ops::floor_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::floor_divide(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::floor_divide(const at::Tensor \u0026 other) const { return at::_ops::floor_divide::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::floor_divide_.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::floor_divide_(const at::Tensor \u0026 other) const { return at::_ops::floor_divide__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::floor_divide.Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::floor_divide(const at::Scalar \u0026 other) const { return at::_ops::floor_divide_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::floor_divide_.Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::floor_divide_(const at::Scalar \u0026 other) const { return at::_ops::floor_divide__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::frac(Tensor self) -\u003e Tensor inline at::Tensor Tensor::frac() const { return at::_ops::frac::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::frac_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::frac_() const { return at::_ops::frac_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::gcd(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::gcd(const at::Tensor \u0026 other) const { return at::_ops::gcd::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::gcd_(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::gcd_(const at::Tensor \u0026 other) const { return at::_ops::gcd_::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::lcm(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::lcm(const at::Tensor \u0026 other) const { return at::_ops::lcm::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::lcm_(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::lcm_(const at::Tensor \u0026 other) const { return at::_ops::lcm_::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::index.Tensor(Tensor self, Tensor?[] indices) -\u003e Tensor inline at::Tensor Tensor::index(const c10::List\u003c::std::optional\u003cat::Tensor\u003e\u003e \u0026 indices) const { return at::_ops::index_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), indices); } // aten::index_copy_(Tensor(a!) self, int dim, Tensor index, Tensor source) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::index_copy_(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 source) const { return at::_ops::index_copy_::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, source); } // aten::index_copy(Tensor self, int dim, Tensor index, Tensor source) -\u003e Tensor inline at::Tensor Tensor::index_copy(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 source) const { return at::_ops::index_copy::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, source); } // aten::index_copy_.dimname(Tensor(a!) self, Dimname dim, Tensor index, Tensor source) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::index_copy_(at::Dimname dim, const at::Tensor \u0026 index, const at::Tensor \u0026 source) const { return at::_ops::index_copy__dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, source); } // aten::index_copy.dimname(Tensor self, Dimname dim, Tensor index, Tensor source) -\u003e Tensor inline at::Tensor Tensor::index_copy(at::Dimname dim, const at::Tensor \u0026 index, const at::Tensor \u0026 source) const { return at::_ops::index_copy_dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, source); } // aten::index_put_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::index_put_(const c10::List\u003c::std::optional\u003cat::Tensor\u003e\u003e \u0026 indices, const at::Tensor \u0026 values, bool accumulate) const { return at::_ops::index_put_::call(const_cast\u003cTensor\u0026\u003e(*this), indices, values, accumulate); } // aten::index_put(Tensor self, Tensor?[] indices, Tensor values, bool accumulate=False) -\u003e Tensor inline at::Tensor Tensor::index_put(const c10::List\u003c::std::optional\u003cat::Tensor\u003e\u003e \u0026 indices, const at::Tensor \u0026 values, bool accumulate) const { return at::_ops::index_put::call(const_cast\u003cTensor\u0026\u003e(*this), indices, values, accumulate); } // aten::isclose(Tensor self, Tensor other, float rtol=1e-05, float atol=1e-08, bool equal_nan=False) -\u003e Tensor inline at::Tensor Tensor::isclose(const at::Tensor \u0026 other, double rtol, double atol, bool equal_nan) const { return at::_ops::isclose::call(const_cast\u003cTensor\u0026\u003e(*this), other, rtol, atol, equal_nan); } // aten::isnan(Tensor self) -\u003e Tensor inline at::Tensor Tensor::isnan() const { return at::_ops::isnan::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::is_distributed(Tensor self) -\u003e bool inline bool Tensor::is_distributed() const { return at::_ops::is_distributed::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::is_floating_point(Tensor self) -\u003e bool inline bool Tensor::__dispatch_is_floating_point() const { return at::_ops::is_floating_point::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::is_complex(Tensor self) -\u003e bool inline bool Tensor::__dispatch_is_complex() const { return at::_ops::is_complex::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::is_conj(Tensor self) -\u003e bool inline bool Tensor::__dispatch_is_conj() const { return at::_ops::is_conj::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::_is_zerotensor(Tensor self) -\u003e bool inline bool Tensor::__dispatch__is_zerotensor() const { return at::_ops::_is_zerotensor::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::is_neg(Tensor self) -\u003e bool inline bool Tensor::__dispatch_is_neg() const { return at::_ops::is_neg::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::isreal(Tensor self) -\u003e Tensor inline at::Tensor Tensor::isreal() const { return at::_ops::isreal::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::is_nonzero(Tensor self) -\u003e bool inline bool Tensor::is_nonzero() const { return at::_ops::is_nonzero::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::is_same_size(Tensor self, Tensor other) -\u003e bool inline bool Tensor::is_same_size(const at::Tensor \u0026 other) const { return at::_ops::is_same_size::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::is_signed(Tensor self) -\u003e bool inline bool Tensor::__dispatch_is_signed() const { return at::_ops::is_signed::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::is_inference(Tensor self) -\u003e bool inline bool Tensor::__dispatch_is_inference() const { return at::_ops::is_inference::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::kron(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::kron(const at::Tensor \u0026 other) const { return at::_ops::kron::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::kthvalue(Tensor self, SymInt k, int dim=-1, bool keepdim=False) -\u003e (Tensor values, Tensor indices) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::kthvalue(int64_t k, int64_t dim, bool keepdim) const { return at::_ops::kthvalue::call(const_cast\u003cTensor\u0026\u003e(*this), k, dim, keepdim); } // aten::kthvalue(Tensor self, SymInt k, int dim=-1, bool keepdim=False) -\u003e (Tensor values, Tensor indices) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::kthvalue_symint(c10::SymInt k, int64_t dim, bool keepdim) const { return at::_ops::kthvalue::call(const_cast\u003cTensor\u0026\u003e(*this), k, dim, keepdim); } // aten::kthvalue.dimname(Tensor self, SymInt k, Dimname dim, bool keepdim=False) -\u003e (Tensor values, Tensor indices) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::kthvalue(int64_t k, at::Dimname dim, bool keepdim) const { return at::_ops::kthvalue_dimname::call(const_cast\u003cTensor\u0026\u003e(*this), k, dim, keepdim); } // aten::kthvalue.dimname(Tensor self, SymInt k, Dimname dim, bool keepdim=False) -\u003e (Tensor values, Tensor indices) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::kthvalue_symint(c10::SymInt k, at::Dimname dim, bool keepdim) const { return at::_ops::kthvalue_dimname::call(const_cast\u003cTensor\u0026\u003e(*this), k, dim, keepdim); } // aten::nan_to_num(Tensor self, float? nan=None, float? posinf=None, float? neginf=None) -\u003e Tensor inline at::Tensor Tensor::nan_to_num(::std::optional\u003cdouble\u003e nan, ::std::optional\u003cdouble\u003e posinf, ::std::optional\u003cdouble\u003e neginf) const { return at::_ops::nan_to_num::call(const_cast\u003cTensor\u0026\u003e(*this), nan, posinf, neginf); } // aten::nan_to_num_(Tensor(a!) self, float? nan=None, float? posinf=None, float? neginf=None) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::nan_to_num_(::std::optional\u003cdouble\u003e nan, ::std::optional\u003cdouble\u003e posinf, ::std::optional\u003cdouble\u003e neginf) const { return at::_ops::nan_to_num_::call(const_cast\u003cTensor\u0026\u003e(*this), nan, posinf, neginf); } // aten::ldexp.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::ldexp(const at::Tensor \u0026 other) const { return at::_ops::ldexp_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::ldexp_(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::ldexp_(const at::Tensor \u0026 other) const { return at::_ops::ldexp_::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::log(Tensor self) -\u003e Tensor inline at::Tensor Tensor::log() const { return at::_ops::log::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::log_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::log_() const { return at::_ops::log_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::log10(Tensor self) -\u003e Tensor inline at::Tensor Tensor::log10() const { return at::_ops::log10::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::log10_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::log10_() const { return at::_ops::log10_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::log1p(Tensor self) -\u003e Tensor inline at::Tensor Tensor::log1p() const { return at::_ops::log1p::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::log1p_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::log1p_() const { return at::_ops::log1p_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::log2(Tensor self) -\u003e Tensor inline at::Tensor Tensor::log2() const { return at::_ops::log2::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::log2_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::log2_() const { return at::_ops::log2_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::logaddexp(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::logaddexp(const at::Tensor \u0026 other) const { return at::_ops::logaddexp::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::logaddexp2(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::logaddexp2(const at::Tensor \u0026 other) const { return at::_ops::logaddexp2::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::xlogy.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::xlogy(const at::Tensor \u0026 other) const { return at::_ops::xlogy_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::xlogy.Scalar_Other(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::xlogy(const at::Scalar \u0026 other) const { return at::_ops::xlogy_Scalar_Other::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::xlogy_.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::xlogy_(const at::Tensor \u0026 other) const { return at::_ops::xlogy__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::xlogy_.Scalar_Other(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::xlogy_(const at::Scalar \u0026 other) const { return at::_ops::xlogy__Scalar_Other::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::log_softmax.int(Tensor self, int dim, ScalarType? dtype=None) -\u003e Tensor inline at::Tensor Tensor::log_softmax(int64_t dim, ::std::optional\u003cat::ScalarType\u003e dtype) const { return at::_ops::log_softmax_int::call(const_cast\u003cTensor\u0026\u003e(*this), dim, dtype); } // aten::log_softmax.Dimname(Tensor self, Dimname dim, *, ScalarType? dtype=None) -\u003e Tensor inline at::Tensor Tensor::log_softmax(at::Dimname dim, ::std::optional\u003cat::ScalarType\u003e dtype) const { return at::_ops::log_softmax_Dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim, dtype); } // aten::logcumsumexp(Tensor self, int dim) -\u003e Tensor inline at::Tensor Tensor::logcumsumexp(int64_t dim) const { return at::_ops::logcumsumexp::call(const_cast\u003cTensor\u0026\u003e(*this), dim); } // aten::logcumsumexp.dimname(Tensor self, Dimname dim) -\u003e Tensor inline at::Tensor Tensor::logcumsumexp(at::Dimname dim) const { return at::_ops::logcumsumexp_dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim); } // aten::logsumexp(Tensor self, int[1] dim, bool keepdim=False) -\u003e Tensor inline at::Tensor Tensor::logsumexp(at::IntArrayRef dim, bool keepdim) const { return at::_ops::logsumexp::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim); } // aten::logsumexp.names(Tensor self, Dimname[1] dim, bool keepdim=False) -\u003e Tensor inline at::Tensor Tensor::logsumexp(at::DimnameList dim, bool keepdim) const { return at::_ops::logsumexp_names::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim); } // aten::matmul(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::matmul(const at::Tensor \u0026 other) const { return at::_ops::matmul::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::matrix_power(Tensor self, int n) -\u003e Tensor inline at::Tensor Tensor::matrix_power(int64_t n) const { return at::_ops::matrix_power::call(const_cast\u003cTensor\u0026\u003e(*this), n); } // aten::matrix_exp(Tensor self) -\u003e Tensor inline at::Tensor Tensor::matrix_exp() const { return at::_ops::matrix_exp::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::aminmax(Tensor self, *, int? dim=None, bool keepdim=False) -\u003e (Tensor min, Tensor max) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::aminmax(::std::optional\u003cint64_t\u003e dim, bool keepdim) const { return at::_ops::aminmax::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim); } // aten::max.dim(Tensor self, int dim, bool keepdim=False) -\u003e (Tensor values, Tensor indices) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::max(int64_t dim, bool keepdim) const { return at::_ops::max_dim::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim); } // aten::max.names_dim(Tensor self, Dimname dim, bool keepdim=False) -\u003e (Tensor values, Tensor indices) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::max(at::Dimname dim, bool keepdim) const { return at::_ops::max_names_dim::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim); } // aten::amax(Tensor self, int[1] dim=[], bool keepdim=False) -\u003e Tensor inline at::Tensor Tensor::amax(at::IntArrayRef dim, bool keepdim) const { return at::_ops::amax::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim); } // aten::mean(Tensor self, *, ScalarType? dtype=None) -\u003e Tensor inline at::Tensor Tensor::mean(::std::optional\u003cat::ScalarType\u003e dtype) const { return at::_ops::mean::call(const_cast\u003cTensor\u0026\u003e(*this), dtype); } // aten::mean.dim(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -\u003e Tensor inline at::Tensor Tensor::mean(at::OptionalIntArrayRef dim, bool keepdim, ::std::optional\u003cat::ScalarType\u003e dtype) const { return at::_ops::mean_dim::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim, dtype); } // aten::mean.names_dim(Tensor self, Dimname[1] dim, bool keepdim=False, *, ScalarType? dtype=None) -\u003e Tensor inline at::Tensor Tensor::mean(at::DimnameList dim, bool keepdim, ::std::optional\u003cat::ScalarType\u003e dtype) const { return at::_ops::mean_names_dim::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim, dtype); } // aten::nanmean(Tensor self, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -\u003e Tensor inline at::Tensor Tensor::nanmean(at::OptionalIntArrayRef dim, bool keepdim, ::std::optional\u003cat::ScalarType\u003e dtype) const { return at::_ops::nanmean::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim, dtype); } // aten::median(Tensor self) -\u003e Tensor inline at::Tensor Tensor::median() const { return at::_ops::median::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::median.dim(Tensor self, int dim, bool keepdim=False) -\u003e (Tensor values, Tensor indices) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::median(int64_t dim, bool keepdim) const { return at::_ops::median_dim::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim); } // aten::median.names_dim(Tensor self, Dimname dim, bool keepdim=False) -\u003e (Tensor values, Tensor indices) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::median(at::Dimname dim, bool keepdim) const { return at::_ops::median_names_dim::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim); } // aten::nanmedian(Tensor self) -\u003e Tensor inline at::Tensor Tensor::nanmedian() const { return at::_ops::nanmedian::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::nanmedian.dim(Tensor self, int dim, bool keepdim=False) -\u003e (Tensor values, Tensor indices) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::nanmedian(int64_t dim, bool keepdim) const { return at::_ops::nanmedian_dim::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim); } // aten::nanmedian.names_dim(Tensor self, Dimname dim, bool keepdim=False) -\u003e (Tensor values, Tensor indices) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::nanmedian(at::Dimname dim, bool keepdim) const { return at::_ops::nanmedian_names_dim::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim); } // aten::min.dim(Tensor self, int dim, bool keepdim=False) -\u003e (Tensor values, Tensor indices) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::min(int64_t dim, bool keepdim) const { return at::_ops::min_dim::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim); } // aten::min.names_dim(Tensor self, Dimname dim, bool keepdim=False) -\u003e (Tensor values, Tensor indices) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::min(at::Dimname dim, bool keepdim) const { return at::_ops::min_names_dim::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim); } // aten::amin(Tensor self, int[1] dim=[], bool keepdim=False) -\u003e Tensor inline at::Tensor Tensor::amin(at::IntArrayRef dim, bool keepdim) const { return at::_ops::amin::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim); } // aten::mm(Tensor self, Tensor mat2) -\u003e Tensor inline at::Tensor Tensor::mm(const at::Tensor \u0026 mat2) const { return at::_ops::mm::call(const_cast\u003cTensor\u0026\u003e(*this), mat2); } // aten::mode(Tensor self, int dim=-1, bool keepdim=False) -\u003e (Tensor values, Tensor indices) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::mode(int64_t dim, bool keepdim) const { return at::_ops::mode::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim); } // aten::mode.dimname(Tensor self, Dimname dim, bool keepdim=False) -\u003e (Tensor values, Tensor indices) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::mode(at::Dimname dim, bool keepdim) const { return at::_ops::mode_dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim); } // aten::mul.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::mul(const at::Tensor \u0026 other) const { return at::_ops::mul_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::mul_.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::mul_(const at::Tensor \u0026 other) const { return at::_ops::mul__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::mul.Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::mul(const at::Scalar \u0026 other) const { return at::_ops::mul_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::mul_.Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::mul_(const at::Scalar \u0026 other) const { return at::_ops::mul__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::multiply.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::multiply(const at::Tensor \u0026 other) const { return at::_ops::multiply_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::multiply_.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::multiply_(const at::Tensor \u0026 other) const { return at::_ops::multiply__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::multiply.Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::multiply(const at::Scalar \u0026 other) const { return at::_ops::multiply_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::multiply_.Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::multiply_(const at::Scalar \u0026 other) const { return at::_ops::multiply__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::mv(Tensor self, Tensor vec) -\u003e Tensor inline at::Tensor Tensor::mv(const at::Tensor \u0026 vec) const { return at::_ops::mv::call(const_cast\u003cTensor\u0026\u003e(*this), vec); } // aten::mvlgamma(Tensor self, int p) -\u003e Tensor inline at::Tensor Tensor::mvlgamma(int64_t p) const { return at::_ops::mvlgamma::call(const_cast\u003cTensor\u0026\u003e(*this), p); } // aten::mvlgamma_(Tensor(a!) self, int p) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::mvlgamma_(int64_t p) const { return at::_ops::mvlgamma_::call(const_cast\u003cTensor\u0026\u003e(*this), p); } // aten::narrow_copy(Tensor self, int dim, SymInt start, SymInt length) -\u003e Tensor inline at::Tensor Tensor::narrow_copy(int64_t dim, int64_t start, int64_t length) const { return at::_ops::narrow_copy::call(const_cast\u003cTensor\u0026\u003e(*this), dim, start, length); } // aten::narrow_copy(Tensor self, int dim, SymInt start, SymInt length) -\u003e Tensor inline at::Tensor Tensor::narrow_copy_symint(int64_t dim, c10::SymInt start, c10::SymInt length) const { return at::_ops::narrow_copy::call(const_cast\u003cTensor\u0026\u003e(*this), dim, start, length); } // aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -\u003e Tensor(a) inline at::Tensor Tensor::narrow(int64_t dim, int64_t start, int64_t length) const { return at::_ops::narrow::call(const_cast\u003cTensor\u0026\u003e(*this), dim, start, length); } // aten::narrow(Tensor(a) self, int dim, SymInt start, SymInt length) -\u003e Tensor(a) inline at::Tensor Tensor::narrow_symint(int64_t dim, c10::SymInt start, c10::SymInt length) const { return at::_ops::narrow::call(const_cast\u003cTensor\u0026\u003e(*this), dim, start, length); } // aten::narrow.Tensor(Tensor(a) self, int dim, Tensor start, SymInt length) -\u003e Tensor(a) inline at::Tensor Tensor::narrow(int64_t dim, const at::Tensor \u0026 start, int64_t length) const { return at::_ops::narrow_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), dim, start, length); } // aten::narrow.Tensor(Tensor(a) self, int dim, Tensor start, SymInt length) -\u003e Tensor(a) inline at::Tensor Tensor::narrow_symint(int64_t dim, const at::Tensor \u0026 start, c10::SymInt length) const { return at::_ops::narrow_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), dim, start, length); } // aten::permute(Tensor(a) self, int[] dims) -\u003e Tensor(a) inline at::Tensor Tensor::permute(at::IntArrayRef dims) const { return at::_ops::permute::call(const_cast\u003cTensor\u0026\u003e(*this), dims); } // aten::movedim.intlist(Tensor(a) self, int[] source, int[] destination) -\u003e Tensor(a) inline at::Tensor Tensor::movedim(at::IntArrayRef source, at::IntArrayRef destination) const { return at::_ops::movedim_intlist::call(const_cast\u003cTensor\u0026\u003e(*this), source, destination); } // aten::movedim.int(Tensor(a) self, int source, int destination) -\u003e Tensor(a) inline at::Tensor Tensor::movedim(int64_t source, int64_t destination) const { return at::_ops::movedim_int::call(const_cast\u003cTensor\u0026\u003e(*this), source, destination); } // aten::moveaxis.intlist(Tensor(a) self, int[] source, int[] destination) -\u003e Tensor(a) inline at::Tensor Tensor::moveaxis(at::IntArrayRef source, at::IntArrayRef destination) const { return at::_ops::moveaxis_intlist::call(const_cast\u003cTensor\u0026\u003e(*this), source, destination); } // aten::moveaxis.int(Tensor(a) self, int source, int destination) -\u003e Tensor(a) inline at::Tensor Tensor::moveaxis(int64_t source, int64_t destination) const { return at::_ops::moveaxis_int::call(const_cast\u003cTensor\u0026\u003e(*this), source, destination); } // aten::numpy_T(Tensor(a) self) -\u003e Tensor(a) inline at::Tensor Tensor::numpy_T() const { return at::_ops::numpy_T::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::matrix_H(Tensor(a) self) -\u003e Tensor(a) inline at::Tensor Tensor::matrix_H() const { return at::_ops::matrix_H::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::mT(Tensor(a) self) -\u003e Tensor(a) inline at::Tensor Tensor::mT() const { return at::_ops::mT::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::mH(Tensor(a) self) -\u003e Tensor(a) inline at::Tensor Tensor::mH() const { return at::_ops::mH::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::adjoint(Tensor(a) self) -\u003e Tensor(a) inline at::Tensor Tensor::adjoint() const { return at::_ops::adjoint::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::is_pinned(Tensor self, Device? device=None) -\u003e bool inline bool Tensor::is_pinned(::std::optional\u003cat::Device\u003e device) const { return at::_ops::is_pinned::call(const_cast\u003cTensor\u0026\u003e(*this), device); } // aten::pin_memory(Tensor(a) self, Device? device=None) -\u003e Tensor(a) inline at::Tensor Tensor::pin_memory(::std::optional\u003cat::Device\u003e device) const { return at::_ops::pin_memory::call(const_cast\u003cTensor\u0026\u003e(*this), device); } // aten::pinverse(Tensor self, float rcond=1e-15) -\u003e Tensor inline at::Tensor Tensor::pinverse(double rcond) const { return at::_ops::pinverse::call(const_cast\u003cTensor\u0026\u003e(*this), rcond); } // aten::rad2deg(Tensor self) -\u003e Tensor inline at::Tensor Tensor::rad2deg() const { return at::_ops::rad2deg::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::rad2deg_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::rad2deg_() const { return at::_ops::rad2deg_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::deg2rad(Tensor self) -\u003e Tensor inline at::Tensor Tensor::deg2rad() const { return at::_ops::deg2rad::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::deg2rad_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::deg2rad_() const { return at::_ops::deg2rad_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::ravel(Tensor(a) self) -\u003e Tensor(a) inline at::Tensor Tensor::ravel() const { return at::_ops::ravel::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::reciprocal(Tensor self) -\u003e Tensor inline at::Tensor Tensor::reciprocal() const { return at::_ops::reciprocal::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::reciprocal_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::reciprocal_() const { return at::_ops::reciprocal_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::neg(Tensor self) -\u003e Tensor inline at::Tensor Tensor::neg() const { return at::_ops::neg::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::neg_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::neg_() const { return at::_ops::neg_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::negative(Tensor self) -\u003e Tensor inline at::Tensor Tensor::negative() const { return at::_ops::negative::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::negative_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::negative_() const { return at::_ops::negative_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::repeat(Tensor self, SymInt[] repeats) -\u003e Tensor inline at::Tensor Tensor::repeat(at::IntArrayRef repeats) const { return at::_ops::repeat::call(const_cast\u003cTensor\u0026\u003e(*this), c10::fromIntArrayRefSlow(repeats)); } // aten::repeat(Tensor self, SymInt[] repeats) -\u003e Tensor inline at::Tensor Tensor::repeat_symint(c10::SymIntArrayRef repeats) const { return at::_ops::repeat::call(const_cast\u003cTensor\u0026\u003e(*this), repeats); } // aten::repeat_interleave.self_Tensor(Tensor self, Tensor repeats, int? dim=None, *, SymInt? output_size=None) -\u003e Tensor inline at::Tensor Tensor::repeat_interleave(const at::Tensor \u0026 repeats, ::std::optional\u003cint64_t\u003e dim, ::std::optional\u003cint64_t\u003e output_size) const { return at::_ops::repeat_interleave_self_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), repeats, dim, output_size.has_value() ? ::std::make_optional(c10::SymInt(*output_size)) : ::std::nullopt); } // aten::repeat_interleave.self_Tensor(Tensor self, Tensor repeats, int? dim=None, *, SymInt? output_size=None) -\u003e Tensor inline at::Tensor Tensor::repeat_interleave_symint(const at::Tensor \u0026 repeats, ::std::optional\u003cint64_t\u003e dim, ::std::optional\u003cc10::SymInt\u003e output_size) const { return at::_ops::repeat_interleave_self_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), repeats, dim, output_size); } // aten::repeat_interleave.self_int(Tensor self, SymInt repeats, int? dim=None, *, SymInt? output_size=None) -\u003e Tensor inline at::Tensor Tensor::repeat_interleave(int64_t repeats, ::std::optional\u003cint64_t\u003e dim, ::std::optional\u003cint64_t\u003e output_size) const { return at::_ops::repeat_interleave_self_int::call(const_cast\u003cTensor\u0026\u003e(*this), repeats, dim, output_size.has_value() ? ::std::make_optional(c10::SymInt(*output_size)) : ::std::nullopt); } // aten::repeat_interleave.self_int(Tensor self, SymInt repeats, int? dim=None, *, SymInt? output_size=None) -\u003e Tensor inline at::Tensor Tensor::repeat_interleave_symint(c10::SymInt repeats, ::std::optional\u003cint64_t\u003e dim, ::std::optional\u003cc10::SymInt\u003e output_size) const { return at::_ops::repeat_interleave_self_int::call(const_cast\u003cTensor\u0026\u003e(*this), repeats, dim, output_size); } // aten::reshape(Tensor(a) self, SymInt[] shape) -\u003e Tensor(a) inline at::Tensor Tensor::reshape(at::IntArrayRef shape) const { return at::_ops::reshape::call(const_cast\u003cTensor\u0026\u003e(*this), c10::fromIntArrayRefSlow(shape)); } // aten::reshape(Tensor(a) self, SymInt[] shape) -\u003e Tensor(a) inline at::Tensor Tensor::reshape_symint(c10::SymIntArrayRef shape) const { return at::_ops::reshape::call(const_cast\u003cTensor\u0026\u003e(*this), shape); } // aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -\u003e Tensor(a) inline at::Tensor Tensor::_reshape_alias(at::IntArrayRef size, at::IntArrayRef stride) const { return at::_ops::_reshape_alias::call(const_cast\u003cTensor\u0026\u003e(*this), c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride)); } // aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -\u003e Tensor(a) inline at::Tensor Tensor::_reshape_alias_symint(c10::SymIntArrayRef size, c10::SymIntArrayRef stride) const { return at::_ops::_reshape_alias::call(const_cast\u003cTensor\u0026\u003e(*this), size, stride); } // aten::reshape_as(Tensor(a) self, Tensor other) -\u003e Tensor(a) inline at::Tensor Tensor::reshape_as(const at::Tensor \u0026 other) const { return at::_ops::reshape_as::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::round(Tensor self) -\u003e Tensor inline at::Tensor Tensor::round() const { return at::_ops::round::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::round_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::round_() const { return at::_ops::round_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::round.decimals(Tensor self, *, int decimals) -\u003e Tensor inline at::Tensor Tensor::round(int64_t decimals) const { return at::_ops::round_decimals::call(const_cast\u003cTensor\u0026\u003e(*this), decimals); } // aten::round_.decimals(Tensor(a!) self, *, int decimals) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::round_(int64_t decimals) const { return at::_ops::round__decimals::call(const_cast\u003cTensor\u0026\u003e(*this), decimals); } // aten::relu(Tensor self) -\u003e Tensor inline at::Tensor Tensor::relu() const { return at::_ops::relu::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::relu_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::relu_() const { return at::_ops::relu_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::prelu(Tensor self, Tensor weight) -\u003e Tensor inline at::Tensor Tensor::prelu(const at::Tensor \u0026 weight) const { return at::_ops::prelu::call(const_cast\u003cTensor\u0026\u003e(*this), weight); } // aten::hardshrink(Tensor self, Scalar lambd=0.5) -\u003e Tensor inline at::Tensor Tensor::hardshrink(const at::Scalar \u0026 lambd) const { return at::_ops::hardshrink::call(const_cast\u003cTensor\u0026\u003e(*this), lambd); } // aten::hardshrink_backward(Tensor grad_out, Tensor self, Scalar lambd) -\u003e Tensor inline at::Tensor Tensor::hardshrink_backward(const at::Tensor \u0026 grad_out, const at::Scalar \u0026 lambd) const { return at::_ops::hardshrink_backward::call(grad_out, const_cast\u003cTensor\u0026\u003e(*this), lambd); } // aten::rsqrt(Tensor self) -\u003e Tensor inline at::Tensor Tensor::rsqrt() const { return at::_ops::rsqrt::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::rsqrt_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::rsqrt_() const { return at::_ops::rsqrt_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::select.Dimname(Tensor(a) self, Dimname dim, int index) -\u003e Tensor(a) inline at::Tensor Tensor::select(at::Dimname dim, int64_t index) const { return at::_ops::select_Dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index); } // aten::select.int(Tensor(a) self, int dim, SymInt index) -\u003e Tensor(a) inline at::Tensor Tensor::select(int64_t dim, int64_t index) const { return at::_ops::select_int::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index); } // aten::select.int(Tensor(a) self, int dim, SymInt index) -\u003e Tensor(a) inline at::Tensor Tensor::select_symint(int64_t dim, c10::SymInt index) const { return at::_ops::select_int::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index); } // aten::sigmoid(Tensor self) -\u003e Tensor inline at::Tensor Tensor::sigmoid() const { return at::_ops::sigmoid::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::sigmoid_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::sigmoid_() const { return at::_ops::sigmoid_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::logit(Tensor self, float? eps=None) -\u003e Tensor inline at::Tensor Tensor::logit(::std::optional\u003cdouble\u003e eps) const { return at::_ops::logit::call(const_cast\u003cTensor\u0026\u003e(*this), eps); } // aten::logit_(Tensor(a!) self, float? eps=None) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::logit_(::std::optional\u003cdouble\u003e eps) const { return at::_ops::logit_::call(const_cast\u003cTensor\u0026\u003e(*this), eps); } // aten::sin(Tensor self) -\u003e Tensor inline at::Tensor Tensor::sin() const { return at::_ops::sin::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::sin_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::sin_() const { return at::_ops::sin_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::sinc(Tensor self) -\u003e Tensor inline at::Tensor Tensor::sinc() const { return at::_ops::sinc::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::sinc_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::sinc_() const { return at::_ops::sinc_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::sinh(Tensor self) -\u003e Tensor inline at::Tensor Tensor::sinh() const { return at::_ops::sinh::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::sinh_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::sinh_() const { return at::_ops::sinh_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::detach(Tensor(a) self) -\u003e Tensor(a) inline at::Tensor Tensor::detach() const { return at::_ops::detach::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::detach_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::detach_() const { return at::_ops::detach_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::size.Dimname(Tensor self, Dimname dim) -\u003e int inline int64_t Tensor::size(at::Dimname dim) const { return at::_ops::size_Dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim); } // aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -\u003e Tensor(a) inline at::Tensor Tensor::slice(int64_t dim, ::std::optional\u003cint64_t\u003e start, ::std::optional\u003cint64_t\u003e end, int64_t step) const { return at::_ops::slice_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), dim, start.has_value() ? ::std::make_optional(c10::SymInt(*start)) : ::std::nullopt, end.has_value() ? ::std::make_optional(c10::SymInt(*end)) : ::std::nullopt, step); } // aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -\u003e Tensor(a) inline at::Tensor Tensor::slice_symint(int64_t dim, ::std::optional\u003cc10::SymInt\u003e start, ::std::optional\u003cc10::SymInt\u003e end, c10::SymInt step) const { return at::_ops::slice_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), dim, start, end, step); } // aten::slice_inverse(Tensor(a) self, Tensor src, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -\u003e Tensor(a) inline at::Tensor Tensor::slice_inverse(const at::Tensor \u0026 src, int64_t dim, ::std::optional\u003cint64_t\u003e start, ::std::optional\u003cint64_t\u003e end, int64_t step) const { return at::_ops::slice_inverse::call(const_cast\u003cTensor\u0026\u003e(*this), src, dim, start.has_value() ? ::std::make_optional(c10::SymInt(*start)) : ::std::nullopt, end.has_value() ? ::std::make_optional(c10::SymInt(*end)) : ::std::nullopt, step); } // aten::slice_inverse(Tensor(a) self, Tensor src, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -\u003e Tensor(a) inline at::Tensor Tensor::slice_inverse_symint(const at::Tensor \u0026 src, int64_t dim, ::std::optional\u003cc10::SymInt\u003e start, ::std::optional\u003cc10::SymInt\u003e end, c10::SymInt step) const { return at::_ops::slice_inverse::call(const_cast\u003cTensor\u0026\u003e(*this), src, dim, start, end, step); } // aten::slice_scatter(Tensor self, Tensor src, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -\u003e Tensor inline at::Tensor Tensor::slice_scatter(const at::Tensor \u0026 src, int64_t dim, ::std::optional\u003cint64_t\u003e start, ::std::optional\u003cint64_t\u003e end, int64_t step) const { return at::_ops::slice_scatter::call(const_cast\u003cTensor\u0026\u003e(*this), src, dim, start.has_value() ? ::std::make_optional(c10::SymInt(*start)) : ::std::nullopt, end.has_value() ? ::std::make_optional(c10::SymInt(*end)) : ::std::nullopt, step); } // aten::slice_scatter(Tensor self, Tensor src, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -\u003e Tensor inline at::Tensor Tensor::slice_scatter_symint(const at::Tensor \u0026 src, int64_t dim, ::std::optional\u003cc10::SymInt\u003e start, ::std::optional\u003cc10::SymInt\u003e end, c10::SymInt step) const { return at::_ops::slice_scatter::call(const_cast\u003cTensor\u0026\u003e(*this), src, dim, start, end, step); } // aten::select_scatter(Tensor self, Tensor src, int dim, SymInt index) -\u003e Tensor inline at::Tensor Tensor::select_scatter(const at::Tensor \u0026 src, int64_t dim, int64_t index) const { return at::_ops::select_scatter::call(const_cast\u003cTensor\u0026\u003e(*this), src, dim, index); } // aten::select_scatter(Tensor self, Tensor src, int dim, SymInt index) -\u003e Tensor inline at::Tensor Tensor::select_scatter_symint(const at::Tensor \u0026 src, int64_t dim, c10::SymInt index) const { return at::_ops::select_scatter::call(const_cast\u003cTensor\u0026\u003e(*this), src, dim, index); } // aten::diagonal_scatter(Tensor self, Tensor src, int offset=0, int dim1=0, int dim2=1) -\u003e Tensor inline at::Tensor Tensor::diagonal_scatter(const at::Tensor \u0026 src, int64_t offset, int64_t dim1, int64_t dim2) const { return at::_ops::diagonal_scatter::call(const_cast\u003cTensor\u0026\u003e(*this), src, offset, dim1, dim2); } // aten::as_strided_scatter(Tensor self, Tensor src, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -\u003e Tensor inline at::Tensor Tensor::as_strided_scatter(const at::Tensor \u0026 src, at::IntArrayRef size, at::IntArrayRef stride, ::std::optional\u003cint64_t\u003e storage_offset) const { return at::_ops::as_strided_scatter::call(const_cast\u003cTensor\u0026\u003e(*this), src, c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride), storage_offset.has_value() ? ::std::make_optional(c10::SymInt(*storage_offset)) : ::std::nullopt); } // aten::as_strided_scatter(Tensor self, Tensor src, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -\u003e Tensor inline at::Tensor Tensor::as_strided_scatter_symint(const at::Tensor \u0026 src, c10::SymIntArrayRef size, c10::SymIntArrayRef stride, ::std::optional\u003cc10::SymInt\u003e storage_offset) const { return at::_ops::as_strided_scatter::call(const_cast\u003cTensor\u0026\u003e(*this), src, size, stride, storage_offset); } // aten::smm(Tensor self, Tensor mat2) -\u003e Tensor inline at::Tensor Tensor::smm(const at::Tensor \u0026 mat2) const { return at::_ops::smm::call(const_cast\u003cTensor\u0026\u003e(*this), mat2); } // aten::softmax.int(Tensor self, int dim, ScalarType? dtype=None) -\u003e Tensor inline at::Tensor Tensor::softmax(int64_t dim, ::std::optional\u003cat::ScalarType\u003e dtype) const { return at::_ops::softmax_int::call(const_cast\u003cTensor\u0026\u003e(*this), dim, dtype); } // aten::softmax.Dimname(Tensor self, Dimname dim, *, ScalarType? dtype=None) -\u003e Tensor inline at::Tensor Tensor::softmax(at::Dimname dim, ::std::optional\u003cat::ScalarType\u003e dtype) const { return at::_ops::softmax_Dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim, dtype); } // aten::unsafe_split.Tensor(Tensor self, SymInt split_size, int dim=0) -\u003e Tensor[] inline ::std::vector\u003cat::Tensor\u003e Tensor::unsafe_split(int64_t split_size, int64_t dim) const { return at::_ops::unsafe_split_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), split_size, dim); } // aten::unsafe_split.Tensor(Tensor self, SymInt split_size, int dim=0) -\u003e Tensor[] inline ::std::vector\u003cat::Tensor\u003e Tensor::unsafe_split_symint(c10::SymInt split_size, int64_t dim) const { return at::_ops::unsafe_split_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), split_size, dim); } // aten::split.Tensor(Tensor(a -\u003e *) self, SymInt split_size, int dim=0) -\u003e Tensor(a)[] inline ::std::vector\u003cat::Tensor\u003e Tensor::split(int64_t split_size, int64_t dim) const { return at::_ops::split_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), split_size, dim); } // aten::split.Tensor(Tensor(a -\u003e *) self, SymInt split_size, int dim=0) -\u003e Tensor(a)[] inline ::std::vector\u003cat::Tensor\u003e Tensor::split_symint(c10::SymInt split_size, int64_t dim) const { return at::_ops::split_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), split_size, dim); } // aten::split.sizes(Tensor(a -\u003e *) self, SymInt[] split_size, int dim=0) -\u003e Tensor(a)[] inline ::std::vector\u003cat::Tensor\u003e Tensor::split(at::IntArrayRef split_size, int64_t dim) const { return at::_ops::split_sizes::call(const_cast\u003cTensor\u0026\u003e(*this), c10::fromIntArrayRefSlow(split_size), dim); } // aten::split.sizes(Tensor(a -\u003e *) self, SymInt[] split_size, int dim=0) -\u003e Tensor(a)[] inline ::std::vector\u003cat::Tensor\u003e Tensor::split_symint(c10::SymIntArrayRef split_size, int64_t dim) const { return at::_ops::split_sizes::call(const_cast\u003cTensor\u0026\u003e(*this), split_size, dim); } // aten::unsafe_split_with_sizes(Tensor self, SymInt[] split_sizes, int dim=0) -\u003e Tensor[] inline ::std::vector\u003cat::Tensor\u003e Tensor::unsafe_split_with_sizes(at::IntArrayRef split_sizes, int64_t dim) const { return at::_ops::unsafe_split_with_sizes::call(const_cast\u003cTensor\u0026\u003e(*this), c10::fromIntArrayRefSlow(split_sizes), dim); } // aten::unsafe_split_with_sizes(Tensor self, SymInt[] split_sizes, int dim=0) -\u003e Tensor[] inline ::std::vector\u003cat::Tensor\u003e Tensor::unsafe_split_with_sizes_symint(c10::SymIntArrayRef split_sizes, int64_t dim) const { return at::_ops::unsafe_split_with_sizes::call(const_cast\u003cTensor\u0026\u003e(*this), split_sizes, dim); } // aten::split_with_sizes(Tensor(a -\u003e *) self, SymInt[] split_sizes, int dim=0) -\u003e Tensor(a)[] inline ::std::vector\u003cat::Tensor\u003e Tensor::split_with_sizes(at::IntArrayRef split_sizes, int64_t dim) const { return at::_ops::split_with_sizes::call(const_cast\u003cTensor\u0026\u003e(*this), c10::fromIntArrayRefSlow(split_sizes), dim); } // aten::split_with_sizes(Tensor(a -\u003e *) self, SymInt[] split_sizes, int dim=0) -\u003e Tensor(a)[] inline ::std::vector\u003cat::Tensor\u003e Tensor::split_with_sizes_symint(c10::SymIntArrayRef split_sizes, int64_t dim) const { return at::_ops::split_with_sizes::call(const_cast\u003cTensor\u0026\u003e(*this), split_sizes, dim); } // aten::hsplit.int(Tensor(a -\u003e *) self, int sections) -\u003e Tensor(a)[] inline ::std::vector\u003cat::Tensor\u003e Tensor::hsplit(int64_t sections) const { return at::_ops::hsplit_int::call(const_cast\u003cTensor\u0026\u003e(*this), sections); } // aten::hsplit.array(Tensor(a -\u003e *) self, int[] indices) -\u003e Tensor(a)[] inline ::std::vector\u003cat::Tensor\u003e Tensor::hsplit(at::IntArrayRef indices) const { return at::_ops::hsplit_array::call(const_cast\u003cTensor\u0026\u003e(*this), indices); } // aten::vsplit.int(Tensor(a -\u003e *) self, int sections) -\u003e Tensor(a)[] inline ::std::vector\u003cat::Tensor\u003e Tensor::vsplit(int64_t sections) const { return at::_ops::vsplit_int::call(const_cast\u003cTensor\u0026\u003e(*this), sections); } // aten::vsplit.array(Tensor(a -\u003e *) self, int[] indices) -\u003e Tensor(a)[] inline ::std::vector\u003cat::Tensor\u003e Tensor::vsplit(at::IntArrayRef indices) const { return at::_ops::vsplit_array::call(const_cast\u003cTensor\u0026\u003e(*this), indices); } // aten::dsplit.int(Tensor(a -\u003e *) self, int sections) -\u003e Tensor(a)[] inline ::std::vector\u003cat::Tensor\u003e Tensor::dsplit(int64_t sections) const { return at::_ops::dsplit_int::call(const_cast\u003cTensor\u0026\u003e(*this), sections); } // aten::dsplit.array(Tensor(a -\u003e *) self, int[] indices) -\u003e Tensor(a)[] inline ::std::vector\u003cat::Tensor\u003e Tensor::dsplit(at::IntArrayRef indices) const { return at::_ops::dsplit_array::call(const_cast\u003cTensor\u0026\u003e(*this), indices); } // aten::squeeze(Tensor(a) self) -\u003e Tensor(a) inline at::Tensor Tensor::squeeze() const { return at::_ops::squeeze::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::squeeze.dim(Tensor(a) self, int dim) -\u003e Tensor(a) inline at::Tensor Tensor::squeeze(int64_t dim) const { return at::_ops::squeeze_dim::call(const_cast\u003cTensor\u0026\u003e(*this), dim); } // aten::squeeze.dimname(Tensor(a) self, Dimname dim) -\u003e Tensor(a) inline at::Tensor Tensor::squeeze(at::Dimname dim) const { return at::_ops::squeeze_dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim); } // aten::squeeze.dims(Tensor(a) self, int[] dim) -\u003e Tensor(a) inline at::Tensor Tensor::squeeze(at::IntArrayRef dim) const { return at::_ops::squeeze_dims::call(const_cast\u003cTensor\u0026\u003e(*this), dim); } // aten::squeeze_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::squeeze_() const { return at::_ops::squeeze_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::squeeze_.dim(Tensor(a!) self, int dim) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::squeeze_(int64_t dim) const { return at::_ops::squeeze__dim::call(const_cast\u003cTensor\u0026\u003e(*this), dim); } // aten::squeeze_.dims(Tensor(a!) self, int[] dim) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::squeeze_(at::IntArrayRef dim) const { return at::_ops::squeeze__dims::call(const_cast\u003cTensor\u0026\u003e(*this), dim); } // aten::squeeze_.dimname(Tensor(a!) self, Dimname dim) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::squeeze_(at::Dimname dim) const { return at::_ops::squeeze__dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim); } // aten::sspaddmm(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1) -\u003e Tensor inline at::Tensor Tensor::sspaddmm(const at::Tensor \u0026 mat1, const at::Tensor \u0026 mat2, const at::Scalar \u0026 beta, const at::Scalar \u0026 alpha) const { return at::_ops::sspaddmm::call(const_cast\u003cTensor\u0026\u003e(*this), mat1, mat2, beta, alpha); } // aten::stft(Tensor self, int n_fft, int? hop_length=None, int? win_length=None, Tensor? window=None, bool normalized=False, bool? onesided=None, bool? return_complex=None, bool? align_to_window=None) -\u003e Tensor inline at::Tensor Tensor::stft(int64_t n_fft, ::std::optional\u003cint64_t\u003e hop_length, ::std::optional\u003cint64_t\u003e win_length, const ::std::optional\u003cat::Tensor\u003e \u0026 window, bool normalized, ::std::optional\u003cbool\u003e onesided, ::std::optional\u003cbool\u003e return_complex, ::std::optional\u003cbool\u003e align_to_window) const { return at::_ops::stft::call(const_cast\u003cTensor\u0026\u003e(*this), n_fft, hop_length, win_length, window, normalized, onesided, return_complex, align_to_window); } // aten::stft.center(Tensor self, int n_fft, int? hop_length=None, int? win_length=None, Tensor? window=None, bool center=True, str pad_mode=\"reflect\", bool normalized=False, bool? onesided=None, bool? return_complex=None, bool? align_to_window=None) -\u003e Tensor inline at::Tensor Tensor::stft(int64_t n_fft, ::std::optional\u003cint64_t\u003e hop_length, ::std::optional\u003cint64_t\u003e win_length, const ::std::optional\u003cat::Tensor\u003e \u0026 window, bool center, c10::string_view pad_mode, bool normalized, ::std::optional\u003cbool\u003e onesided, ::std::optional\u003cbool\u003e return_complex, ::std::optional\u003cbool\u003e align_to_window) const { return at::_ops::stft_center::call(const_cast\u003cTensor\u0026\u003e(*this), n_fft, hop_length, win_length, window, center, pad_mode, normalized, onesided, return_complex, align_to_window); } // aten::istft(Tensor self, int n_fft, int? hop_length=None, int? win_length=None, Tensor? window=None, bool center=True, bool normalized=False, bool? onesided=None, int? length=None, bool return_complex=False) -\u003e Tensor inline at::Tensor Tensor::istft(int64_t n_fft, ::std::optional\u003cint64_t\u003e hop_length, ::std::optional\u003cint64_t\u003e win_length, const ::std::optional\u003cat::Tensor\u003e \u0026 window, bool center, bool normalized, ::std::optional\u003cbool\u003e onesided, ::std::optional\u003cint64_t\u003e length, bool return_complex) const { return at::_ops::istft::call(const_cast\u003cTensor\u0026\u003e(*this), n_fft, hop_length, win_length, window, center, normalized, onesided, length, return_complex); } // aten::stride.Dimname(Tensor self, Dimname dim) -\u003e int inline int64_t Tensor::stride(at::Dimname dim) const { return at::_ops::stride_Dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim); } // aten::sum(Tensor self, *, ScalarType? dtype=None) -\u003e Tensor inline at::Tensor Tensor::sum(::std::optional\u003cat::ScalarType\u003e dtype) const { return at::_ops::sum::call(const_cast\u003cTensor\u0026\u003e(*this), dtype); } // aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -\u003e Tensor inline at::Tensor Tensor::sum(at::OptionalIntArrayRef dim, bool keepdim, ::std::optional\u003cat::ScalarType\u003e dtype) const { return at::_ops::sum_dim_IntList::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim, dtype); } // aten::sum.dim_DimnameList(Tensor self, Dimname[1] dim, bool keepdim=False, *, ScalarType? dtype=None) -\u003e Tensor inline at::Tensor Tensor::sum(at::DimnameList dim, bool keepdim, ::std::optional\u003cat::ScalarType\u003e dtype) const { return at::_ops::sum_dim_DimnameList::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim, dtype); } // aten::nansum(Tensor self, int[1]? dim=None, bool keepdim=False, *, ScalarType? dtype=None) -\u003e Tensor inline at::Tensor Tensor::nansum(at::OptionalIntArrayRef dim, bool keepdim, ::std::optional\u003cat::ScalarType\u003e dtype) const { return at::_ops::nansum::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim, dtype); } // aten::hash_tensor(Tensor self, int[1] dim=[], *, bool keepdim=False, int mode=0) -\u003e Tensor inline at::Tensor Tensor::hash_tensor(at::IntArrayRef dim, bool keepdim, int64_t mode) const { return at::_ops::hash_tensor::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim, mode); } // aten::sum_to_size(Tensor self, SymInt[] size) -\u003e Tensor inline at::Tensor Tensor::sum_to_size(at::IntArrayRef size) const { return at::_ops::sum_to_size::call(const_cast\u003cTensor\u0026\u003e(*this), c10::fromIntArrayRefSlow(size)); } // aten::sum_to_size(Tensor self, SymInt[] size) -\u003e Tensor inline at::Tensor Tensor::sum_to_size_symint(c10::SymIntArrayRef size) const { return at::_ops::sum_to_size::call(const_cast\u003cTensor\u0026\u003e(*this), size); } // aten::sqrt(Tensor self) -\u003e Tensor inline at::Tensor Tensor::sqrt() const { return at::_ops::sqrt::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::sqrt_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::sqrt_() const { return at::_ops::sqrt_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::square(Tensor self) -\u003e Tensor inline at::Tensor Tensor::square() const { return at::_ops::square::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::square_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::square_() const { return at::_ops::square_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::std(Tensor self, bool unbiased=True) -\u003e Tensor inline at::Tensor Tensor::std(bool unbiased) const { return at::_ops::std::call(const_cast\u003cTensor\u0026\u003e(*this), unbiased); } // aten::std.dim(Tensor self, int[1]? dim, bool unbiased=True, bool keepdim=False) -\u003e Tensor inline at::Tensor Tensor::std(at::OptionalIntArrayRef dim, bool unbiased, bool keepdim) const { return at::_ops::std_dim::call(const_cast\u003cTensor\u0026\u003e(*this), dim, unbiased, keepdim); } // aten::std.correction(Tensor self, int[1]? dim=None, *, Scalar? correction=None, bool keepdim=False) -\u003e Tensor inline at::Tensor Tensor::std(at::OptionalIntArrayRef dim, const ::std::optional\u003cat::Scalar\u003e \u0026 correction, bool keepdim) const { return at::_ops::std_correction::call(const_cast\u003cTensor\u0026\u003e(*this), dim, correction, keepdim); } // aten::std.names_dim(Tensor self, Dimname[1] dim, bool unbiased=True, bool keepdim=False) -\u003e Tensor inline at::Tensor Tensor::std(at::DimnameList dim, bool unbiased, bool keepdim) const { return at::_ops::std_names_dim::call(const_cast\u003cTensor\u0026\u003e(*this), dim, unbiased, keepdim); } // aten::std.correction_names(Tensor self, Dimname[1] dim, *, Scalar? correction=None, bool keepdim=False) -\u003e Tensor inline at::Tensor Tensor::std(at::DimnameList dim, const ::std::optional\u003cat::Scalar\u003e \u0026 correction, bool keepdim) const { return at::_ops::std_correction_names::call(const_cast\u003cTensor\u0026\u003e(*this), dim, correction, keepdim); } // aten::prod(Tensor self, *, ScalarType? dtype=None) -\u003e Tensor inline at::Tensor Tensor::prod(::std::optional\u003cat::ScalarType\u003e dtype) const { return at::_ops::prod::call(const_cast\u003cTensor\u0026\u003e(*this), dtype); } // aten::prod.dim_int(Tensor self, int dim, bool keepdim=False, *, ScalarType? dtype=None) -\u003e Tensor inline at::Tensor Tensor::prod(int64_t dim, bool keepdim, ::std::optional\u003cat::ScalarType\u003e dtype) const { return at::_ops::prod_dim_int::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim, dtype); } // aten::prod.dim_Dimname(Tensor self, Dimname dim, bool keepdim=False, *, ScalarType? dtype=None) -\u003e Tensor inline at::Tensor Tensor::prod(at::Dimname dim, bool keepdim, ::std::optional\u003cat::ScalarType\u003e dtype) const { return at::_ops::prod_dim_Dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim, keepdim, dtype); } // aten::t(Tensor(a) self) -\u003e Tensor(a) inline at::Tensor Tensor::t() const { return at::_ops::t::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::t_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::t_() const { return at::_ops::t_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::tan(Tensor self) -\u003e Tensor inline at::Tensor Tensor::tan() const { return at::_ops::tan::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::tan_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::tan_() const { return at::_ops::tan_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::tanh(Tensor self) -\u003e Tensor inline at::Tensor Tensor::tanh() const { return at::_ops::tanh::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::tanh_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::tanh_() const { return at::_ops::tanh_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::tile(Tensor self, SymInt[] dims) -\u003e Tensor inline at::Tensor Tensor::tile(at::IntArrayRef dims) const { return at::_ops::tile::call(const_cast\u003cTensor\u0026\u003e(*this), c10::fromIntArrayRefSlow(dims)); } // aten::tile(Tensor self, SymInt[] dims) -\u003e Tensor inline at::Tensor Tensor::tile_symint(c10::SymIntArrayRef dims) const { return at::_ops::tile::call(const_cast\u003cTensor\u0026\u003e(*this), dims); } // aten::transpose.int(Tensor(a) self, int dim0, int dim1) -\u003e Tensor(a) inline at::Tensor Tensor::transpose(int64_t dim0, int64_t dim1) const { return at::_ops::transpose_int::call(const_cast\u003cTensor\u0026\u003e(*this), dim0, dim1); } // aten::transpose.Dimname(Tensor(a) self, Dimname dim0, Dimname dim1) -\u003e Tensor(a) inline at::Tensor Tensor::transpose(at::Dimname dim0, at::Dimname dim1) const { return at::_ops::transpose_Dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim0, dim1); } // aten::transpose_(Tensor(a!) self, int dim0, int dim1) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::transpose_(int64_t dim0, int64_t dim1) const { return at::_ops::transpose_::call(const_cast\u003cTensor\u0026\u003e(*this), dim0, dim1); } // aten::flip(Tensor self, int[] dims) -\u003e Tensor inline at::Tensor Tensor::flip(at::IntArrayRef dims) const { return at::_ops::flip::call(const_cast\u003cTensor\u0026\u003e(*this), dims); } // aten::fliplr(Tensor self) -\u003e Tensor inline at::Tensor Tensor::fliplr() const { return at::_ops::fliplr::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::flipud(Tensor self) -\u003e Tensor inline at::Tensor Tensor::flipud() const { return at::_ops::flipud::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::roll(Tensor self, SymInt[1] shifts, int[1] dims=[]) -\u003e Tensor inline at::Tensor Tensor::roll(at::IntArrayRef shifts, at::IntArrayRef dims) const { return at::_ops::roll::call(const_cast\u003cTensor\u0026\u003e(*this), c10::fromIntArrayRefSlow(shifts), dims); } // aten::roll(Tensor self, SymInt[1] shifts, int[1] dims=[]) -\u003e Tensor inline at::Tensor Tensor::roll_symint(c10::SymIntArrayRef shifts, at::IntArrayRef dims) const { return at::_ops::roll::call(const_cast\u003cTensor\u0026\u003e(*this), shifts, dims); } // aten::rot90(Tensor self, int k=1, int[] dims=[0,1]) -\u003e Tensor inline at::Tensor Tensor::rot90(int64_t k, at::IntArrayRef dims) const { return at::_ops::rot90::call(const_cast\u003cTensor\u0026\u003e(*this), k, dims); } // aten::_nested_tensor_size(Tensor self) -\u003e Tensor inline at::Tensor Tensor::_nested_tensor_size() const { return at::_ops::_nested_tensor_size::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::_nested_tensor_strides(Tensor self) -\u003e Tensor inline at::Tensor Tensor::_nested_tensor_strides() const { return at::_ops::_nested_tensor_strides::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::_nested_tensor_storage_offsets(Tensor self) -\u003e Tensor inline at::Tensor Tensor::_nested_tensor_storage_offsets() const { return at::_ops::_nested_tensor_storage_offsets::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::trunc(Tensor self) -\u003e Tensor inline at::Tensor Tensor::trunc() const { return at::_ops::trunc::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::trunc_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::trunc_() const { return at::_ops::trunc_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::fix(Tensor self) -\u003e Tensor inline at::Tensor Tensor::fix() const { return at::_ops::fix::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::fix_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::fix_() const { return at::_ops::fix_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::type_as(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::type_as(const at::Tensor \u0026 other) const { return at::_ops::type_as::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::unsqueeze(Tensor(a) self, int dim) -\u003e Tensor(a) inline at::Tensor Tensor::unsqueeze(int64_t dim) const { return at::_ops::unsqueeze::call(const_cast\u003cTensor\u0026\u003e(*this), dim); } // aten::unsqueeze_(Tensor(a!) self, int dim) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::unsqueeze_(int64_t dim) const { return at::_ops::unsqueeze_::call(const_cast\u003cTensor\u0026\u003e(*this), dim); } // aten::var(Tensor self, bool unbiased=True) -\u003e Tensor inline at::Tensor Tensor::var(bool unbiased) const { return at::_ops::var::call(const_cast\u003cTensor\u0026\u003e(*this), unbiased); } // aten::var.dim(Tensor self, int[1]? dim, bool unbiased=True, bool keepdim=False) -\u003e Tensor inline at::Tensor Tensor::var(at::OptionalIntArrayRef dim, bool unbiased, bool keepdim) const { return at::_ops::var_dim::call(const_cast\u003cTensor\u0026\u003e(*this), dim, unbiased, keepdim); } // aten::var.correction(Tensor self, int[1]? dim=None, *, Scalar? correction=None, bool keepdim=False) -\u003e Tensor inline at::Tensor Tensor::var(at::OptionalIntArrayRef dim, const ::std::optional\u003cat::Scalar\u003e \u0026 correction, bool keepdim) const { return at::_ops::var_correction::call(const_cast\u003cTensor\u0026\u003e(*this), dim, correction, keepdim); } // aten::var.names_dim(Tensor self, Dimname[1] dim, bool unbiased=True, bool keepdim=False) -\u003e Tensor inline at::Tensor Tensor::var(at::DimnameList dim, bool unbiased, bool keepdim) const { return at::_ops::var_names_dim::call(const_cast\u003cTensor\u0026\u003e(*this), dim, unbiased, keepdim); } // aten::var.correction_names(Tensor self, Dimname[1] dim, *, Scalar? correction=None, bool keepdim=False) -\u003e Tensor inline at::Tensor Tensor::var(at::DimnameList dim, const ::std::optional\u003cat::Scalar\u003e \u0026 correction, bool keepdim) const { return at::_ops::var_correction_names::call(const_cast\u003cTensor\u0026\u003e(*this), dim, correction, keepdim); } // aten::view_as(Tensor(a) self, Tensor other) -\u003e Tensor(a) inline at::Tensor Tensor::view_as(const at::Tensor \u0026 other) const { return at::_ops::view_as::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::where.self(Tensor condition, Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::where(const at::Tensor \u0026 condition, const at::Tensor \u0026 other) const { return at::_ops::where_self::call(condition, const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::where.ScalarOther(Tensor condition, Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::where(const at::Tensor \u0026 condition, const at::Scalar \u0026 other) const { return at::_ops::where_ScalarOther::call(condition, const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::norm.ScalarOpt_dtype(Tensor self, Scalar? p, *, ScalarType dtype) -\u003e Tensor inline at::Tensor Tensor::norm(const ::std::optional\u003cat::Scalar\u003e \u0026 p, at::ScalarType dtype) const { return at::_ops::norm_ScalarOpt_dtype::call(const_cast\u003cTensor\u0026\u003e(*this), p, dtype); } // aten::norm.Scalar(Tensor self, Scalar p=2) -\u003e Tensor inline at::Tensor Tensor::norm(const at::Scalar \u0026 p) const { return at::_ops::norm_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), p); } // aten::norm.ScalarOpt_dim_dtype(Tensor self, Scalar? p, int[1] dim, bool keepdim, *, ScalarType dtype) -\u003e Tensor inline at::Tensor Tensor::norm(const ::std::optional\u003cat::Scalar\u003e \u0026 p, at::IntArrayRef dim, bool keepdim, at::ScalarType dtype) const { return at::_ops::norm_ScalarOpt_dim_dtype::call(const_cast\u003cTensor\u0026\u003e(*this), p, dim, keepdim, dtype); } // aten::norm.ScalarOpt_dim(Tensor self, Scalar? p, int[1] dim, bool keepdim=False) -\u003e Tensor inline at::Tensor Tensor::norm(const ::std::optional\u003cat::Scalar\u003e \u0026 p, at::IntArrayRef dim, bool keepdim) const { return at::_ops::norm_ScalarOpt_dim::call(const_cast\u003cTensor\u0026\u003e(*this), p, dim, keepdim); } // aten::norm.names_ScalarOpt_dim_dtype(Tensor self, Scalar? p, Dimname[1] dim, bool keepdim, *, ScalarType dtype) -\u003e Tensor inline at::Tensor Tensor::norm(const ::std::optional\u003cat::Scalar\u003e \u0026 p, at::DimnameList dim, bool keepdim, at::ScalarType dtype) const { return at::_ops::norm_names_ScalarOpt_dim_dtype::call(const_cast\u003cTensor\u0026\u003e(*this), p, dim, keepdim, dtype); } // aten::norm.names_ScalarOpt_dim(Tensor self, Scalar? p, Dimname[1] dim, bool keepdim=False) -\u003e Tensor inline at::Tensor Tensor::norm(const ::std::optional\u003cat::Scalar\u003e \u0026 p, at::DimnameList dim, bool keepdim) const { return at::_ops::norm_names_ScalarOpt_dim::call(const_cast\u003cTensor\u0026\u003e(*this), p, dim, keepdim); } // aten::frexp.Tensor(Tensor self) -\u003e (Tensor mantissa, Tensor exponent) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::frexp() const { return at::_ops::frexp_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -\u003e Tensor inline at::Tensor Tensor::clone(::std::optional\u003cat::MemoryFormat\u003e memory_format) const { return at::_ops::clone::call(const_cast\u003cTensor\u0026\u003e(*this), memory_format); } // aten::positive(Tensor(a) self) -\u003e Tensor(a) inline at::Tensor Tensor::positive() const { return at::_ops::positive::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::resize_as_(Tensor(a!) self, Tensor the_template, *, MemoryFormat? memory_format=None) -\u003e Tensor(a!) inline const at::Tensor \u0026 Tensor::resize_as_(const at::Tensor \u0026 the_template, ::std::optional\u003cat::MemoryFormat\u003e memory_format) const { return at::_ops::resize_as_::call(const_cast\u003cTensor\u0026\u003e(*this), the_template, memory_format); } // aten::resize_as_sparse_(Tensor(a!) self, Tensor the_template) -\u003e Tensor(a!) inline const at::Tensor \u0026 Tensor::resize_as_sparse_(const at::Tensor \u0026 the_template) const { return at::_ops::resize_as_sparse_::call(const_cast\u003cTensor\u0026\u003e(*this), the_template); } // aten::zero_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::zero_() const { return at::_ops::zero_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::sub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -\u003e Tensor inline at::Tensor Tensor::sub(const at::Tensor \u0026 other, const at::Scalar \u0026 alpha) const { return at::_ops::sub_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other, alpha); } // aten::sub_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::sub_(const at::Tensor \u0026 other, const at::Scalar \u0026 alpha) const { return at::_ops::sub__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other, alpha); } // aten::sub.Scalar(Tensor self, Scalar other, Scalar alpha=1) -\u003e Tensor inline at::Tensor Tensor::sub(const at::Scalar \u0026 other, const at::Scalar \u0026 alpha) const { return at::_ops::sub_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other, alpha); } // aten::sub_.Scalar(Tensor(a!) self, Scalar other, Scalar alpha=1) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::sub_(const at::Scalar \u0026 other, const at::Scalar \u0026 alpha) const { return at::_ops::sub__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other, alpha); } // aten::subtract.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -\u003e Tensor inline at::Tensor Tensor::subtract(const at::Tensor \u0026 other, const at::Scalar \u0026 alpha) const { return at::_ops::subtract_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other, alpha); } // aten::subtract_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::subtract_(const at::Tensor \u0026 other, const at::Scalar \u0026 alpha) const { return at::_ops::subtract__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other, alpha); } // aten::subtract.Scalar(Tensor self, Scalar other, Scalar alpha=1) -\u003e Tensor inline at::Tensor Tensor::subtract(const at::Scalar \u0026 other, const at::Scalar \u0026 alpha) const { return at::_ops::subtract_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other, alpha); } // aten::subtract_.Scalar(Tensor(a!) self, Scalar other, Scalar alpha=1) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::subtract_(const at::Scalar \u0026 other, const at::Scalar \u0026 alpha) const { return at::_ops::subtract__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other, alpha); } // aten::heaviside(Tensor self, Tensor values) -\u003e Tensor inline at::Tensor Tensor::heaviside(const at::Tensor \u0026 values) const { return at::_ops::heaviside::call(const_cast\u003cTensor\u0026\u003e(*this), values); } // aten::heaviside_(Tensor(a!) self, Tensor values) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::heaviside_(const at::Tensor \u0026 values) const { return at::_ops::heaviside_::call(const_cast\u003cTensor\u0026\u003e(*this), values); } // aten::addmm(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1) -\u003e Tensor inline at::Tensor Tensor::addmm(const at::Tensor \u0026 mat1, const at::Tensor \u0026 mat2, const at::Scalar \u0026 beta, const at::Scalar \u0026 alpha) const { return at::_ops::addmm::call(const_cast\u003cTensor\u0026\u003e(*this), mat1, mat2, beta, alpha); } // aten::addmm_(Tensor(a!) self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::addmm_(const at::Tensor \u0026 mat1, const at::Tensor \u0026 mat2, const at::Scalar \u0026 beta, const at::Scalar \u0026 alpha) const { return at::_ops::addmm_::call(const_cast\u003cTensor\u0026\u003e(*this), mat1, mat2, beta, alpha); } // aten::_addmm_activation(Tensor self, Tensor mat1, Tensor mat2, *, Scalar beta=1, Scalar alpha=1, bool use_gelu=False) -\u003e Tensor inline at::Tensor Tensor::_addmm_activation(const at::Tensor \u0026 mat1, const at::Tensor \u0026 mat2, const at::Scalar \u0026 beta, const at::Scalar \u0026 alpha, bool use_gelu) const { return at::_ops::_addmm_activation::call(const_cast\u003cTensor\u0026\u003e(*this), mat1, mat2, beta, alpha, use_gelu); } // aten::sparse_resize_(Tensor(a!) self, int[] size, int sparse_dim, int dense_dim) -\u003e Tensor(a!) inline const at::Tensor \u0026 Tensor::sparse_resize_(at::IntArrayRef size, int64_t sparse_dim, int64_t dense_dim) const { return at::_ops::sparse_resize_::call(const_cast\u003cTensor\u0026\u003e(*this), size, sparse_dim, dense_dim); } // aten::sparse_resize_and_clear_(Tensor(a!) self, int[] size, int sparse_dim, int dense_dim) -\u003e Tensor(a!) inline const at::Tensor \u0026 Tensor::sparse_resize_and_clear_(at::IntArrayRef size, int64_t sparse_dim, int64_t dense_dim) const { return at::_ops::sparse_resize_and_clear_::call(const_cast\u003cTensor\u0026\u003e(*this), size, sparse_dim, dense_dim); } // aten::sparse_mask(Tensor self, Tensor mask) -\u003e Tensor inline at::Tensor Tensor::sparse_mask(const at::Tensor \u0026 mask) const { return at::_ops::sparse_mask::call(const_cast\u003cTensor\u0026\u003e(*this), mask); } // aten::_sparse_mask_projection(Tensor self, Tensor mask, bool accumulate_matches=False) -\u003e Tensor inline at::Tensor Tensor::_sparse_mask_projection(const at::Tensor \u0026 mask, bool accumulate_matches) const { return at::_ops::_sparse_mask_projection::call(const_cast\u003cTensor\u0026\u003e(*this), mask, accumulate_matches); } // aten::to_dense(Tensor self, ScalarType? dtype=None, *, bool? masked_grad=None) -\u003e Tensor inline at::Tensor Tensor::to_dense(::std::optional\u003cat::ScalarType\u003e dtype, ::std::optional\u003cbool\u003e masked_grad) const { return at::_ops::to_dense::call(const_cast\u003cTensor\u0026\u003e(*this), dtype, masked_grad); } // aten::_to_dense(Tensor self, ScalarType? dtype=None, bool? masked_grad=None) -\u003e Tensor inline at::Tensor Tensor::_to_dense(::std::optional\u003cat::ScalarType\u003e dtype, ::std::optional\u003cbool\u003e masked_grad) const { return at::_ops::_to_dense::call(const_cast\u003cTensor\u0026\u003e(*this), dtype, masked_grad); } // aten::sparse_dim(Tensor self) -\u003e int inline int64_t Tensor::sparse_dim() const { return at::_ops::sparse_dim::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::_dimI(Tensor self) -\u003e int inline int64_t Tensor::_dimI() const { return at::_ops::_dimI::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::dense_dim(Tensor self) -\u003e int inline int64_t Tensor::dense_dim() const { return at::_ops::dense_dim::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::_dimV(Tensor self) -\u003e int inline int64_t Tensor::_dimV() const { return at::_ops::_dimV::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::_nnz(Tensor self) -\u003e int inline int64_t Tensor::_nnz() const { return at::_ops::_nnz::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::coalesce(Tensor(a) self) -\u003e Tensor(a) inline at::Tensor Tensor::coalesce() const { return at::_ops::coalesce::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::is_coalesced(Tensor self) -\u003e bool inline bool Tensor::is_coalesced() const { return at::_ops::is_coalesced::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::_indices(Tensor(a) self) -\u003e Tensor(a) inline at::Tensor Tensor::_indices() const { return at::_ops::_indices::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::_values(Tensor(a) self) -\u003e Tensor(a) inline at::Tensor Tensor::_values() const { return at::_ops::_values::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::_coalesced_(Tensor(a!) self, bool coalesced) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::_coalesced_(bool coalesced) const { return at::_ops::_coalesced_::call(const_cast\u003cTensor\u0026\u003e(*this), coalesced); } // aten::indices(Tensor(a) self) -\u003e Tensor(a) inline at::Tensor Tensor::indices() const { return at::_ops::indices::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::values(Tensor(a) self) -\u003e Tensor(a) inline at::Tensor Tensor::values() const { return at::_ops::values::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::crow_indices(Tensor(a) self) -\u003e Tensor(a) inline at::Tensor Tensor::crow_indices() const { return at::_ops::crow_indices::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::col_indices(Tensor(a) self) -\u003e Tensor(a) inline at::Tensor Tensor::col_indices() const { return at::_ops::col_indices::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::ccol_indices(Tensor(a) self) -\u003e Tensor(a) inline at::Tensor Tensor::ccol_indices() const { return at::_ops::ccol_indices::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::row_indices(Tensor(a) self) -\u003e Tensor(a) inline at::Tensor Tensor::row_indices() const { return at::_ops::row_indices::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::unbind.int(Tensor(a -\u003e *) self, int dim=0) -\u003e Tensor(a)[] inline ::std::vector\u003cat::Tensor\u003e Tensor::unbind(int64_t dim) const { return at::_ops::unbind_int::call(const_cast\u003cTensor\u0026\u003e(*this), dim); } // aten::unbind.Dimname(Tensor(a -\u003e *) self, Dimname dim) -\u003e Tensor(a)[] inline ::std::vector\u003cat::Tensor\u003e Tensor::unbind(at::Dimname dim) const { return at::_ops::unbind_Dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim); } // aten::to_sparse.sparse_dim(Tensor self, int sparse_dim) -\u003e Tensor inline at::Tensor Tensor::to_sparse(int64_t sparse_dim) const { return at::_ops::to_sparse_sparse_dim::call(const_cast\u003cTensor\u0026\u003e(*this), sparse_dim); } // aten::_to_sparse.sparse_dim(Tensor self, int sparse_dim) -\u003e Tensor inline at::Tensor Tensor::_to_sparse(int64_t sparse_dim) const { return at::_ops::_to_sparse_sparse_dim::call(const_cast\u003cTensor\u0026\u003e(*this), sparse_dim); } // aten::to_sparse(Tensor self, *, Layout? layout=None, int[2]? blocksize=None, int? dense_dim=None) -\u003e Tensor inline at::Tensor Tensor::to_sparse(::std::optional\u003cat::Layout\u003e layout, at::OptionalIntArrayRef blocksize, ::std::optional\u003cint64_t\u003e dense_dim) const { return at::_ops::to_sparse::call(const_cast\u003cTensor\u0026\u003e(*this), layout, blocksize, dense_dim); } // aten::_to_sparse(Tensor self, *, Layout? layout=None, int[2]? blocksize=None, int? dense_dim=None) -\u003e Tensor inline at::Tensor Tensor::_to_sparse(::std::optional\u003cat::Layout\u003e layout, at::OptionalIntArrayRef blocksize, ::std::optional\u003cint64_t\u003e dense_dim) const { return at::_ops::_to_sparse::call(const_cast\u003cTensor\u0026\u003e(*this), layout, blocksize, dense_dim); } // aten::to_sparse_csr(Tensor self, int? dense_dim=None) -\u003e Tensor inline at::Tensor Tensor::to_sparse_csr(::std::optional\u003cint64_t\u003e dense_dim) const { return at::_ops::to_sparse_csr::call(const_cast\u003cTensor\u0026\u003e(*this), dense_dim); } // aten::_to_sparse_csr(Tensor self, int? dense_dim=None) -\u003e Tensor inline at::Tensor Tensor::_to_sparse_csr(::std::optional\u003cint64_t\u003e dense_dim) const { return at::_ops::_to_sparse_csr::call(const_cast\u003cTensor\u0026\u003e(*this), dense_dim); } // aten::to_sparse_csc(Tensor self, int? dense_dim=None) -\u003e Tensor inline at::Tensor Tensor::to_sparse_csc(::std::optional\u003cint64_t\u003e dense_dim) const { return at::_ops::to_sparse_csc::call(const_cast\u003cTensor\u0026\u003e(*this), dense_dim); } // aten::_to_sparse_csc(Tensor self, int? dense_dim=None) -\u003e Tensor inline at::Tensor Tensor::_to_sparse_csc(::std::optional\u003cint64_t\u003e dense_dim) const { return at::_ops::_to_sparse_csc::call(const_cast\u003cTensor\u0026\u003e(*this), dense_dim); } // aten::to_sparse_bsr(Tensor self, int[2] blocksize, int? dense_dim=None) -\u003e Tensor inline at::Tensor Tensor::to_sparse_bsr(at::IntArrayRef blocksize, ::std::optional\u003cint64_t\u003e dense_dim) const { return at::_ops::to_sparse_bsr::call(const_cast\u003cTensor\u0026\u003e(*this), blocksize, dense_dim); } // aten::_to_sparse_bsr(Tensor self, int[2] blocksize, int? dense_dim=None) -\u003e Tensor inline at::Tensor Tensor::_to_sparse_bsr(at::IntArrayRef blocksize, ::std::optional\u003cint64_t\u003e dense_dim) const { return at::_ops::_to_sparse_bsr::call(const_cast\u003cTensor\u0026\u003e(*this), blocksize, dense_dim); } // aten::to_sparse_bsc(Tensor self, int[2] blocksize, int? dense_dim=None) -\u003e Tensor inline at::Tensor Tensor::to_sparse_bsc(at::IntArrayRef blocksize, ::std::optional\u003cint64_t\u003e dense_dim) const { return at::_ops::to_sparse_bsc::call(const_cast\u003cTensor\u0026\u003e(*this), blocksize, dense_dim); } // aten::_to_sparse_bsc(Tensor self, int[2] blocksize, int? dense_dim=None) -\u003e Tensor inline at::Tensor Tensor::_to_sparse_bsc(at::IntArrayRef blocksize, ::std::optional\u003cint64_t\u003e dense_dim) const { return at::_ops::_to_sparse_bsc::call(const_cast\u003cTensor\u0026\u003e(*this), blocksize, dense_dim); } // aten::to_mkldnn(Tensor self, ScalarType? dtype=None) -\u003e Tensor inline at::Tensor Tensor::to_mkldnn(::std::optional\u003cat::ScalarType\u003e dtype) const { return at::_ops::to_mkldnn::call(const_cast\u003cTensor\u0026\u003e(*this), dtype); } // aten::dequantize.self(Tensor self) -\u003e Tensor inline at::Tensor Tensor::dequantize() const { return at::_ops::dequantize_self::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::q_scale(Tensor self) -\u003e float inline double Tensor::q_scale() const { return at::_ops::q_scale::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::q_zero_point(Tensor self) -\u003e int inline int64_t Tensor::q_zero_point() const { return at::_ops::q_zero_point::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::q_per_channel_scales(Tensor self) -\u003e Tensor inline at::Tensor Tensor::q_per_channel_scales() const { return at::_ops::q_per_channel_scales::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::q_per_channel_zero_points(Tensor self) -\u003e Tensor inline at::Tensor Tensor::q_per_channel_zero_points() const { return at::_ops::q_per_channel_zero_points::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::q_per_channel_axis(Tensor self) -\u003e int inline int64_t Tensor::q_per_channel_axis() const { return at::_ops::q_per_channel_axis::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::int_repr(Tensor self) -\u003e Tensor inline at::Tensor Tensor::int_repr() const { return at::_ops::int_repr::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::qscheme(Tensor self) -\u003e QScheme inline at::QScheme Tensor::qscheme() const { return at::_ops::qscheme::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::_autocast_to_reduced_precision(Tensor(a) self, bool cuda_enabled, bool cpu_enabled, ScalarType cuda_dtype, ScalarType cpu_dtype) -\u003e Tensor(a) inline at::Tensor Tensor::_autocast_to_reduced_precision(bool cuda_enabled, bool cpu_enabled, at::ScalarType cuda_dtype, at::ScalarType cpu_dtype) const { return at::_ops::_autocast_to_reduced_precision::call(const_cast\u003cTensor\u0026\u003e(*this), cuda_enabled, cpu_enabled, cuda_dtype, cpu_dtype); } // aten::_autocast_to_full_precision(Tensor(a) self, bool cuda_enabled, bool cpu_enabled) -\u003e Tensor(a) inline at::Tensor Tensor::_autocast_to_full_precision(bool cuda_enabled, bool cpu_enabled) const { return at::_ops::_autocast_to_full_precision::call(const_cast\u003cTensor\u0026\u003e(*this), cuda_enabled, cpu_enabled); } // aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -\u003e Tensor(a) inline at::Tensor Tensor::to(at::TensorOptions options, bool non_blocking, bool copy, ::std::optional\u003cat::MemoryFormat\u003e memory_format) const { return at::_ops::to_dtype_layout::call(const_cast\u003cTensor\u0026\u003e(*this), c10::optTypeMetaToScalarType(options.dtype_opt()), options.layout_opt(), options.device_opt(), options.pinned_memory_opt(), non_blocking, copy, c10::impl::check_tensor_options_and_extract_memory_format(options, memory_format)); } // aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -\u003e Tensor(a) inline at::Tensor Tensor::to(::std::optional\u003cat::ScalarType\u003e dtype, ::std::optional\u003cat::Layout\u003e layout, ::std::optional\u003cat::Device\u003e device, ::std::optional\u003cbool\u003e pin_memory, bool non_blocking, bool copy, ::std::optional\u003cat::MemoryFormat\u003e memory_format) const { return at::_ops::to_dtype_layout::call(const_cast\u003cTensor\u0026\u003e(*this), dtype, layout, device, pin_memory, non_blocking, copy, memory_format); } // aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -\u003e Tensor(a) inline at::Tensor Tensor::to(at::Device device, at::ScalarType dtype, bool non_blocking, bool copy, ::std::optional\u003cat::MemoryFormat\u003e memory_format) const { return at::_ops::to_device::call(const_cast\u003cTensor\u0026\u003e(*this), device, dtype, non_blocking, copy, memory_format); } // aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -\u003e Tensor(a) inline at::Tensor Tensor::to(at::ScalarType dtype, bool non_blocking, bool copy, ::std::optional\u003cat::MemoryFormat\u003e memory_format) const { return at::_ops::to_dtype::call(const_cast\u003cTensor\u0026\u003e(*this), dtype, non_blocking, copy, memory_format); } // aten::to.other(Tensor(a) self, Tensor other, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -\u003e Tensor(a) inline at::Tensor Tensor::to(const at::Tensor \u0026 other, bool non_blocking, bool copy, ::std::optional\u003cat::MemoryFormat\u003e memory_format) const { return at::_ops::to_other::call(const_cast\u003cTensor\u0026\u003e(*this), other, non_blocking, copy, memory_format); } // aten::item(Tensor self) -\u003e Scalar inline at::Scalar Tensor::item() const { return at::_ops::item::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::set_.source_Storage(Tensor(a!) self, Storage source) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::set_(at::Storage source) const { return at::_ops::set__source_Storage::call(const_cast\u003cTensor\u0026\u003e(*this), source); } // aten::set_.source_Storage_storage_offset(Tensor(a!) self, Storage source, SymInt storage_offset, SymInt[] size, SymInt[] stride=[]) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::set_(at::Storage source, int64_t storage_offset, at::IntArrayRef size, at::IntArrayRef stride) const { return at::_ops::set__source_Storage_storage_offset::call(const_cast\u003cTensor\u0026\u003e(*this), source, storage_offset, c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride)); } // aten::set_.source_Storage_storage_offset(Tensor(a!) self, Storage source, SymInt storage_offset, SymInt[] size, SymInt[] stride=[]) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::set__symint(at::Storage source, c10::SymInt storage_offset, c10::SymIntArrayRef size, c10::SymIntArrayRef stride) const { return at::_ops::set__source_Storage_storage_offset::call(const_cast\u003cTensor\u0026\u003e(*this), source, storage_offset, size, stride); } // aten::set_.source_Tensor_storage_offset(Tensor(a!) self, Tensor source, SymInt storage_offset, SymInt[] size, SymInt[] stride=[]) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::set_(const at::Tensor \u0026 source, int64_t storage_offset, at::IntArrayRef size, at::IntArrayRef stride) const { return at::_ops::set__source_Tensor_storage_offset::call(const_cast\u003cTensor\u0026\u003e(*this), source, storage_offset, c10::fromIntArrayRefSlow(size), c10::fromIntArrayRefSlow(stride)); } // aten::set_.source_Tensor_storage_offset(Tensor(a!) self, Tensor source, SymInt storage_offset, SymInt[] size, SymInt[] stride=[]) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::set__symint(const at::Tensor \u0026 source, c10::SymInt storage_offset, c10::SymIntArrayRef size, c10::SymIntArrayRef stride) const { return at::_ops::set__source_Tensor_storage_offset::call(const_cast\u003cTensor\u0026\u003e(*this), source, storage_offset, size, stride); } // aten::set_.source_Tensor(Tensor(a!) self, Tensor source) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::set_(const at::Tensor \u0026 source) const { return at::_ops::set__source_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), source); } // aten::set_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::set_() const { return at::_ops::set_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::is_set_to(Tensor self, Tensor tensor) -\u003e bool inline bool Tensor::is_set_to(const at::Tensor \u0026 tensor) const { return at::_ops::is_set_to::call(const_cast\u003cTensor\u0026\u003e(*this), tensor); } // aten::masked_fill_.Scalar(Tensor(a!) self, Tensor mask, Scalar value) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::masked_fill_(const at::Tensor \u0026 mask, const at::Scalar \u0026 value) const { return at::_ops::masked_fill__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), mask, value); } // aten::masked_fill.Scalar(Tensor self, Tensor mask, Scalar value) -\u003e Tensor inline at::Tensor Tensor::masked_fill(const at::Tensor \u0026 mask, const at::Scalar \u0026 value) const { return at::_ops::masked_fill_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), mask, value); } // aten::masked_fill_.Tensor(Tensor(a!) self, Tensor mask, Tensor value) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::masked_fill_(const at::Tensor \u0026 mask, const at::Tensor \u0026 value) const { return at::_ops::masked_fill__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), mask, value); } // aten::masked_fill.Tensor(Tensor self, Tensor mask, Tensor value) -\u003e Tensor inline at::Tensor Tensor::masked_fill(const at::Tensor \u0026 mask, const at::Tensor \u0026 value) const { return at::_ops::masked_fill_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), mask, value); } // aten::masked_scatter_(Tensor(a!) self, Tensor mask, Tensor source) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::masked_scatter_(const at::Tensor \u0026 mask, const at::Tensor \u0026 source) const { return at::_ops::masked_scatter_::call(const_cast\u003cTensor\u0026\u003e(*this), mask, source); } // aten::masked_scatter(Tensor self, Tensor mask, Tensor source) -\u003e Tensor inline at::Tensor Tensor::masked_scatter(const at::Tensor \u0026 mask, const at::Tensor \u0026 source) const { return at::_ops::masked_scatter::call(const_cast\u003cTensor\u0026\u003e(*this), mask, source); } // aten::view(Tensor(a) self, SymInt[] size) -\u003e Tensor(a) inline at::Tensor Tensor::view(at::IntArrayRef size) const { return at::_ops::view::call(const_cast\u003cTensor\u0026\u003e(*this), c10::fromIntArrayRefSlow(size)); } // aten::view(Tensor(a) self, SymInt[] size) -\u003e Tensor(a) inline at::Tensor Tensor::view_symint(c10::SymIntArrayRef size) const { return at::_ops::view::call(const_cast\u003cTensor\u0026\u003e(*this), size); } // aten::view.dtype(Tensor(a) self, ScalarType dtype) -\u003e Tensor(a) inline at::Tensor Tensor::view(at::ScalarType dtype) const { return at::_ops::view_dtype::call(const_cast\u003cTensor\u0026\u003e(*this), dtype); } // aten::put_(Tensor(a!) self, Tensor index, Tensor source, bool accumulate=False) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::put_(const at::Tensor \u0026 index, const at::Tensor \u0026 source, bool accumulate) const { return at::_ops::put_::call(const_cast\u003cTensor\u0026\u003e(*this), index, source, accumulate); } // aten::put(Tensor self, Tensor index, Tensor source, bool accumulate=False) -\u003e Tensor inline at::Tensor Tensor::put(const at::Tensor \u0026 index, const at::Tensor \u0026 source, bool accumulate) const { return at::_ops::put::call(const_cast\u003cTensor\u0026\u003e(*this), index, source, accumulate); } // aten::index_add_(Tensor(a!) self, int dim, Tensor index, Tensor source, *, Scalar alpha=1) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::index_add_(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 source, const at::Scalar \u0026 alpha) const { return at::_ops::index_add_::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, source, alpha); } // aten::index_add(Tensor self, int dim, Tensor index, Tensor source, *, Scalar alpha=1) -\u003e Tensor inline at::Tensor Tensor::index_add(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 source, const at::Scalar \u0026 alpha) const { return at::_ops::index_add::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, source, alpha); } // aten::index_add.dimname(Tensor self, Dimname dim, Tensor index, Tensor source, *, Scalar alpha=1) -\u003e Tensor inline at::Tensor Tensor::index_add(at::Dimname dim, const at::Tensor \u0026 index, const at::Tensor \u0026 source, const at::Scalar \u0026 alpha) const { return at::_ops::index_add_dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, source, alpha); } // aten::index_reduce_(Tensor(a!) self, int dim, Tensor index, Tensor source, str reduce, *, bool include_self=True) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::index_reduce_(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 source, c10::string_view reduce, bool include_self) const { return at::_ops::index_reduce_::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, source, reduce, include_self); } // aten::index_reduce(Tensor self, int dim, Tensor index, Tensor source, str reduce, *, bool include_self=True) -\u003e Tensor inline at::Tensor Tensor::index_reduce(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 source, c10::string_view reduce, bool include_self) const { return at::_ops::index_reduce::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, source, reduce, include_self); } // aten::index_fill_.int_Scalar(Tensor(a!) self, int dim, Tensor index, Scalar value) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::index_fill_(int64_t dim, const at::Tensor \u0026 index, const at::Scalar \u0026 value) const { return at::_ops::index_fill__int_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, value); } // aten::index_fill.int_Scalar(Tensor self, int dim, Tensor index, Scalar value) -\u003e Tensor inline at::Tensor Tensor::index_fill(int64_t dim, const at::Tensor \u0026 index, const at::Scalar \u0026 value) const { return at::_ops::index_fill_int_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, value); } // aten::index_fill_.int_Tensor(Tensor(a!) self, int dim, Tensor index, Tensor value) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::index_fill_(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 value) const { return at::_ops::index_fill__int_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, value); } // aten::index_fill.int_Tensor(Tensor self, int dim, Tensor index, Tensor value) -\u003e Tensor inline at::Tensor Tensor::index_fill(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 value) const { return at::_ops::index_fill_int_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, value); } // aten::index_fill_.Dimname_Scalar(Tensor(a!) self, Dimname dim, Tensor index, Scalar value) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::index_fill_(at::Dimname dim, const at::Tensor \u0026 index, const at::Scalar \u0026 value) const { return at::_ops::index_fill__Dimname_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, value); } // aten::index_fill_.Dimname_Tensor(Tensor(a!) self, Dimname dim, Tensor index, Tensor value) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::index_fill_(at::Dimname dim, const at::Tensor \u0026 index, const at::Tensor \u0026 value) const { return at::_ops::index_fill__Dimname_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, value); } // aten::index_fill.Dimname_Scalar(Tensor self, Dimname dim, Tensor index, Scalar value) -\u003e Tensor inline at::Tensor Tensor::index_fill(at::Dimname dim, const at::Tensor \u0026 index, const at::Scalar \u0026 value) const { return at::_ops::index_fill_Dimname_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, value); } // aten::index_fill.Dimname_Tensor(Tensor self, Dimname dim, Tensor index, Tensor value) -\u003e Tensor inline at::Tensor Tensor::index_fill(at::Dimname dim, const at::Tensor \u0026 index, const at::Tensor \u0026 value) const { return at::_ops::index_fill_Dimname_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, value); } // aten::scatter.src(Tensor self, int dim, Tensor index, Tensor src) -\u003e Tensor inline at::Tensor Tensor::scatter(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 src) const { return at::_ops::scatter_src::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, src); } // aten::scatter_.src(Tensor(a!) self, int dim, Tensor index, Tensor src) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::scatter_(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 src) const { return at::_ops::scatter__src::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, src); } // aten::scatter.value(Tensor self, int dim, Tensor index, Scalar value) -\u003e Tensor inline at::Tensor Tensor::scatter(int64_t dim, const at::Tensor \u0026 index, const at::Scalar \u0026 value) const { return at::_ops::scatter_value::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, value); } // aten::scatter_.value(Tensor(a!) self, int dim, Tensor index, Scalar value) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::scatter_(int64_t dim, const at::Tensor \u0026 index, const at::Scalar \u0026 value) const { return at::_ops::scatter__value::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, value); } // aten::scatter.reduce(Tensor self, int dim, Tensor index, Tensor src, *, str reduce) -\u003e Tensor inline at::Tensor Tensor::scatter(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 src, c10::string_view reduce) const { return at::_ops::scatter_reduce::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, src, reduce); } // aten::scatter_.reduce(Tensor(a!) self, int dim, Tensor index, Tensor src, *, str reduce) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::scatter_(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 src, c10::string_view reduce) const { return at::_ops::scatter__reduce::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, src, reduce); } // aten::scatter.value_reduce(Tensor self, int dim, Tensor index, Scalar value, *, str reduce) -\u003e Tensor inline at::Tensor Tensor::scatter(int64_t dim, const at::Tensor \u0026 index, const at::Scalar \u0026 value, c10::string_view reduce) const { return at::_ops::scatter_value_reduce::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, value, reduce); } // aten::scatter_.value_reduce(Tensor(a!) self, int dim, Tensor index, Scalar value, *, str reduce) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::scatter_(int64_t dim, const at::Tensor \u0026 index, const at::Scalar \u0026 value, c10::string_view reduce) const { return at::_ops::scatter__value_reduce::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, value, reduce); } // aten::scatter.dimname_src(Tensor self, Dimname dim, Tensor index, Tensor src) -\u003e Tensor inline at::Tensor Tensor::scatter(at::Dimname dim, const at::Tensor \u0026 index, const at::Tensor \u0026 src) const { return at::_ops::scatter_dimname_src::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, src); } // aten::scatter.dimname_value(Tensor self, Dimname dim, Tensor index, Scalar value) -\u003e Tensor inline at::Tensor Tensor::scatter(at::Dimname dim, const at::Tensor \u0026 index, const at::Scalar \u0026 value) const { return at::_ops::scatter_dimname_value::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, value); } // aten::scatter_add(Tensor self, int dim, Tensor index, Tensor src) -\u003e Tensor inline at::Tensor Tensor::scatter_add(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 src) const { return at::_ops::scatter_add::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, src); } // aten::scatter_add_(Tensor(a!) self, int dim, Tensor index, Tensor src) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::scatter_add_(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 src) const { return at::_ops::scatter_add_::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, src); } // aten::scatter_add.dimname(Tensor self, Dimname dim, Tensor index, Tensor src) -\u003e Tensor inline at::Tensor Tensor::scatter_add(at::Dimname dim, const at::Tensor \u0026 index, const at::Tensor \u0026 src) const { return at::_ops::scatter_add_dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, src); } // aten::scatter_reduce.two(Tensor self, int dim, Tensor index, Tensor src, str reduce, *, bool include_self=True) -\u003e Tensor inline at::Tensor Tensor::scatter_reduce(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 src, c10::string_view reduce, bool include_self) const { return at::_ops::scatter_reduce_two::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, src, reduce, include_self); } // aten::scatter_reduce_.two(Tensor(a!) self, int dim, Tensor index, Tensor src, str reduce, *, bool include_self=True) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::scatter_reduce_(int64_t dim, const at::Tensor \u0026 index, const at::Tensor \u0026 src, c10::string_view reduce, bool include_self) const { return at::_ops::scatter_reduce__two::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, src, reduce, include_self); } // aten::eq_.Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::eq_(const at::Scalar \u0026 other) const { return at::_ops::eq__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::eq_.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::eq_(const at::Tensor \u0026 other) const { return at::_ops::eq__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::bitwise_and.Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::bitwise_and(const at::Scalar \u0026 other) const { return at::_ops::bitwise_and_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::bitwise_and.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::bitwise_and(const at::Tensor \u0026 other) const { return at::_ops::bitwise_and_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::bitwise_and_.Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::bitwise_and_(const at::Scalar \u0026 other) const { return at::_ops::bitwise_and__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::bitwise_and_.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::bitwise_and_(const at::Tensor \u0026 other) const { return at::_ops::bitwise_and__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::__and__.Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::__and__(const at::Scalar \u0026 other) const { return at::_ops::__and___Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::__and__.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::__and__(const at::Tensor \u0026 other) const { return at::_ops::__and___Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::__iand__.Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::__iand__(const at::Scalar \u0026 other) const { return at::_ops::__iand___Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::__iand__.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::__iand__(const at::Tensor \u0026 other) const { return at::_ops::__iand___Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::bitwise_or.Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::bitwise_or(const at::Scalar \u0026 other) const { return at::_ops::bitwise_or_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::bitwise_or.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::bitwise_or(const at::Tensor \u0026 other) const { return at::_ops::bitwise_or_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::bitwise_or_.Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::bitwise_or_(const at::Scalar \u0026 other) const { return at::_ops::bitwise_or__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::bitwise_or_.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::bitwise_or_(const at::Tensor \u0026 other) const { return at::_ops::bitwise_or__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::__or__.Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::__or__(const at::Scalar \u0026 other) const { return at::_ops::__or___Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::__or__.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::__or__(const at::Tensor \u0026 other) const { return at::_ops::__or___Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::__ior__.Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::__ior__(const at::Scalar \u0026 other) const { return at::_ops::__ior___Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::__ior__.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::__ior__(const at::Tensor \u0026 other) const { return at::_ops::__ior___Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::bitwise_xor.Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::bitwise_xor(const at::Scalar \u0026 other) const { return at::_ops::bitwise_xor_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::bitwise_xor.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::bitwise_xor(const at::Tensor \u0026 other) const { return at::_ops::bitwise_xor_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::bitwise_xor_.Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::bitwise_xor_(const at::Scalar \u0026 other) const { return at::_ops::bitwise_xor__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::bitwise_xor_.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::bitwise_xor_(const at::Tensor \u0026 other) const { return at::_ops::bitwise_xor__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::__xor__.Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::__xor__(const at::Scalar \u0026 other) const { return at::_ops::__xor___Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::__xor__.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::__xor__(const at::Tensor \u0026 other) const { return at::_ops::__xor___Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::__ixor__.Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::__ixor__(const at::Scalar \u0026 other) const { return at::_ops::__ixor___Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::__ixor__.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::__ixor__(const at::Tensor \u0026 other) const { return at::_ops::__ixor___Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::__lshift__.Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::__lshift__(const at::Scalar \u0026 other) const { return at::_ops::__lshift___Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::__lshift__.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::__lshift__(const at::Tensor \u0026 other) const { return at::_ops::__lshift___Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::__ilshift__.Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::__ilshift__(const at::Scalar \u0026 other) const { return at::_ops::__ilshift___Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::__ilshift__.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::__ilshift__(const at::Tensor \u0026 other) const { return at::_ops::__ilshift___Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::bitwise_left_shift.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::bitwise_left_shift(const at::Tensor \u0026 other) const { return at::_ops::bitwise_left_shift_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::bitwise_left_shift_.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::bitwise_left_shift_(const at::Tensor \u0026 other) const { return at::_ops::bitwise_left_shift__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::bitwise_left_shift.Tensor_Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::bitwise_left_shift(const at::Scalar \u0026 other) const { return at::_ops::bitwise_left_shift_Tensor_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::bitwise_left_shift_.Tensor_Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::bitwise_left_shift_(const at::Scalar \u0026 other) const { return at::_ops::bitwise_left_shift__Tensor_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::__rshift__.Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::__rshift__(const at::Scalar \u0026 other) const { return at::_ops::__rshift___Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::__rshift__.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::__rshift__(const at::Tensor \u0026 other) const { return at::_ops::__rshift___Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::__irshift__.Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::__irshift__(const at::Scalar \u0026 other) const { return at::_ops::__irshift___Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::__irshift__.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::__irshift__(const at::Tensor \u0026 other) const { return at::_ops::__irshift___Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::bitwise_right_shift.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::bitwise_right_shift(const at::Tensor \u0026 other) const { return at::_ops::bitwise_right_shift_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::bitwise_right_shift_.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::bitwise_right_shift_(const at::Tensor \u0026 other) const { return at::_ops::bitwise_right_shift__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::bitwise_right_shift.Tensor_Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::bitwise_right_shift(const at::Scalar \u0026 other) const { return at::_ops::bitwise_right_shift_Tensor_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::bitwise_right_shift_.Tensor_Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::bitwise_right_shift_(const at::Scalar \u0026 other) const { return at::_ops::bitwise_right_shift__Tensor_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::tril_(Tensor(a!) self, int diagonal=0) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::tril_(int64_t diagonal) const { return at::_ops::tril_::call(const_cast\u003cTensor\u0026\u003e(*this), diagonal); } // aten::triu_(Tensor(a!) self, int diagonal=0) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::triu_(int64_t diagonal) const { return at::_ops::triu_::call(const_cast\u003cTensor\u0026\u003e(*this), diagonal); } // aten::digamma_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::digamma_() const { return at::_ops::digamma_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::lerp_.Scalar(Tensor(a!) self, Tensor end, Scalar weight) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::lerp_(const at::Tensor \u0026 end, const at::Scalar \u0026 weight) const { return at::_ops::lerp__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), end, weight); } // aten::lerp_.Tensor(Tensor(a!) self, Tensor end, Tensor weight) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::lerp_(const at::Tensor \u0026 end, const at::Tensor \u0026 weight) const { return at::_ops::lerp__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), end, weight); } // aten::addbmm_(Tensor(a!) self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::addbmm_(const at::Tensor \u0026 batch1, const at::Tensor \u0026 batch2, const at::Scalar \u0026 beta, const at::Scalar \u0026 alpha) const { return at::_ops::addbmm_::call(const_cast\u003cTensor\u0026\u003e(*this), batch1, batch2, beta, alpha); } // aten::addbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -\u003e Tensor inline at::Tensor Tensor::addbmm(const at::Tensor \u0026 batch1, const at::Tensor \u0026 batch2, const at::Scalar \u0026 beta, const at::Scalar \u0026 alpha) const { return at::_ops::addbmm::call(const_cast\u003cTensor\u0026\u003e(*this), batch1, batch2, beta, alpha); } // aten::random_.from(Tensor(a!) self, int from, int? to, *, Generator? generator=None) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::random_(int64_t from, ::std::optional\u003cint64_t\u003e to, ::std::optional\u003cat::Generator\u003e generator) const { return at::_ops::random__from::call(const_cast\u003cTensor\u0026\u003e(*this), from, to, generator); } // aten::random_.to(Tensor(a!) self, int to, *, Generator? generator=None) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::random_(int64_t to, ::std::optional\u003cat::Generator\u003e generator) const { return at::_ops::random__to::call(const_cast\u003cTensor\u0026\u003e(*this), to, generator); } // aten::random_(Tensor(a!) self, *, Generator? generator=None) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::random_(::std::optional\u003cat::Generator\u003e generator) const { return at::_ops::random_::call(const_cast\u003cTensor\u0026\u003e(*this), generator); } // aten::uniform_(Tensor(a!) self, float from=0, float to=1, *, Generator? generator=None) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::uniform_(double from, double to, ::std::optional\u003cat::Generator\u003e generator) const { return at::_ops::uniform_::call(const_cast\u003cTensor\u0026\u003e(*this), from, to, generator); } // aten::cauchy_(Tensor(a!) self, float median=0, float sigma=1, *, Generator? generator=None) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::cauchy_(double median, double sigma, ::std::optional\u003cat::Generator\u003e generator) const { return at::_ops::cauchy_::call(const_cast\u003cTensor\u0026\u003e(*this), median, sigma, generator); } // aten::log_normal_(Tensor(a!) self, float mean=1, float std=2, *, Generator? generator=None) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::log_normal_(double mean, double std, ::std::optional\u003cat::Generator\u003e generator) const { return at::_ops::log_normal_::call(const_cast\u003cTensor\u0026\u003e(*this), mean, std, generator); } // aten::exponential_(Tensor(a!) self, float lambd=1, *, Generator? generator=None) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::exponential_(double lambd, ::std::optional\u003cat::Generator\u003e generator) const { return at::_ops::exponential_::call(const_cast\u003cTensor\u0026\u003e(*this), lambd, generator); } // aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::geometric_(double p, ::std::optional\u003cat::Generator\u003e generator) const { return at::_ops::geometric_::call(const_cast\u003cTensor\u0026\u003e(*this), p, generator); } // aten::diag(Tensor self, int diagonal=0) -\u003e Tensor inline at::Tensor Tensor::diag(int64_t diagonal) const { return at::_ops::diag::call(const_cast\u003cTensor\u0026\u003e(*this), diagonal); } // aten::cross(Tensor self, Tensor other, int? dim=None) -\u003e Tensor inline at::Tensor Tensor::cross(const at::Tensor \u0026 other, ::std::optional\u003cint64_t\u003e dim) const { return at::_ops::cross::call(const_cast\u003cTensor\u0026\u003e(*this), other, dim); } // aten::triu(Tensor self, int diagonal=0) -\u003e Tensor inline at::Tensor Tensor::triu(int64_t diagonal) const { return at::_ops::triu::call(const_cast\u003cTensor\u0026\u003e(*this), diagonal); } // aten::tril(Tensor self, int diagonal=0) -\u003e Tensor inline at::Tensor Tensor::tril(int64_t diagonal) const { return at::_ops::tril::call(const_cast\u003cTensor\u0026\u003e(*this), diagonal); } // aten::trace(Tensor self) -\u003e Tensor inline at::Tensor Tensor::trace() const { return at::_ops::trace::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::ne.Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::ne(const at::Scalar \u0026 other) const { return at::_ops::ne_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::ne.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::ne(const at::Tensor \u0026 other) const { return at::_ops::ne_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::ne_.Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::ne_(const at::Scalar \u0026 other) const { return at::_ops::ne__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::ne_.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::ne_(const at::Tensor \u0026 other) const { return at::_ops::ne__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::not_equal.Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::not_equal(const at::Scalar \u0026 other) const { return at::_ops::not_equal_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::not_equal.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::not_equal(const at::Tensor \u0026 other) const { return at::_ops::not_equal_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::not_equal_.Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::not_equal_(const at::Scalar \u0026 other) const { return at::_ops::not_equal__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::not_equal_.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::not_equal_(const at::Tensor \u0026 other) const { return at::_ops::not_equal__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::eq.Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::eq(const at::Scalar \u0026 other) const { return at::_ops::eq_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::eq.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::eq(const at::Tensor \u0026 other) const { return at::_ops::eq_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::ge.Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::ge(const at::Scalar \u0026 other) const { return at::_ops::ge_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::ge.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::ge(const at::Tensor \u0026 other) const { return at::_ops::ge_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::ge_.Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::ge_(const at::Scalar \u0026 other) const { return at::_ops::ge__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::ge_.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::ge_(const at::Tensor \u0026 other) const { return at::_ops::ge__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::greater_equal.Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::greater_equal(const at::Scalar \u0026 other) const { return at::_ops::greater_equal_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::greater_equal.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::greater_equal(const at::Tensor \u0026 other) const { return at::_ops::greater_equal_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::greater_equal_.Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::greater_equal_(const at::Scalar \u0026 other) const { return at::_ops::greater_equal__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::greater_equal_.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::greater_equal_(const at::Tensor \u0026 other) const { return at::_ops::greater_equal__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::le.Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::le(const at::Scalar \u0026 other) const { return at::_ops::le_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::le.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::le(const at::Tensor \u0026 other) const { return at::_ops::le_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::le_.Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::le_(const at::Scalar \u0026 other) const { return at::_ops::le__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::le_.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::le_(const at::Tensor \u0026 other) const { return at::_ops::le__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::less_equal.Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::less_equal(const at::Scalar \u0026 other) const { return at::_ops::less_equal_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::less_equal.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::less_equal(const at::Tensor \u0026 other) const { return at::_ops::less_equal_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::less_equal_.Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::less_equal_(const at::Scalar \u0026 other) const { return at::_ops::less_equal__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::less_equal_.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::less_equal_(const at::Tensor \u0026 other) const { return at::_ops::less_equal__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::gt.Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::gt(const at::Scalar \u0026 other) const { return at::_ops::gt_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::gt.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::gt(const at::Tensor \u0026 other) const { return at::_ops::gt_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::gt_.Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::gt_(const at::Scalar \u0026 other) const { return at::_ops::gt__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::gt_.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::gt_(const at::Tensor \u0026 other) const { return at::_ops::gt__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::greater.Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::greater(const at::Scalar \u0026 other) const { return at::_ops::greater_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::greater.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::greater(const at::Tensor \u0026 other) const { return at::_ops::greater_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::greater_.Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::greater_(const at::Scalar \u0026 other) const { return at::_ops::greater__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::greater_.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::greater_(const at::Tensor \u0026 other) const { return at::_ops::greater__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::lt.Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::lt(const at::Scalar \u0026 other) const { return at::_ops::lt_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::lt.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::lt(const at::Tensor \u0026 other) const { return at::_ops::lt_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::lt_.Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::lt_(const at::Scalar \u0026 other) const { return at::_ops::lt__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::lt_.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::lt_(const at::Tensor \u0026 other) const { return at::_ops::lt__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::less.Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::less(const at::Scalar \u0026 other) const { return at::_ops::less_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::less.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::less(const at::Tensor \u0026 other) const { return at::_ops::less_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::less_.Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::less_(const at::Scalar \u0026 other) const { return at::_ops::less__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::less_.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::less_(const at::Tensor \u0026 other) const { return at::_ops::less__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::take(Tensor self, Tensor index) -\u003e Tensor inline at::Tensor Tensor::take(const at::Tensor \u0026 index) const { return at::_ops::take::call(const_cast\u003cTensor\u0026\u003e(*this), index); } // aten::take_along_dim(Tensor self, Tensor indices, int? dim=None) -\u003e Tensor inline at::Tensor Tensor::take_along_dim(const at::Tensor \u0026 indices, ::std::optional\u003cint64_t\u003e dim) const { return at::_ops::take_along_dim::call(const_cast\u003cTensor\u0026\u003e(*this), indices, dim); } // aten::index_select(Tensor self, int dim, Tensor index) -\u003e Tensor inline at::Tensor Tensor::index_select(int64_t dim, const at::Tensor \u0026 index) const { return at::_ops::index_select::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index); } // aten::index_select.dimname(Tensor self, Dimname dim, Tensor index) -\u003e Tensor inline at::Tensor Tensor::index_select(at::Dimname dim, const at::Tensor \u0026 index) const { return at::_ops::index_select_dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index); } // aten::masked_select(Tensor self, Tensor mask) -\u003e Tensor inline at::Tensor Tensor::masked_select(const at::Tensor \u0026 mask) const { return at::_ops::masked_select::call(const_cast\u003cTensor\u0026\u003e(*this), mask); } // aten::nonzero(Tensor self) -\u003e Tensor inline at::Tensor Tensor::nonzero() const { return at::_ops::nonzero::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::nonzero_static(Tensor self, *, SymInt size, int fill_value=-1) -\u003e Tensor inline at::Tensor Tensor::nonzero_static(int64_t size, int64_t fill_value) const { return at::_ops::nonzero_static::call(const_cast\u003cTensor\u0026\u003e(*this), size, fill_value); } // aten::nonzero_static(Tensor self, *, SymInt size, int fill_value=-1) -\u003e Tensor inline at::Tensor Tensor::nonzero_static_symint(c10::SymInt size, int64_t fill_value) const { return at::_ops::nonzero_static::call(const_cast\u003cTensor\u0026\u003e(*this), size, fill_value); } // aten::nonzero_numpy(Tensor self) -\u003e Tensor[] inline ::std::vector\u003cat::Tensor\u003e Tensor::nonzero_numpy() const { return at::_ops::nonzero_numpy::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::argwhere(Tensor self) -\u003e Tensor inline at::Tensor Tensor::argwhere() const { return at::_ops::argwhere::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::gather(Tensor self, int dim, Tensor index, *, bool sparse_grad=False) -\u003e Tensor inline at::Tensor Tensor::gather(int64_t dim, const at::Tensor \u0026 index, bool sparse_grad) const { return at::_ops::gather::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, sparse_grad); } // aten::gather.dimname(Tensor self, Dimname dim, Tensor index, *, bool sparse_grad=False) -\u003e Tensor inline at::Tensor Tensor::gather(at::Dimname dim, const at::Tensor \u0026 index, bool sparse_grad) const { return at::_ops::gather_dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim, index, sparse_grad); } // aten::addcmul(Tensor self, Tensor tensor1, Tensor tensor2, *, Scalar value=1) -\u003e Tensor inline at::Tensor Tensor::addcmul(const at::Tensor \u0026 tensor1, const at::Tensor \u0026 tensor2, const at::Scalar \u0026 value) const { return at::_ops::addcmul::call(const_cast\u003cTensor\u0026\u003e(*this), tensor1, tensor2, value); } // aten::addcmul_(Tensor(a!) self, Tensor tensor1, Tensor tensor2, *, Scalar value=1) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::addcmul_(const at::Tensor \u0026 tensor1, const at::Tensor \u0026 tensor2, const at::Scalar \u0026 value) const { return at::_ops::addcmul_::call(const_cast\u003cTensor\u0026\u003e(*this), tensor1, tensor2, value); } // aten::addcdiv(Tensor self, Tensor tensor1, Tensor tensor2, *, Scalar value=1) -\u003e Tensor inline at::Tensor Tensor::addcdiv(const at::Tensor \u0026 tensor1, const at::Tensor \u0026 tensor2, const at::Scalar \u0026 value) const { return at::_ops::addcdiv::call(const_cast\u003cTensor\u0026\u003e(*this), tensor1, tensor2, value); } // aten::addcdiv_(Tensor(a!) self, Tensor tensor1, Tensor tensor2, *, Scalar value=1) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::addcdiv_(const at::Tensor \u0026 tensor1, const at::Tensor \u0026 tensor2, const at::Scalar \u0026 value) const { return at::_ops::addcdiv_::call(const_cast\u003cTensor\u0026\u003e(*this), tensor1, tensor2, value); } // aten::triangular_solve(Tensor self, Tensor A, bool upper=True, bool transpose=False, bool unitriangular=False) -\u003e (Tensor solution, Tensor cloned_coefficient) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::triangular_solve(const at::Tensor \u0026 A, bool upper, bool transpose, bool unitriangular) const { return at::_ops::triangular_solve::call(const_cast\u003cTensor\u0026\u003e(*this), A, upper, transpose, unitriangular); } // aten::svd(Tensor self, bool some=True, bool compute_uv=True) -\u003e (Tensor U, Tensor S, Tensor V) inline ::std::tuple\u003cat::Tensor,at::Tensor,at::Tensor\u003e Tensor::svd(bool some, bool compute_uv) const { return at::_ops::svd::call(const_cast\u003cTensor\u0026\u003e(*this), some, compute_uv); } // aten::swapaxes(Tensor(a) self, int axis0, int axis1) -\u003e Tensor(a) inline at::Tensor Tensor::swapaxes(int64_t axis0, int64_t axis1) const { return at::_ops::swapaxes::call(const_cast\u003cTensor\u0026\u003e(*this), axis0, axis1); } // aten::swapaxes_(Tensor(a!) self, int axis0, int axis1) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::swapaxes_(int64_t axis0, int64_t axis1) const { return at::_ops::swapaxes_::call(const_cast\u003cTensor\u0026\u003e(*this), axis0, axis1); } // aten::swapdims(Tensor(a) self, int dim0, int dim1) -\u003e Tensor(a) inline at::Tensor Tensor::swapdims(int64_t dim0, int64_t dim1) const { return at::_ops::swapdims::call(const_cast\u003cTensor\u0026\u003e(*this), dim0, dim1); } // aten::swapdims_(Tensor(a!) self, int dim0, int dim1) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::swapdims_(int64_t dim0, int64_t dim1) const { return at::_ops::swapdims_::call(const_cast\u003cTensor\u0026\u003e(*this), dim0, dim1); } // aten::cholesky(Tensor self, bool upper=False) -\u003e Tensor inline at::Tensor Tensor::cholesky(bool upper) const { return at::_ops::cholesky::call(const_cast\u003cTensor\u0026\u003e(*this), upper); } // aten::cholesky_solve(Tensor self, Tensor input2, bool upper=False) -\u003e Tensor inline at::Tensor Tensor::cholesky_solve(const at::Tensor \u0026 input2, bool upper) const { return at::_ops::cholesky_solve::call(const_cast\u003cTensor\u0026\u003e(*this), input2, upper); } // aten::cholesky_inverse(Tensor self, bool upper=False) -\u003e Tensor inline at::Tensor Tensor::cholesky_inverse(bool upper) const { return at::_ops::cholesky_inverse::call(const_cast\u003cTensor\u0026\u003e(*this), upper); } // aten::qr(Tensor self, bool some=True) -\u003e (Tensor Q, Tensor R) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::qr(bool some) const { return at::_ops::qr::call(const_cast\u003cTensor\u0026\u003e(*this), some); } // aten::geqrf(Tensor self) -\u003e (Tensor a, Tensor tau) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::geqrf() const { return at::_ops::geqrf::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::orgqr(Tensor self, Tensor input2) -\u003e Tensor inline at::Tensor Tensor::orgqr(const at::Tensor \u0026 input2) const { return at::_ops::orgqr::call(const_cast\u003cTensor\u0026\u003e(*this), input2); } // aten::ormqr(Tensor self, Tensor input2, Tensor input3, bool left=True, bool transpose=False) -\u003e Tensor inline at::Tensor Tensor::ormqr(const at::Tensor \u0026 input2, const at::Tensor \u0026 input3, bool left, bool transpose) const { return at::_ops::ormqr::call(const_cast\u003cTensor\u0026\u003e(*this), input2, input3, left, transpose); } // aten::lu_solve(Tensor self, Tensor LU_data, Tensor LU_pivots) -\u003e Tensor inline at::Tensor Tensor::lu_solve(const at::Tensor \u0026 LU_data, const at::Tensor \u0026 LU_pivots) const { return at::_ops::lu_solve::call(const_cast\u003cTensor\u0026\u003e(*this), LU_data, LU_pivots); } // aten::multinomial(Tensor self, SymInt num_samples, bool replacement=False, *, Generator? generator=None) -\u003e Tensor inline at::Tensor Tensor::multinomial(int64_t num_samples, bool replacement, ::std::optional\u003cat::Generator\u003e generator) const { return at::_ops::multinomial::call(const_cast\u003cTensor\u0026\u003e(*this), num_samples, replacement, generator); } // aten::multinomial(Tensor self, SymInt num_samples, bool replacement=False, *, Generator? generator=None) -\u003e Tensor inline at::Tensor Tensor::multinomial_symint(c10::SymInt num_samples, bool replacement, ::std::optional\u003cat::Generator\u003e generator) const { return at::_ops::multinomial::call(const_cast\u003cTensor\u0026\u003e(*this), num_samples, replacement, generator); } // aten::lgamma_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::lgamma_() const { return at::_ops::lgamma_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::lgamma(Tensor self) -\u003e Tensor inline at::Tensor Tensor::lgamma() const { return at::_ops::lgamma::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::digamma(Tensor self) -\u003e Tensor inline at::Tensor Tensor::digamma() const { return at::_ops::digamma::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::polygamma(int n, Tensor self) -\u003e Tensor inline at::Tensor Tensor::polygamma(int64_t n) const { return at::_ops::polygamma::call(n, const_cast\u003cTensor\u0026\u003e(*this)); } // aten::polygamma_(Tensor(a!) self, int n) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::polygamma_(int64_t n) const { return at::_ops::polygamma_::call(const_cast\u003cTensor\u0026\u003e(*this), n); } // aten::erfinv(Tensor self) -\u003e Tensor inline at::Tensor Tensor::erfinv() const { return at::_ops::erfinv::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::erfinv_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::erfinv_() const { return at::_ops::erfinv_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::i0(Tensor self) -\u003e Tensor inline at::Tensor Tensor::i0() const { return at::_ops::i0::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::i0_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::i0_() const { return at::_ops::i0_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::sign(Tensor self) -\u003e Tensor inline at::Tensor Tensor::sign() const { return at::_ops::sign::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::sign_(Tensor(a!) self) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::sign_() const { return at::_ops::sign_::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::signbit(Tensor self) -\u003e Tensor inline at::Tensor Tensor::signbit() const { return at::_ops::signbit::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::dist(Tensor self, Tensor other, Scalar p=2) -\u003e Tensor inline at::Tensor Tensor::dist(const at::Tensor \u0026 other, const at::Scalar \u0026 p) const { return at::_ops::dist::call(const_cast\u003cTensor\u0026\u003e(*this), other, p); } // aten::atan2_(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::atan2_(const at::Tensor \u0026 other) const { return at::_ops::atan2_::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::atan2(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::atan2(const at::Tensor \u0026 other) const { return at::_ops::atan2::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::arctan2(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::arctan2(const at::Tensor \u0026 other) const { return at::_ops::arctan2::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::arctan2_(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::arctan2_(const at::Tensor \u0026 other) const { return at::_ops::arctan2_::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::lerp.Scalar(Tensor self, Tensor end, Scalar weight) -\u003e Tensor inline at::Tensor Tensor::lerp(const at::Tensor \u0026 end, const at::Scalar \u0026 weight) const { return at::_ops::lerp_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), end, weight); } // aten::lerp.Tensor(Tensor self, Tensor end, Tensor weight) -\u003e Tensor inline at::Tensor Tensor::lerp(const at::Tensor \u0026 end, const at::Tensor \u0026 weight) const { return at::_ops::lerp_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), end, weight); } // aten::histc(Tensor self, int bins=100, Scalar min=0, Scalar max=0) -\u003e Tensor inline at::Tensor Tensor::histc(int64_t bins, const at::Scalar \u0026 min, const at::Scalar \u0026 max) const { return at::_ops::histc::call(const_cast\u003cTensor\u0026\u003e(*this), bins, min, max); } // aten::histogram.bins_tensor(Tensor self, Tensor bins, *, Tensor? weight=None, bool density=False) -\u003e (Tensor hist, Tensor bin_edges) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::histogram(const at::Tensor \u0026 bins, const ::std::optional\u003cat::Tensor\u003e \u0026 weight, bool density) const { return at::_ops::histogram_bins_tensor::call(const_cast\u003cTensor\u0026\u003e(*this), bins, weight, density); } // aten::histogram.bin_ct(Tensor self, int bins=100, *, float[]? range=None, Tensor? weight=None, bool density=False) -\u003e (Tensor hist, Tensor bin_edges) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::histogram(int64_t bins, ::std::optional\u003cat::ArrayRef\u003cdouble\u003e\u003e range, const ::std::optional\u003cat::Tensor\u003e \u0026 weight, bool density) const { return at::_ops::histogram_bin_ct::call(const_cast\u003cTensor\u0026\u003e(*this), bins, range, weight, density); } // aten::fmod.Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::fmod(const at::Scalar \u0026 other) const { return at::_ops::fmod_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::fmod_.Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::fmod_(const at::Scalar \u0026 other) const { return at::_ops::fmod__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::fmod.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::fmod(const at::Tensor \u0026 other) const { return at::_ops::fmod_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::fmod_.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::fmod_(const at::Tensor \u0026 other) const { return at::_ops::fmod__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::hypot(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::hypot(const at::Tensor \u0026 other) const { return at::_ops::hypot::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::hypot_(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::hypot_(const at::Tensor \u0026 other) const { return at::_ops::hypot_::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::igamma(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::igamma(const at::Tensor \u0026 other) const { return at::_ops::igamma::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::igamma_(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::igamma_(const at::Tensor \u0026 other) const { return at::_ops::igamma_::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::igammac(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::igammac(const at::Tensor \u0026 other) const { return at::_ops::igammac::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::igammac_(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::igammac_(const at::Tensor \u0026 other) const { return at::_ops::igammac_::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::nextafter(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::nextafter(const at::Tensor \u0026 other) const { return at::_ops::nextafter::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::nextafter_(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::nextafter_(const at::Tensor \u0026 other) const { return at::_ops::nextafter_::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::remainder.Scalar(Tensor self, Scalar other) -\u003e Tensor inline at::Tensor Tensor::remainder(const at::Scalar \u0026 other) const { return at::_ops::remainder_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::remainder_.Scalar(Tensor(a!) self, Scalar other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::remainder_(const at::Scalar \u0026 other) const { return at::_ops::remainder__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::remainder.Tensor(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::remainder(const at::Tensor \u0026 other) const { return at::_ops::remainder_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::remainder_.Tensor(Tensor(a!) self, Tensor other) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::remainder_(const at::Tensor \u0026 other) const { return at::_ops::remainder__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::min(Tensor self) -\u003e Tensor inline at::Tensor Tensor::min() const { return at::_ops::min::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::fmin(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::fmin(const at::Tensor \u0026 other) const { return at::_ops::fmin::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::max(Tensor self) -\u003e Tensor inline at::Tensor Tensor::max() const { return at::_ops::max::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::fmax(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::fmax(const at::Tensor \u0026 other) const { return at::_ops::fmax::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::maximum(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::maximum(const at::Tensor \u0026 other) const { return at::_ops::maximum::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::max.other(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::max(const at::Tensor \u0026 other) const { return at::_ops::max_other::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::minimum(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::minimum(const at::Tensor \u0026 other) const { return at::_ops::minimum::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::min.other(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::min(const at::Tensor \u0026 other) const { return at::_ops::min_other::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::quantile(Tensor self, Tensor q, int? dim=None, bool keepdim=False, *, str interpolation=\u0027linear\u0027) -\u003e Tensor inline at::Tensor Tensor::quantile(const at::Tensor \u0026 q, ::std::optional\u003cint64_t\u003e dim, bool keepdim, c10::string_view interpolation) const { return at::_ops::quantile::call(const_cast\u003cTensor\u0026\u003e(*this), q, dim, keepdim, interpolation); } // aten::quantile.scalar(Tensor self, float q, int? dim=None, bool keepdim=False, *, str interpolation=\u0027linear\u0027) -\u003e Tensor inline at::Tensor Tensor::quantile(double q, ::std::optional\u003cint64_t\u003e dim, bool keepdim, c10::string_view interpolation) const { return at::_ops::quantile_scalar::call(const_cast\u003cTensor\u0026\u003e(*this), q, dim, keepdim, interpolation); } // aten::nanquantile(Tensor self, Tensor q, int? dim=None, bool keepdim=False, *, str interpolation=\u0027linear\u0027) -\u003e Tensor inline at::Tensor Tensor::nanquantile(const at::Tensor \u0026 q, ::std::optional\u003cint64_t\u003e dim, bool keepdim, c10::string_view interpolation) const { return at::_ops::nanquantile::call(const_cast\u003cTensor\u0026\u003e(*this), q, dim, keepdim, interpolation); } // aten::nanquantile.scalar(Tensor self, float q, int? dim=None, bool keepdim=False, *, str interpolation=\u0027linear\u0027) -\u003e Tensor inline at::Tensor Tensor::nanquantile(double q, ::std::optional\u003cint64_t\u003e dim, bool keepdim, c10::string_view interpolation) const { return at::_ops::nanquantile_scalar::call(const_cast\u003cTensor\u0026\u003e(*this), q, dim, keepdim, interpolation); } // aten::sort(Tensor self, int dim=-1, bool descending=False) -\u003e (Tensor values, Tensor indices) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::sort(int64_t dim, bool descending) const { return at::_ops::sort::call(const_cast\u003cTensor\u0026\u003e(*this), dim, descending); } // aten::sort.stable(Tensor self, *, bool? stable, int dim=-1, bool descending=False) -\u003e (Tensor values, Tensor indices) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::sort(::std::optional\u003cbool\u003e stable, int64_t dim, bool descending) const { return at::_ops::sort_stable::call(const_cast\u003cTensor\u0026\u003e(*this), stable, dim, descending); } // aten::sort.dimname(Tensor self, Dimname dim, bool descending=False) -\u003e (Tensor values, Tensor indices) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::sort(at::Dimname dim, bool descending) const { return at::_ops::sort_dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim, descending); } // aten::sort.dimname_stable(Tensor self, *, bool? stable, Dimname dim, bool descending=False) -\u003e (Tensor values, Tensor indices) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::sort(::std::optional\u003cbool\u003e stable, at::Dimname dim, bool descending) const { return at::_ops::sort_dimname_stable::call(const_cast\u003cTensor\u0026\u003e(*this), stable, dim, descending); } // aten::msort(Tensor self) -\u003e Tensor inline at::Tensor Tensor::msort() const { return at::_ops::msort::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::argsort(Tensor self, int dim=-1, bool descending=False) -\u003e Tensor inline at::Tensor Tensor::argsort(int64_t dim, bool descending) const { return at::_ops::argsort::call(const_cast\u003cTensor\u0026\u003e(*this), dim, descending); } // aten::argsort.stable(Tensor self, *, bool stable, int dim=-1, bool descending=False) -\u003e Tensor inline at::Tensor Tensor::argsort(bool stable, int64_t dim, bool descending) const { return at::_ops::argsort_stable::call(const_cast\u003cTensor\u0026\u003e(*this), stable, dim, descending); } // aten::argsort.dimname(Tensor self, Dimname dim, bool descending=False) -\u003e Tensor inline at::Tensor Tensor::argsort(at::Dimname dim, bool descending) const { return at::_ops::argsort_dimname::call(const_cast\u003cTensor\u0026\u003e(*this), dim, descending); } // aten::topk(Tensor self, SymInt k, int dim=-1, bool largest=True, bool sorted=True) -\u003e (Tensor values, Tensor indices) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::topk(int64_t k, int64_t dim, bool largest, bool sorted) const { return at::_ops::topk::call(const_cast\u003cTensor\u0026\u003e(*this), k, dim, largest, sorted); } // aten::topk(Tensor self, SymInt k, int dim=-1, bool largest=True, bool sorted=True) -\u003e (Tensor values, Tensor indices) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::topk_symint(c10::SymInt k, int64_t dim, bool largest, bool sorted) const { return at::_ops::topk::call(const_cast\u003cTensor\u0026\u003e(*this), k, dim, largest, sorted); } // aten::all(Tensor self) -\u003e Tensor inline at::Tensor Tensor::all() const { return at::_ops::all::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::any(Tensor self) -\u003e Tensor inline at::Tensor Tensor::any() const { return at::_ops::any::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::renorm(Tensor self, Scalar p, int dim, Scalar maxnorm) -\u003e Tensor inline at::Tensor Tensor::renorm(const at::Scalar \u0026 p, int64_t dim, const at::Scalar \u0026 maxnorm) const { return at::_ops::renorm::call(const_cast\u003cTensor\u0026\u003e(*this), p, dim, maxnorm); } // aten::renorm_(Tensor(a!) self, Scalar p, int dim, Scalar maxnorm) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::renorm_(const at::Scalar \u0026 p, int64_t dim, const at::Scalar \u0026 maxnorm) const { return at::_ops::renorm_::call(const_cast\u003cTensor\u0026\u003e(*this), p, dim, maxnorm); } // aten::unfold(Tensor(a) self, int dimension, int size, int step) -\u003e Tensor(a) inline at::Tensor Tensor::unfold(int64_t dimension, int64_t size, int64_t step) const { return at::_ops::unfold::call(const_cast\u003cTensor\u0026\u003e(*this), dimension, size, step); } // aten::equal(Tensor self, Tensor other) -\u003e bool inline bool Tensor::equal(const at::Tensor \u0026 other) const { return at::_ops::equal::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::pow.Tensor_Tensor(Tensor self, Tensor exponent) -\u003e Tensor inline at::Tensor Tensor::pow(const at::Tensor \u0026 exponent) const { return at::_ops::pow_Tensor_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), exponent); } // aten::pow.Tensor_Scalar(Tensor self, Scalar exponent) -\u003e Tensor inline at::Tensor Tensor::pow(const at::Scalar \u0026 exponent) const { return at::_ops::pow_Tensor_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), exponent); } // aten::pow_.Scalar(Tensor(a!) self, Scalar exponent) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::pow_(const at::Scalar \u0026 exponent) const { return at::_ops::pow__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), exponent); } // aten::pow_.Tensor(Tensor(a!) self, Tensor exponent) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::pow_(const at::Tensor \u0026 exponent) const { return at::_ops::pow__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), exponent); } // aten::float_power.Tensor_Tensor(Tensor self, Tensor exponent) -\u003e Tensor inline at::Tensor Tensor::float_power(const at::Tensor \u0026 exponent) const { return at::_ops::float_power_Tensor_Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), exponent); } // aten::float_power.Tensor_Scalar(Tensor self, Scalar exponent) -\u003e Tensor inline at::Tensor Tensor::float_power(const at::Scalar \u0026 exponent) const { return at::_ops::float_power_Tensor_Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), exponent); } // aten::float_power_.Scalar(Tensor(a!) self, Scalar exponent) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::float_power_(const at::Scalar \u0026 exponent) const { return at::_ops::float_power__Scalar::call(const_cast\u003cTensor\u0026\u003e(*this), exponent); } // aten::float_power_.Tensor(Tensor(a!) self, Tensor exponent) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::float_power_(const at::Tensor \u0026 exponent) const { return at::_ops::float_power__Tensor::call(const_cast\u003cTensor\u0026\u003e(*this), exponent); } // aten::normal_(Tensor(a!) self, float mean=0, float std=1, *, Generator? generator=None) -\u003e Tensor(a!) inline at::Tensor \u0026 Tensor::normal_(double mean, double std, ::std::optional\u003cat::Generator\u003e generator) const { return at::_ops::normal_::call(const_cast\u003cTensor\u0026\u003e(*this), mean, std, generator); } // aten::alias(Tensor(a) self) -\u003e Tensor(a) inline at::Tensor Tensor::alias() const { return at::_ops::alias::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::isfinite(Tensor self) -\u003e Tensor inline at::Tensor Tensor::isfinite() const { return at::_ops::isfinite::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::isinf(Tensor self) -\u003e Tensor inline at::Tensor Tensor::isinf() const { return at::_ops::isinf::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::record_stream(Tensor(a!) self, Stream s) -\u003e () inline void Tensor::record_stream(at::Stream s) const { return at::_ops::record_stream::call(const_cast\u003cTensor\u0026\u003e(*this), s); } // aten::isposinf(Tensor self) -\u003e Tensor inline at::Tensor Tensor::isposinf() const { return at::_ops::isposinf::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::isneginf(Tensor self) -\u003e Tensor inline at::Tensor Tensor::isneginf() const { return at::_ops::isneginf::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::det(Tensor self) -\u003e Tensor inline at::Tensor Tensor::det() const { return at::_ops::det::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::slogdet(Tensor self) -\u003e (Tensor sign, Tensor logabsdet) inline ::std::tuple\u003cat::Tensor,at::Tensor\u003e Tensor::slogdet() const { return at::_ops::slogdet::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::logdet(Tensor self) -\u003e Tensor inline at::Tensor Tensor::logdet() const { return at::_ops::logdet::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::inverse(Tensor self) -\u003e Tensor inline at::Tensor Tensor::inverse() const { return at::_ops::inverse::call(const_cast\u003cTensor\u0026\u003e(*this)); } // aten::inner(Tensor self, Tensor other) -\u003e Tensor inline at::Tensor Tensor::inner(const at::Tensor \u0026 other) const { return at::_ops::inner::call(const_cast\u003cTensor\u0026\u003e(*this), other); } // aten::outer(Tensor self, Tensor vec2) -\u003e Tensor inline at::Tensor Tensor::outer(const at::Tensor \u0026 vec2) const { return at::_ops::outer::call(const_cast\u003cTensor\u0026\u003e(*this), vec2); } // aten::ger(Tensor self, Tensor vec2) -\u003e Tensor inline at::Tensor Tensor::ger(const at::Tensor \u0026 vec2) const { return at::_ops::ger::call(const_cast\u003cTensor\u0026\u003e(*this), vec2); } // aten::to_padded_tensor(Tensor self, float padding, SymInt[]? output_size=None) -\u003e Tensor inline at::Tensor Tensor::to_padded_tensor(double padding, at::OptionalIntArrayRef output_size) const { return at::_ops::to_padded_tensor::call(const_cast\u003cTensor\u0026\u003e(*this), padding, output_size.has_value() ? ::std::make_optional(c10::fromIntArrayRefSlow(*output_size)) : ::std::nullopt); } // aten::to_padded_tensor(Tensor self, float padding, SymInt[]? output_size=None) -\u003e Tensor inline at::Tensor Tensor::to_padded_tensor_symint(double padding, at::OptionalSymIntArrayRef output_size) const { return at::_ops::to_padded_tensor::call(const_cast\u003cTensor\u0026\u003e(*this), padding, output_size); } } // namespace at namespace c10 { template \u003c\u003e struct MaybeOwnedTraits\u003cat::Tensor\u003e { using owned_type = at::Tensor; using borrow_type = at::Tensor; static borrow_type createBorrow(const owned_type\u0026 from) { // NOTE: this can be implemented without the special // unsafe_borrow_t Tensor constructor as // // return borrow_type(c10::intrusive_ptr\u003cat::TensorImpl, at::UndefinedTensorImpl\u003e::reclaim(from.unsafeGetTensorImpl())); // // but that hurts inlining due to the nullptr check in the // Tensor(c10::intrusive_ptr\u003c...\u003e) constructor. We already know // that from.impl_ isn\u0027t null because from is a valid Tensor, so // we needn\u0027t do the check again. (using __builtin_assume can // avoid this, but wouldn\u0027t be portable to MSVC.) return borrow_type(borrow_type::unsafe_borrow_t{}, from); } static void assignBorrow(borrow_type\u0026 lhs, const borrow_type\u0026 rhs) { lhs.unsafeReleaseTensorImpl(); // See above note: this can be implemented with public API // similarly to createBorrow(), but that would hurt inlining. lhs = borrow_type(borrow_type::unsafe_borrow_t{}, rhs); } static void destroyBorrow(borrow_type\u0026 toDestroy) { toDestroy.unsafeReleaseTensorImpl(); // \"leak\" it, but it was already +0. } static const owned_type\u0026 referenceFromBorrow(const borrow_type\u0026 borrow) { return borrow; } static const owned_type* pointerFromBorrow(const borrow_type\u0026 borrow) { return \u0026borrow; } static bool debugBorrowIsValid(const borrow_type\u0026 /*borrow*/) { return true; } }; template \u003c\u003e struct ExclusivelyOwnedTraits\u003cat::Tensor\u003e { using repr_type = at::Tensor; using pointer_type = at::Tensor*; using const_pointer_type = const at::Tensor*; static repr_type nullRepr() { return at::Tensor(); } template \u003cclass... Args\u003e static repr_type createInPlace(Args\u0026\u0026... args) { return at::Tensor(std::forward\u003cArgs\u003e(args)...); } static repr_type moveToRepr(at::Tensor\u0026\u0026 x) { return std::move(x); } static void destroyOwned(at::Tensor\u0026 x) { return ExclusivelyOwnedTraits\u003cat::TensorBase\u003e::destroyOwned(x); } static at::Tensor take(at::Tensor\u0026 x) { return std::move(x); } static pointer_type getImpl(repr_type\u0026 x) { return \u0026x; } static const_pointer_type getImpl(const repr_type\u0026 x) { return \u0026x; } }; } // namespace c10 namespace at { inline c10::MaybeOwned\u003cTensor\u003e borrow_from_optional_tensor( const std::optional\u003cTensor\u003e\u0026 opt) { return opt.has_value() ? c10::MaybeOwned\u003cTensor\u003e::borrowed(*opt) : c10::MaybeOwned\u003cTensor\u003e::owned(std::in_place); } inline c10::MaybeOwned\u003cTensor\u003e Tensor::expect_contiguous(MemoryFormat memory_format) const \u0026 { if (is_contiguous(memory_format)) { return c10::MaybeOwned\u003cTensor\u003e::borrowed(*this); } else { return c10::MaybeOwned\u003cTensor\u003e::owned(__dispatch_contiguous(memory_format)); } } } // namespace at",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "../_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/api/program_listing_file_build_aten_src_ATen_core_TensorBody.h.html"
       },
       "datePublished": "2023-01-01T00:00:00Z",
       "dateModified": "2023-01-01T00:00:00Z"
     }
 </script>
  <script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
  
  </body>
</html>